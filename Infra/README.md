# Infra(인프라)

IT 인프라 - IT의 기반으로 되어 있는 방대한 데이터들을 관리<br>
인프라 아키텍처 - IT인프라의 구조

## 아키텍처의 종류

### 집약형 아키텍처

해당 주요 업무들을 모두 한대로 처리를 하는 작업

- 리소스 관리 -> 고부하 처리 요구가 왔지만 다른 처리에 영향을 주지 않는다.
  - 하나의 처리가 실수로 대령의 요청을 보내더라도 다른 처리에 영향을 주지 않는다.
- 이중화 -> CPU 하나가 망가져도 멈추지 않는다.
- '기간 시스템'으로 불리는 업무 시스템에서 이용하고 있는 경우가 많다.(은행의 계정시스템)
- 장점
  - 한 대의 대형 컴퓨터만 있으면 되므로 구성이 간단하다
  - 대형 컴퓨터의 리소스 관리나 이중화에 의해 안정성이 높고 고성능이다
- 단점
  - 대형 컴퓨터의 도입 비용과 유지비용이 비싸다
  - 확장성의 한계가 있다

### 분할형 아키텍처

여러 대의 컴퓨터를 조합하여 하나의 시스템을 구축하는 구조

- 소형 컴퓨터도 성능을 구현할 수 있지만 여러개를 묶어서 더 특화 시킨다
- 장점
  - 낮은 비용으로 시스템을 구축할 수 있다.
  - 서버 대수를 늘릴 수 있어서 확장성이 좋다
- 단점
  - 대수가 늘아나면 관리 구조가 복잡해진다.
  - 한 대가 망가지면 영향 범위를 최소화 하기 위한 구조를 검토해야 한다.

### 물리 서버 VS 논리 서버

서버 - 분할형 아키텍처에서 이용되고 있는 컴퓨터, 컴퓨터 자체(물리) 혹은 동작하는 소프트웨어(논리)를 의미

- 웹 서버: 인터넷 접속시 HHTML 생성을 담당하는 것 / DB 서버: 대량의 데이터를 저장해서 요청에 따라 데이터를 제공하는 것
  <br>
  컴퓨터 자체를 가리키는 경우 - '물리 서버'라고 부른다

## 수직 분할형 아키텍처

- 각각의 서버가 유사한 작업을 하는지, 전혀 다른 작업을 하는지에 따라 나뉘게 된다

### 클라이언트 - 서버형 아키텍처

수직 분할형 서버

- 킅라이언트는 소형 컴퓨터(PC), 스마트 폰에 설치
- 서버는 업무 애플리케이션, 미들웨어, 데이터베이스 등의 소프트웨어를 '물리 서버' 상에서 구현
- 클라이엉ㄴ트 측에서 전용 소프트 웨어를 설치하고 사용을 해야 한다.(즉, 정기적인 업데이트가 필요)
- 장점
  - 클라이언트 측에서 많은 처리를 실행 할 수 있어서 소수의 서버로 다수의 클라이언트 처리 가능
- 단점
  - 클라이언트 측의 소프트웨어 정기 업데이트가 필요하다
  - 서버 확장성의 한계가 발생할 수 잇다.

### 3계층형 아키텍처

수직 분할형 서버

- 프레젠테이션 계층
  - 사용자 입력을 받는다
  - 웹 브라우저 화면을 표시한다
- 애플리케이션 계층
  - 사용자 요청(Request)에 따라 업무를 처리한다.
- 데이터 계층
  - 애플리케이션 계층의 요청에 따라 입출력을 한다.
- 장점
  - 서버 부하 집중 개선
  - 클라리언트 단말의 정기 업데이트가 불필요
  - '처리 반환'에 의한 서버 부하 저감
- 단점
  - 구조가 클라이언트-서버보다 복잡하다

## 수평 분할형 아키텍처

용도가 같은 서버를 늘려나가는 방법<br>
대수가 늘어나면서 한 대가 시스템에 주는 영향력이 낮아진다.<br>
또한, 처리를 담당하는 서버 대수가 늘어나면 전체적인 성능 향상도 실현할 수 있다.

### 단순 분할형 아키텍처

"Sharding(샤딩)" 혹은 "Partitioning(파니셔닝)" 이라고 부른다.

- 시스템이 둘로 분할 됨으로써 시스템의 전체 처리 성능을 두배로 향샹 시클 수 있다.
- 두개의 독립적인 시스템이 생성되기 때문에 서로 장애의 영향을 받지 않는다.
- 장점
  - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
  - 분할된 시스템이 독립적으로 운영되므로 서로 영향을 주지 않는다.
- 단점
  - 데이터를 일원화 해서 볼 수 없다.
  - 애플리케이션 업데이트는 양쪽을 동시에 진행을 해야 한다.
  - 처리량이 균등하게 분할돼 잇지 않으면 서버별 처리양에 치우침이 생간다.

### 공유형 아키텍처

단순 분할형과 다르게 일부 계층에서 상호 접속이 이루어진다.

- 장점
  - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
  - 분할한 시스템이 서로 다른 시스템의 데이터를 참조할 수 있다.
- 단점
  - 분할한 시스템 간 독립성이 낮아진다.
  - 공유한 계층의 확장성이 낮이진다.

## 지리 분할형 아키텍처

업부 연속성 및 시스템 가용성을 높이기 위한 방식

### 스탠바이형 아키텍처

스탠바이 구성, HA구성, 액티브-스탠바이 구성으로만 이루어져 있다.

- 최소 두 대 물리 서버가 있어 한대가 고장나면 가동 중인 소프트웨어를 다른 한 대로 옮겨서 운영하는 방식("재시작" = "Failover")
- 장점
  - 물리 서버 고장에 대처를 할 수 있따
- 단점
  - 보통 페일 오버 대상 서비스가 놀고 있는 상태가 되기 때문에 리소스 측면에서 낭비된다.
- 스탠바이를 따로 두지 않고 동시에 교차로 사용하다가, 고장나면 페일 오버를 진행한다.

### 재해 대책형 아키텍처

재해에 대해서 복구 구성을 취하고 있다.

- 서버 장비를 최소 구성 및 동시 구성으로 별도 사이트를 배치하고, 소프트 웨어도 상용 환경과 동일하게 설정한다.
- 데이터는 매일 갱신되야 되기 때문에 저장소 장비 기능, OS기능, 데이터베이스 기능 등 동기 처리를 위한 방법은 여러가지가 있다.
- 각각의 비용, 대상 데이터, 동기 연장 특성 등을 고려하여 결정

<hr>

# 서버

서버는 랙(Lack)이라는 것이 장차괸다, 서버 외에도 HDD가 가득 장착돼 저장소나 인터넷 및 LAN을 연결하기 위한 네트워크 스위치도 탑재

- 서버, 소비 전력, 중량이 매우 중요하다

## 서버의 구성

- 서버와 PC는 물리적으로는 기본 구성이 같다.
- 정눵니 이중화 되어 있고, 대용량 CPU가 탑재 되어 있는 정도가 다르다

## CPU(Central Processing Unit)

- 서버 중심에 위채헛 연산 처리를 실시한다.
- 명령과 데이터는 기억 장치나 입출력 장치를 통해 전달된다.
- CPU를 '코어'라고 하며 하나의 CPU에 여러 개의 '코어'가 존재하는 멀티 코어도 있다.

## 메모리

- 기억 명령을 수행을 한다.
- CPU옆에 위치를 하며 CPU에 전달하는 내용이나 데이터를 저장하거나 처리 결과를 받는다.
- 메모리에 저장되는 정보는 영구성이 없다(서버가 재시작되면 없어진다)
- CPU자체에도 메모리를 존재한다(레지스터 L1/L2 캐시, 빠르지만 용량이 작다)
- 매모리가 여러 단계로 분리가 되어 있다.
  - 고속 CPU는 처리 지연을 허락하지 않는다.
  - 엑세스 속도를 위해서 영역을 여러 단계로 나눈다.
    - 캐시 메모리가 커질 수록 엑세스 속도가 커진다.
  - 그래서 바로 쓸 수 있는 것은 L1, 근처에 두고 싶은 것은 L2에 둔다.

### 메모리 인터리빙(Memory Interleaving)

- 메모리에 데이터를 미리 CPU에 전달하여 처리 지연을 줄이는 기능
- EX)
  - 3개의 채널을 사용하여 데이터 1을 요구하면 2와 3을 같이 보낸다.
  - 데이터가 연속해서 엑세스 된다는 규칙
  - 먼저 읽어서 처리 지연을 줄여 준다.
- 모든 채널의 동일 뱅크에 메모리를 채워야 한다.
- 다단계 구조를 가지고 각각의 엑세스 속도에 맞게 사용되기

## I/O 장치

### HDD

- 서버에서는 메모리에 비해 CPU에서 멀리 떨어진 곳에 HDD가 배치된다.
- 장기 저장 목적의 데이터 저장 장소로 사용한다.
- 전기가 없을 경우 메모리는 사라지지만, 디스크는 유지 된다.
- 자기 원반이 여러개 들어 있어, 고속으로 회전해서 읽기/쓰기를 한다
- 회전 구조 때문에 물리 법칙에 좌우되며, 메모리 처럼 순식간에 엑세스 할 수 없다
- 최근에는 물리적인 회전 요소를 사용하지 않는 SSD를 사용한다
- 하드웨어(스토리지)
  - I/O의 서브시스템이라고 불리는 장치로, 내부에서는 CPU와 캐시가 존재하고 수많은 HDD외에도 여러 기능를 탑재한다.
- 서버와 I/O에서는 HDD가 직접 데이터를 교환하는 것이 아니라 캐시를 이용해서 한다.
  - CPU 캐시와 이용방법이 동일하다 메모리 처럼 고속으로 I/O가 가능하다
- 파이버 채널(Fiber Channel)
  - 대형 저장소와 연결해서 케이블을 애용해서 SAN이라는 네트워크와 연동된다
  - SAN에 접속하기 위한 파이버 채널 인테페이스를 FC 포트라고 한다.
- I/O 읽기
  - 읽기 캐시 경우에는 캐시상에 데이터 복사본만 있으면 된다.
- I/O 쓰기
  - 쓰기 캐시 경우에는 데이터를 기록했다고 간주하는 경우 데이터를 잃을 수 있다.
  - 이러한 쓰기 I/O를 라이트백(Write Back)이라고 한다
- 라이트 스루(Write Through)
  - I/O는 캐시와 HDD에 모두 엑세스 한다.
  - 쓰기에는 디스크를 모두 읽어서 라이트 백과 비교한다
  - 이 경우에는 쓰기 캐시의 장점이 없어진다.
- 기본적으로 캐시의 장점을 살리기 위해 라이트백으로 설정한다

### 네트워크 인터페이스

서버와 외부 장비를 연결하기 위한 것으로 외부 접속용 인터페이스

### I/O 제어

I/O 버스는 PCI의 x8, x16 - I/O 회선의 개수를 의미한다

- 각 CPU/칩섹 구조마다 PCI를 연결할 수 있는 회선이 정해져 있다.
- 단, 각 서버에는 내부적인 사용 용도도 있으므로 외부 연결을 위해 사용할 수 있는 PCI 회전 수는 CPU가 처리할 수 있는 총량보다 적다

-- 이해가 안되서 추가 공부

## 버스

서버 내부에 잇는 컴포넌트들을 서로 연결시키는 회선

- 중요한 점: 버스가 어느 정도의 데이터 전송 능력(대역)을 가지고 있는가

### 대역 (처리량(Throughput))

데이터 전송 능력

- 한번에 데이터를 보낼 수 있는 데이터 전송의 폭(전송폭) X 1초에 전송할 수 있는 횟수(전송횟수)
- 전송 횟수는 '1초 / 1 처리당 소요시간(응답시간)' 으로도 표현한다
- EX) PCI Express 3.0은 1회선당 2GB/s
  - x8은 8회선으로 8배의 능력을 가지고 있다

### 버스 대역

CPU에 가까운 쪽이 1초당 전송량이 크다

- CPU와 메모리는 대량으로 데이터를 교환해서 매우 빠른 전송 능력이 요구 되어서 바로 앞에 위치한다
- USB 3.0 포트는 500MB/s이므로 저속이여서 PCH앞에 배치해도 상관 없다

- EX) 광랜 인터넷 - 최대 1GBps = 12MB/s 대역으로 통신이 가능하다
- 데이터 전송 속도와 전기적 신호 속도가 다르다는 견해로 버스 전송 속도는 기가트랜스러를 사용할 수도 있다
- 버스 흐름에서 가장 중요한 부분은 CPU와 장치 사이에 병목 현상이 없어야 한다.

  - 데이터 전송이 어떤 이유로 막혀 있는 상태가 있으면 안된다

- 예시 다시 공부

## 3계층형 시스템

웹 서버, AP 서버, DB 서버<br>
각각의 서버는 CPU, 메모리, 디스크, NIC/HBA 같은 하드웨어 부품이 나열되어 있다.(물리장치들)

httpd: HTTP PROTOCOL을 지원하는 Daemon, 즉, HTML 파일을 전송해주는 규약

- FTP를 지원하는 daemon은 ftpd이며, telnet을 지원하는 daemon은 telentd이다
- 즉, http를 지원하는 서버이며, Web Server를 구축한다는 말은 httpd를 수행하는 말과 같다
- EX) 아파치 서버도 Linux의 기본 httpd이다

daemon: 서비스의 요청에 대해 응답하는 오랫동안 실행중인 백그라운드(background) 프로세스다.

- 유닉스(리눅스 포함) 운영체제에서 이름이 "d"로 끝나는 프로세스(inetd, httpd, nfsd, sshd, named, lpd 등)이다.
- 부팅 때 자동으로 켜져 백그라운드에서 계속 실행되면서 꺼지지 않고 실시간으로 클라이언트와 통신을 계속 해야하는 서버 프로세스

background process: 입력장치에 대해 터미널과 관계를 끊은 모든 프로세스

- 사용자에게 무언가를 키보드를 통해 전달받지 않고 스스로 동작하는 프로세스
- 눈에 보이진 않지만 뒷 지역, 배경(Background)에서 묵묵히 할 일 하는 프로세스

NIC: Network Interface Controller

- LAN의 연결지점으로 제공하기 위해 컴퓨터에 설치하는 어뎁터
- 물리 계층과 데이터 계층서비스를 제공하다
- 장비와 LAN 사이의 통신을 제공한다

### 프로세스와 스레드

프로세스 및 스레드는 실팽 파일 자체가 아니라 OS상에서 시행돼서 어느정도 독립성을 가지고 동작한다

- 활동하기 위해서는 메모리 공간이 필요하고 커널에 의해 메모리 상으로 확보가 된다
- 메모리 공간을 통해서 데이터를 주고 받고 사용할 수 있다
- 메모리 공간은 프로세스 시작 시에 공간이 확보가 된다

프로세스의 시작

1. OS상에서 프로세스가 시작돼서 사용자 요청을 받을 수 있다.
2. 시작 의뢰가 있으면 커널이 프로세스를 요청하고 요청 분량만큼 메모리를 할당한다
3. 프로그램은 서버 내부의 디스크 상에 설치된다

프로세스와 스레드 메모리 공간의 차이

- 하나의 프로세스사 동작하고 있으면 메모리 공간을 점유하는 스레드 하나가 동작하고 있다.
- 각 스레드는 메모리 공간을 공유한다. 스레드 시작시에는 신규 메모리 공간은 필요 없지만, 다른 스레드에 이상이 발생하면 영향을 받는다.

논리 구성<br>
웹서버: OS안에 Httpd 프로세스들로 이루어져 있다 <br>
AP서버: OS안에 스레드들이 하나의 메모리 공간을 공유하고 있다.<br>
DB서버: DB안에 공유메모리들이 존재하고 여러 포르세스들이 참조한다<br>

- 각각의 서버들은 스위치를 경유해서 연결돼 있다

  - 각각의 서버를 보면 CPU, 메모리, 디스크, NIC/HBA 같은 하드웨어 부품이 나열돼 있다

- 오라클 DB에서는 여러 프로세스가 '공유 메모리 공간'을 이용할 수도 있다

1. 오라클 DB는 각 프로세스별 메모리(PGA), 전체가 공유하는 메모리(SGA)가 나누어져 있다.
2. SGA는 디스크상의 데이터 캐시나 실행 완료된 SQL 캐시, 테이블 인덱스 등이 저장
3. PGA는 해당 프로세스 SQL이 이용하는 소트 영역이나 테이블 결합에 사용하는 메모리 영역이 저장된다(다른 메모리 접근 불가)

SGA(System Global Area) - 모든 사용자가 공유 가능하여 사용<br>
PGA(Program Global Area) - 사용자마다 공유하지 않고 개별적으로 사용

- 이와 별도로 프로세스별 독자 메모리 영역도 있어서 용도별로 나누어 사용하고 있다
- 프로세스 간 공유하고 싶은 데이터(캐시를 저장하는 데이터)는 공유 메모리에 둔다

프로세스와 스레드의 차이점
||장점|단점|
|---|---|---|
|프로세스|개별 처리 독립성이 높다|생성시 CPU 부하가 높다|
|스레드|생성시 CPU 부하가 낮다| 메모리 공간을 공유하기 때문에 원하지 않는 데이터를 읽을 수 있다|

## OS 커널

OS에서 커널 자체를 '인프라'이다.

- 뒤에서 무슨 일이 벌어지는지 은폐하면서도 편리한 인터페이스를 제공한다
- 커널이 존재하기 때문에 개발자는 하드웨어나 다른 애플리케이션에 끼치는 영향을 의식하지 않고 애플리케이션을 만들 수 있다

### 시스템 콜 인터페이스

프로세스나 스레드로 부터 명령을 받는 인터페이스

- 애플리케이션이 OS를 통해 어떤 처리를 하고 싶으면 시스템 콜이라는 명령을 이용해서 커널에 명령을 내린다
  - 시스템 콜: 커널 영역의 기능을 사용자 모드가 사용 가능하도록한다. 즉, 프로세스가 하드웨어에 직접 접근해서 필요한 기능을 사용할 수 있게 해준다
- EX) 디스크상의 데이터를 읽고 싶거나 네트워크 통신을 하고 싶을 때, 새로운 프로세스를 생성하고 싶을 때
- 디스크 읽기 쓰기는 네트워크 읽기 쓰기와 같이 프로세스 관점에서는 동일한 시스템 콜이다

  - 둘 다 커널을 통해서 명령처리 되어서 뒤 프로세스를 인식할 필요가 없기 때문이다

- OS 커널의 역할 6가지
  - 시스템 콜 인터페이스, 프로세스 관리, 메모리 관리, 네트워크 스택, 파일 시스템 관리, 장치 드라이버

### 프로세스 관리

프로세스를 관리한다

- OS상에서 수십, 수백, 수천개의 프로세스를 가동할 수 있다
- 물리 서버는 CPU 코어의 개수가 적는데, 처리 순서를 어떻게 처리할 것인지 결정한다
- 가동되고 있는 프로세스 관리와 CPU 이용 우선순위 등을 스케줄한다

### 메모리 관리

메모리 영역을 관리

- 서버상의 메모리를 단위 크기 블록으로 분할해서 프로세스에 할당한다
- 물리 메모리 공간의 최대치를 고려한다.
- 프로세스가 이용하는 독립 메모리 공간을 확보하거나 상호 간의 참조 영역을 지키기 위해 독립성을 관리하는 등의 메모리 관리 역할을 한다
- 메모리 관리가 없으면 각 프로세스는 자신 이외의 프로세스가 사용하고 있는 메모리 영역을 파악해야 한다

### 네트워크 스택

네트워크를 관리

### 파일 시스템 관리

OS 기능의 하나로서 물리 디스크에 제공된 데이터를 관리하는 기능이다

- 디렉토리 구조제공, 엑세스 관리, 고속화 안정성 기능이 있다
- 프로레스 관점의 파일 시스템
  - 프로세스(스레드)는 편리성 때문에 파일 단위로 생각
  - 파일 시스템은 여러 프로세스가 공유한다
  - 자주 사용하는 내용은 메모리상에서 캐시하고 있다
  - 커널이 파일 시스템의 인터페이스로 동작한다
  - 프로세스는 물리 디스크 구조나 데이터 배치 상태를 의식할 필요가 없다

### 장치 드라이버

디스크나 NIC등의 물리 장치용 인터페이스를 제공한다

- NIC나 디스크는 다수의 제조사가 족자제품을 제공하고 있다.
- 각각에 대응하는 애플리케이션을 개발하는 것은 현실적이지 못하기 때문에 커널은 장치 드라이버를 이용해서 물리장치를 은폐
- 장치 제조사가 OS에 대응하는 장치 드라이버를 제공해서 OS당 표준 장차로서 커널을 경유해 이용할 수 있다

### 커널 구성 방식

1. 모놀로식 커널

- OS의 주요 구성 요소를 모두 하나의 메모리 공간을 통해 제공한다
- 명칭이 가진 의미대로 한 명의 '왕자'가 모든 기능을 제공하고 있다
- EX) LINUX OS

2. 마이크로 커널

- 최소한의 기능만 커널이 제공, 그 외 기능은 커널 밖에서 제공한다
- 커널 자체가 작아지기 때문에 더 심플하다
- EX) MAX OS

## 웹데이터 흐름

### 클라이언트 PC부터 웹 서버까지

클라이언트 PC에서 웹 브라우저를 실행해서 웹 서버에 요청을 보내고 AP서버에 질의 하기 까지의 흐름

1. 웹 브라우저가 요청을 발행한다

- 특정 인터넷 사이트를 요청한다

2. 이름 해석을 한다

- 해당 사이트가 어디에 있는지 이름 해석한다
- 이 결과를 가지고 웹 서버에게 요청한다

3. 웹 서버가 요청을 접수한다

- 'httpd' 프로세스가 요청을 접수한다

4. 웹 서버가 동적 콘텐츠인지 정적 컨텐츠인지 확인한다

- httpd 프로세스가 내용을 판단한다
- 정적: 변화가 없는 콘텐츠, html, css, js와 같이 미리 서버를 저장하고 서버의 요청을 바로 응답하는 컨텐츠
  - 실시간으로 변경할 필요가 없는 데이터
- 동적: 서버의 요청마다 결과값을 다르게 부여주는 형식, 사용자가 맞춤형 콘텐츠를 제공할 수 있도록 한다
  - 높은 빈도로 변경되는 데이터

5. 필요한 경로로 데이터를 엑세스 한다

- 정적인 정보이면 디스크로부터 읽는다
- 동적인 정보는 네트워크를 경유해서 다른 서버에 요청을 보낸다

`http://www.naver.com`을 입력하는 것은 HTTP를 이용해서 `www.naver.com` 서버 접속하는 것을 의미한다

서버가 아닌 PC에서의 처리 흐름

- 디스크에서 프로그램을 읽어서 프로세스를 시작하고, 메로리 공간을 확보한다

1. PC 내부도 서버와 거의 같은 구조이다
2. 웹 브라우저도 OS의 '프로세스'로 실행된다
3. 프로그램은 원래 디스크에 저장돼 있다. 이것을 읽어서 메모리에 상주시키고 실행하는 OS이다
4. 웹 브라우저 화면에서 링크를 클릭하면 웹 서버로 요청을 보낸다
5. 이것도 OS의 '시스템 콜'로 실행되고, 커널을 통해 NIC에 네트워크 통신이 요청된다
6. 네트워크 경유로 웹 서버에 질의를 한다

이름 해석(Name Resolution): 웹 브라우저가 서버를 확인하는 과정

- 인터넷 상 주소는 IP로 되어 있어 문자열 URL과 IP를 연결시켜야 한다

1. 웹 브라우저는 IP 주소를 일단 모른다
2. OS의 호스트명, IP 주소 변환 테이블을 참조해서 존재하지 않는 경우, 외부의 DNS서버에 요청을 던진다

- DNS 서버에 호스트명이 아닌 IP주소로 지정돼 있는 것은 이 때문이다

3. 전 세계에 있는 DNS 서버는 Root DNS를 기준으로 트리 구조로 돼있다

- 개별 DNS 서버는 정기적으로 부모 DNS서버에서 데이터를 받아서 최신 IP주소 목록을 유지한다

4. IP 주소 검색 결과가 반환된다

- 웹 서버의 역할은 HTTP 요청에 대해 적절한 파일이나 콘텐츠를 반환
- HTTP(HyperText Transfer Protocol)의 프로토콜을 가리킨다
- 웹 서버에는 Http를 처리할 수 있는 'httpd 프로세스'가 가동되고 있다.
- 부모/자식 프로세스 중에서는 자식 프로세스가 HTTP 요청을 접수한다

### 웝 서버부터 AP서버 까지

'동적 컨텐츠'를 수행하는 것이 AP서버이다

- 즉, 아직 존재하지 않는 콘텐츠를 가능한 빨리 만들어내는 역할
- 자바를 이용한 AP서버에서는 JVM이 동작한다

1. 웹 서버로부터 요청이 도착한다

- 웝 서버에서 온 요청은 NIC를 경유해서 커널에 의해 끼어들기 처리한다

2. 스레드가 요청 받으면 자신이 계산 가능한지, DB 접속이 필요한지 판단

- 스레드가 요청을 접수한다

3. DB 접속이 필요한 연결 풀에 엑세스 한다

- 동적 데이터를 가져오기 위해 연결 풀이용한다

4. DB에 보내는 접속 요청도 시스템 콜을 사용한다
5. 네트워크 경유로 DB서버에 대한 질의가 이루어진다

- AP서버가 DB서버에 접속하기 위해서 '드라이버'가 필요하다
- 커널의 장치 드라이버와 비슷하다

- 자주 갱신되지 않고 규모가 작은 경우에는 JVM 내부에 캐시로 저장해 두었다가 반환하는 것이 좋다
- 규모가 매우 큰 경우에는 DB서버 외에 CDN(Content Delivery Network)이라 불리는 데이터 전송 전용 서버를 이용한 경우도 있다
  - 대량의 데이터를 전송에 특화 되어 있다, 복사본(캐시)를 배치하는 기술과 병렬 기술을 활용해서 처리를 효율화한다

### AP서버 부터

오라클 DB인 경우 서버가 요청을 접수한다. 요청은 SQL을 통해서 이루어진다

1. AP서버로 부터 요청이 도착한다

- DB서버에서는 DB프로세스가 요청을 접수한다

2. 프로세스가 요청을 접수하고 캐시가 존재하는지 확인한다

- 이전에 사용한 정보는 캐시에 있기 때문에 이 정보를 찾기 위해 일단 공유 메모리를 검색한다

3. 캐시가 없으면 디스크에 엑세스 한다

- 공유 메모리에 데이터가 존재하지 않기 때문에 디스크에서 읽는다
- 이전과 같은 방식으로 시스템 콜을 경유해서 디스크에 요청한다

4. 디스크가 데이터를 반환한다

- 디스크의 데이터는 요청을 보낸 프로세스로 반환된다

5. 데이터를 캐시 형태로 저장한다

- 한번 엑세스한 데이터는 메모리에 캐시 형태로 저장되고 이후 엑세스 시에 재사용 된다

6. 결과를 AP 서버에 반환한다

- 요청을 보낸 AP서버로 데이터를 반환한다

- 웹 서버에서는 개뱔 프러세스가 독립된 형태로 동작하지만, DB서버에서는 여러 개의 프로세스가 역할을 분담하는 경우가 있다
  - 서버 프로세스: SQL의 요청을 받아서 데이터를 검색 가공한다, 디스크에서 메모리를 읽거나 메모리에 캐시를 저장하는 역할도 한다
  - 백그라운드 프로세스: 메모리 상의 차이 정보(REDO)을 관리하거나 데이터를 디스크에 반영하는 일을 한다
  - 개별 서버 프로세스가 아닌 공유화를 통해 효율성 및 비동기성을
- 저장장치에는 다수의 디스크가 설치되어 있다
  - 본질적인 구조는 거의 차이가 존재하지 않는다
  - 메모리에는 데이터를 캐시 형태로 저장하는 구조도 있다

### AP서버에서 웹 서버까지

DB서버에서 데이터가 돌아왔기 떄문에 AP서버의 요청 스레드로 결과가 반환된다

1. DB서버로 부터 데이터가 도착한다

- DB서버에서 돌아온 데이터는 NIC 경유로 원래 스레드로 반환이 된다

2. 스레드가 데이터를 가지고 계산 등을 한 후에 파일 데이터를 생성한다

- DB데이터, JVM의 캐시, 데이터 등을 이용하여 계산 처리, 집계 처리등이 이루어지고 특정 형태의 파일이 생성된다

3. 결과를 웹 서버로 반환한다

- 웝 서버로 데이터들이 반환된다
- 주로 HTML, XML을 이용하거나 동적 이미지 등의 바이너리 데이터를 반환할 수도 있다
- HTTP로 전송 가능한 데이터라면 어떤 형태의 데이터든지 상관없다

### 웝서버에서 클라이언트 PC까지

AP서버에서 돌아온 데이터를 받아서 웹 서버의 httpd 프로세스가 PC의 웹 브라우저로 반환된다

1. AP서버로 부터 데이터가 도착한다

- AP서버에서 돌아온 데이터는 NIC 경우로 원래 스레드에 반환

2. 프로세스는 받은 데이터를 그대로 반환한다

- 필요한 데이터 가공은 모두 AP서버에서 이루어진다 => 그대로 반환한다

3. 결과가 웹 브라우저로 반환되고 화면에 표시된다

- 요청한 데이터를 웹 브라우저로 반환된다
- 웹페이지는 HTML과 다수의 이미지 파일등이 있기 때문에 복수의 요청으로 분할돼서 웹서버에 도착하고, 요청별로 데이터를 반환한다

### 전체 경로

클라이언트 PC -> 웹 서버

1. 웹 브라우저가 요청을 발행
2. 이름 해석을 한다
3. 웹 서버가 요청을 접수한다
4. 웹 서버가 정적 콘텐츠인지, 동적 콘텐츠인지 판단한다
5. 필요한 경로로 데이터를 엑세스 한다

웹 서버 -> AP 서버

6. 동적 컨텐츠를 소화하기 위해 웹 서버로 부터 요청이 도착한다
7. 스레드가 요청을 받으면 자신이 계산할 지, DB 접속이 필요한지 판단한다
8. DB 접속이 핑요하면 연결 풀에 엑세스 한다
9. DB 서버에 요청을 던진다

AP 서버 -> DB 서버 -> AP 서버

10. AP 서버로 부터 요청이 도착한다
11. 프로세스가 요청을 접수하고 캐시가 존재하는지 확인한다
12. 캐시에 없으면 디스크에 엑세스 한다
13. 디스크가 데이터를 반환한다
14. 데이터를 캐시 형태로 저장한다
15. 결과를 AP 서버에 반환한다

AP 서버 -> 웹 서버

16. DB서 서버로부터 데이터가 도착한다
17. 스레드가 데이터를 가지고 계산 등을 한 후에 파일 데이터를 생성한다
18. 결과를 웹 서버로 반환한다

웹 서버 -> 클라이언트 PC

19. AP 서버로 부터 데이터가 도착한다
20. 프로세스는 받은 데이터를 그대로 반환한다
21. 결과를 웹 브라우저에 반환되고 화면에 표시한다

### 웹 데이터 흐름 정리

- 공통점

  - 프로세스나 스레드가 요청을 받는다
  - 도착한 요청을 파악해서 필요에 따라 별도 서버로 요청을 보낸다
  - 도착한 요청에 대해 응답한다

- 3계층 시스템은 사용자 요청이 시발점이 되어 다양한 서버로 전달한다
- 자신이 할 수 없는 처리는 다음 서버에서 그 역할을 떠넘긴다
- 요청 기반 아카텍처이기 떄문에 각 서버는 '문을 열고 기다리고 있는' 상태이다

## 가상화

컴퓨터 시스템에서 물리 리소스를 추상화 하는 것

- 한 대의 서버를 여러 대의 논리 리소스 처럼 보이게 하는 기술

### OS

하드웨어를 이식하지 않고 애플리케이션을 사용가능

- OS의 커널에 의해 하드웨어가 추상화되면서, 컴퓨터에 연결된 기억 장치나 네트워크를 통한 데이터 교환이 하드웨어를 의식하지 않고 이루어지고 있다
  - OS가 없으면 하드웨어의 사양을 고려해서 프로그램을 작성해야 한다
    - 메모리 관리, 멀티 태스크, 파일 시스템등도 별도로 구현해야한다
  - OS에 의해 하드웨어가 추상화돼 있다
    - 메모리의 물리 주소, 하드디스크의 물리 주소를 고려하지 않고 프로그램을 개발할 수 있다
- 하나의 컴퓨터에서 동시에 다수의 프로그램이 움직이고 있으므로 OS는 중요하다
- OS가 있어서 가상 메모리를 사용해 프로세스 및 OS 커널의 메모리 공간을 분리한다
  - 하나의 프로그램이 실패한다고 해도 시스템 전체에 영향을 끼치지 않는다

### 가상 머신

1. 호스트 OS형

- 원도우즈나 리눅스 등의 호스트 OS 상에 가상화 소프트웨어를 설치해서 이용
- VMware Server, Microsoft Virtual Server
- 소프트웨어를 에뮬레이터 하는 것으로 성능면에서 제한이 있다

2. 하이퍼바이저형

- 하드웨어상에서 직접 가상화 소프트웨어를 실행하고 그 위에 가상 머신을 동작시키는 기술이다
- VMware vSphere, Hyper-V, Xen, KVM
- 호스트 OS를 거치지 않으므로 호스트형보다 성능이 우사하다
- 완전 가상화
  - 물리 머신상에서 동작하는 OS나 드라이브를 그래도 게스트로 이용할 수 있다
  - 소프트웨어를 에뮬리이션하기 때문에 성능이 저하된다
- 준 가상화
  - 가상 환경에서 동작시키는 게스트 OS마다 준가상화 전용 드라이버나 준 가상화용으로 최적화된 OS커널을 이용해야 한다

### 컨테이너

리소스가 격리된 프로세스

- 하나의 OS상에서 여러 개의 동시에 가동할 수 있다
- 독립된 루트 파일 시스템, CPU/메모리, 프로세스 공간 등을 사용할 수 있다
- 즉 각 컨테이너가 커널 공간을 공유한다
  - 하이퍼바이저 가상화 같은 경우는 각 게스트가 커널 공간을 가지고 있다
- 각 컨테이너는 커널 공간을 공유한다

- chroot: 프로세스가 OS의 루트 디렉터리 아래에 있는 특정 계층에 접근하지 못하도록 하는 기능
  - 하나의 컴퓨터로 상용, 개발 환경을 함께 사용하면 잘못된 파일을 변경하거나 삭제할 위험을 제거

### Docker

애플리케이션 실행 환경을 자동 구축해 주는 '도커 이미지'라는 기술을 클라우드 이외의 환경에서도 사용할 수 있다

- Docker hub라는 도커 이미지를 공유하면서 더 많이 사용할 수 있다

1. 도커 파일을 통해서 도커 이미지를 작성할 수 있다

- 애플리케이션 프레이워크, 애플리케이션 라이브러리, OS이미지

2. 도커 이미지 공개

- 도커 허브에 도커 이미지들을 저장한다

3. 도커 이미지 배포를 한다

장점

- 컨테이너는 호스트 OS와 OS 커널을 공유하므로 컨테이너 실행이나 정지 속도가 빠르다
- 호스트 OS의 커널을 공유하므로 VM만 사용하는 경우와 비교해 한대의 호스트 머신상에서 훨씬 많은 컨테이너 실행 가능
  - 리소스를 한 곳에서 쉽게 관리할 수 있다
- 도커는 라이브러리나 프레임워크 등을 도커 이미지로 묶어서 공유할 수 있는 것
  - 특정 환경에서는 재현되지만 자신의 개발 환경에서는 재현되지 않은 문제가 발생하기 어렵다
  - 버그를 효율적으로 수정할 수 있다

### 클라우드와 가상화 기술

하이퍼바이저 및 컨테이너 등의 가상화 기술들은 AWS(Amazon), GCP(Google), Azure(Microsoft)등에서 사용하고 있다

- 가상 머신 서비스, 컨테이너 서비스, FasaS 서비스나 다른 기타 서비스를 지탱하는 기술로 이용되고 있다

### IaaS, PaaS, SaaS

On-premis: 하드웨어 푸터 어플리케이션까지 모든 것을 사용자가 처리

IaaS(Infrastructure as a Service): 소프트웨어 및 서비스 구축을 위해 인프라만 제공하는 형태

- 서버, 네트워크 , 스토리지, 메모리, CPU 등 가상 인프라를 빌려주는 서비스
- OS, 미들웨어 등은 사용자가 직접 설치 괸리한다

PaaS(Platform as a Service): 소프트웨어 개발 및 관리에 필요한 환경(Platform)을 서비스별, 기능별로 제공<br>

- 애플리케이션 설계, 개발, 테스트, 배포, 호스팅을 포함하며, 애플리케이션, 서비스를 제공하기 위해 필요한 모든 자원을 빌료주는 것
- 개발 및 운영 환경을 포함한 플랫폼을 제공
- 제공된 플랫폼에서 어플리케이션, 서비스 개발에 집중할 수 있다

SaaS(Software as a Service): 서비스 제공자가 서버 등의 기본 인프라는 물론 바로 상ㅇ할 수 있는 애플리케이션 최종 사용자에게 제공하는 서비스

- 클라우드를 통해 제공되는 소프트웨어로 별도의 설치나 전환 과정 없이 퍼블릭 클라우드에 설치되어 있는 애플리케이션
- 서비스를 인터넷을 통해 제공받는 것

## 로드 밸런싱

하나의 인터넷 서비스가 발생하는 트래픽이 많을 때 여러 대의 서버가 분산하여 서버의 로드율 증가, 부하량 속도 저하등을 고려하여 적절히 분산처리하여 해결해주는 서비스

- Scale-up: Server가 더 빠르게 동작하기 위해 하드웨어 성능을 올리는 방법
- Scale-out: 하나의 Server보다는 여러 대의 Server가 나눠서 일을 하는 방법

  - 하드웨어 서버 향상하는 비용보다 서버 한대 추가 비용이 더 작다
  - 여러 대의 Server 덕분에 무중단 서비스를 제공할 수 있다.
  - 여러 대의 Server에 균등하게 Traffic을 분산시켜주는 역할을 하는 것이 `Load Balancer`이다

- NAT
  - 사설 IP주소를 공인 IP 주소로 바꾸는 데 사용하는 통신망의 주소 변조기
- Tunneling
  - 인터넷 상에서 눈에 보이지 않는 통로를 만들어서 통신할 수 있게 한다
  - 데이터를 캡슐화해서 연결된 상호간에만 캡슐화된 패킷을 구별해 캡슐화를 해제할 수 있다.
- DSR(Dynamic Source Routing Protocol)

  - 로브 밸런서 사용시 클라이언트로 되돌아가는 경우 목적지 주소를 스위치 IP 주소가 아닌 클라이언트 IP 주소로 전달
  - 네트워크 스위치를 거치지 않고 클라리언트를 찾아가는 개념

- L2: Mac주소를 바탕으로 Load Balancing
- L3: IP 주소를 바탕으로 Load Balancing
- L4: Transport Layer(IP와 Port) Level에서 Load Balancing
- L7: Application Layer(사용자의 Request) Level에서 Load Balancing

## Scaling

### X-axis Scaling

- 로드 밸런서 뒤에서 여러 개의 애플리케이션을 복사본을 실행하는 것
- N개의 복사 본이 있는 경우 각 복사본은 로드의 1/N을 처리한다
- 각 복사본이 모든 데이터를 잡재적으로 액세스 하기 때문에 캐시가 효과적이기 위해서는 더 많은 메모리가 필요하다

### Y-axis Scaling

- 여러 개의 다른 서비스로 분할한다
- 각 서비스는 하나 이상의 밀접하게 관련된 기능을 담당한다
- 두 가지의 방식
  - 동사 기반의 분해를 사용하고 체크아웃과 같은 단일 사용 사례를 구현 서비스 로 정의
  - 명사별로 응용 프로그램을 분해하고 고객관리 등 특정 법인과 모든 운영을 책임지는 서비스이다.

### Z-axis Scaling (추가 공부)

- 각 서버는 동일한 코드 사본을 실행하는 것으로 X-axis Scaling과 비슷
- 각 서버가 데이터의 일부분만 책임을 진다
- 시스템의 일부 구성요소는 각 요청을 적절한 서버로 라우팅할 책임이 있다.
- Z-axis Scaling은 주로 데이터베이스 축적에 사용된다
  - 데이터는 각 레코드의 속성에 기초하여 서버 집합에 걸쳐서 분할 된다
- 장점
  - 각 서버는 데이터의 서브셋만 처리한다
  - 캐시 활용도가 향상되고 메모리 사용량과 I/O 트래픽이 감소한다
  - 요청이 일반적으로 여러 서버에 분산되기 때문에 트랜잭션 확장성도 향상된다
  - Z-axis Scaling은 장애 발생 시 일부만 데이터를 엑세스할 수 있기 때문에 장애 분리를 개선한다
  - RESTORE 테이블의 기본 키는 서로 다른 두 데이터베이스 서버 사이의 행을 분할하는 데 사용한다
- 단점
  - 애플리케이션의 복잡성이 증가한다
  - 데이터를 다시 분할해야 하는 경우 까다로울 수 있는 분할 방식을 구현해야한다
  - 개발 및 애플리케이션 복잡성이 증가하는 문제를 해결하지 못한다

## MSA(MicroService Architecture)

사용하는 이유 (이전의 Monolithic Architecture의 특징)

- 소프트웨어의 모든 구성요소가 한 프로젝트에 통합되어 있는 형태
- 서비스 / 프로젝트가 커지면 커질 수록, 영향도 파악 및 전체 시스템 구조의 파악에 어려움
- 빌드 시간 및 테스트 시간, 그리고 배포 시간이 기아급수적으로 늘어남
- 서비스를 부분적으로 Scale-out하기가 힘들다
- 부분의 장애가 전체 서비스의 장애로 이어지는 경우가 발생하게 된다

MSA

- 각각의 서비스는 크기가 작을 뿐 서비스 자체는 하나의 모놀리틱 아키텍쳐와 유사한 구조를 가짐
- 각각의 서비스는 독립적으로 배포가 가능해야함
- 각각의 서비스는 다른 서비스에 대한 의존성이 최소화 되어야함
- 각 서비스는 개별 프로세스로 구동되며, REST와 같은 가벼운 방식으로 통신되어야 함

장점

- 배포: 서비스별 배포 가능(배포시 전체 서비스의 중단이 없다)
  - 요구사항을 신혹하게 반영하여 배포할 수 있다
- 확장: 특정 서비스에 대한 확장성이 용이함
  - 클라우드 사용에 적합한 아키텍처
- 장애: 장애가 전체 서비스로 확장될 가능성이 적다
  - 부분적 장애에 대한 격리가 수월함
- 신기술 적용이 유연하고 서비스를 다양한 언어로 개발 운영 할 수 있는 장점이 있다

단점

- 성능: 서비스 간 호출시 API를 사용하기 때문에, 통신 비용이나 Latency가 그만큼 늘어나게 된다
- 테스트 / 트랜잭션: 서비스가 분리되어 있기 떄문에 테스트와 트랜잭변 복잡도가 증가
- 데이터 관리: 데이터가 여러 서비스에 분산되기 떄문에 한 번에 조회하기 어렵고, 정합성 또한 관리하기 어렵다


## 네트워크

서로 다른 장비 간 데이터를 교환할 때 기본적으로는 네트워크를 경유해서 데이터를 송수신할 필요할때 사용

### 계층구조

데이터나 기능 호출 흐름에 따라 계층 간 역할이 나누어진다

- 역할이 나누어져 있기 때문에 각 층은 자신이 담당하는 일만 책임진다
- 상호 연결되어 있는 계층들에서는 교환 방법, 즉 인터페이스만 정해주면 된다

- 각 계층을 나눔으로 써, 계층 간에 서로 영향을 주지 않고 독립적으로 동작할 수 있다
- 상호 간에 내부 처리를 은폐하고 있기 대문에 인터페이스만 바꾸지 않으면 각 계층이 내부적인 처리를 마음대로 바꾸어도 문제 없다
- 대신, 작업 효율을 희생해야 한다

### OSI 7계층 모델

OSI통신을 7개의 계층으로 나눈 것

- 이 계층 구조 개념은 다양한 분야에서 공통적으로 참조할 수 있는 '참조 모델'

1. 애플리케이션 계층

- 애플리케이션 처리

2. 프레젠테이션 계층

- 데이터 표현 방법

3. 세션 계층

- 통신 시작과 종료 순서

4. 전송 계층

- 네트워크 통신 관리

5. 네트워크 계층

- 네트워크 통신 경로 선택

6. 데이터 링크 계층

- 직접 접속돼 있는 기간 처리

7. 물리 계층

- 전기적인 접속

- 시스템이 커질수록 역할별로 계층화 하지 않으면 전체 구조가 복잡해진다
- 서버 한 대의 서버 내부를 살펴봐도 역시 계층주어로 되어 있다

하나의 상자로 표시하고 있는 애플리케이션이나 커널 등도 세분화 된 계층으로 나누고 레이어(Layer)으로 불린다

- 자바 애플리케이션, 애플리케이션 서버, JVM, 커널, 하드웨어로 분리된다
  - 커널과 애플리케이션(JVM)은 시스템 콜이라는 인터페이스로 연결되어 있다

## 프로토콜

컴퓨터가 서로 소통하기 위해 정한 규약

- 통신 매체 프로토콜이 다르면 통신이 불가능하다
- 언어 프로토콜과 그 것을 전달하는 프로토콜이 일치를 해야 한다
- 컴퓨터 상에서 떨어져 있는 두 곳의 장비는 사전에 프로토콜알아 두어야 한다
- 브라우저에서 HTTP 프로토콜을 사용해서 서버에게 웹 페이지를 달라고 요청할 때, 전기 신호나 전파를 이용해서 전달
- 네트워크에서는 제조사마다 서로 일치된 프로토콜을 사용한다
  - IEEE(Institute of Electronics Engineers): 전기 통신을 사용한 프로토콜 표존화, 무선 LAN 프로토콜(LAN 공유기)
  - IETF(Internet Engineering Task Force): 인터넷에서 사용하는 다양한 기술 표준화(RFC)
- 통신 매체가 되는 통신 프로토콜이 있고 통합하면 의미를 전달하는 통신 프로토콜이 있다

- 서버 내부의 프로토콜
  - USB와 PC, 저장소에서 데이터 꺼낼때도 다 프로토콜이 있다
  - SCSI: 저장소용 장비 드라이버가 SCSI 등의 프로토콜을 사용해서 데이터 교환을 한다
  - 멀치 코어 CPU들이 서로 소통하기 위해서도 프로토콜이 존재한다

### TCP/IP

인터넷을 포함해서 현재 네트워크의 필수 프로토콜 (TCP/IP Protocol Suite)

- TCP와 IP의 두가지 프로토콜을 주축으로 만들어진 프로토콜

### TCP/IP 계층 구조

- TCP/IP에서는 반드시 7계층이 아니라 4계층(5계층)으로 불리며 1~2 계층을 모아서 링크, 5~7 계층을 모아서 애플리케이션 계층으로 취급하기도 한다
  <br>

웹 서버에서 HTTP라고 하는 프로토콜을 사용할 때의 계층 구조

1. HTTP

- httpd 프로세스를 사용

2. TCP

- 애플리케이션이 의뢰한 데이터를 책임지고 상대방에게 전달

3. IP

- 데이터를 최종 위치까지 전달

4. 이너넷

- 직접 연결돼 잇는 주변 장비에게 전송
  <br>
- HTTP 통신 데이터를 상대방에게 보내기 위해서 TCP 데이터를 건네지만, 이더넷 계층까지는 OS 커널이 담당한다
  - 커널내에서 TCP, IP, 이더넷을 모두 담당하게 된다, 각 담당하는 기능은 필요한 정보를 데이터에 부여해서 최종적으로 이더넷 프레임이 생성된다
  - 이것이 NIC에 전달돼서 이더넷 케이블 등을 통해 인접 노드를 경유해서 최종 위치로 전달
  - 네트워크에 연결된 컴퓨터 등은 호스트 라고 한다
- 통신하고 싶은 애플리케이션은 독자적으로 통신 구조를 만들 필요 없이 TCP/IP에게 위임할 수 있다
- 간단하게 데이터를 보내기 위해서는 TCP 대신 UDP 혹은 무선으로 통신할 수도 있다

명칭

- L2: 링크 계층, 이더넷 계층
- L3: IP 계층
- L4: 전송 계층(TCP)
- L7: 애플리케이션 계층
  - L5, L6, L7을 모아서 애플리케이션으로 취급한다

### HTTP 처리 흐름 in L7

- 애플리케이션을 시작으로 통신이 시작이 된다
- 애플리케이션이 사용하는 모든 프로토콜을 애플리케이션 계층 프로토콜이라고 부른다
- 자신이 통신하는 것이 아니라 통신은 모두 TCP/IP에 맡긴다
- RFC2616에서 HTTP 사용을 정하고 있다

1. 브라우저에 URL을 입력한다
2. 요청이 전송된다
3. 웹 서버에서는 요청이 해석된다
4. 파일이나 이미지를 응답으로 반환한다
5. 파일 내부를 해석해서 이미지 등이 포함돼 있으면 다시 요청을 보낸다

- 추가 이미지나 스크립트 등이 포함돼 있으면 웹 서버에 이들을 계속 요청을 한다

- Request 요청은 명령으로 구성된다
- Response는 요청에 대한 결과와 그에 대한 상태 정보를 가지고 있다

1. 요청: 서버에 대한 요구 명령, 대상 데이터를 지정

- EX) GET/HTTP/1.1

2. Message-header: 브라우저에 상세한 정보를 전달(표시 대응 브라우저, 데이터 형식, 접속 방식)

- EX) User-Agent: Mozli.....

3. Message-Body

- Request: 브라우저에 입력한 내용이 포함된다
- Reponse: HTML 데이터 등 실제 데이터가 저장된다

- HTTP가 그 하위 계층인 IP나 유선을 통해 명령을 보내거나 통신 제어를 하지 않는다

  - 이 때문에 HTTO 요청은 여러가지 명량만으로 구성돼서 매우 간단하다

- 애플리케이션 프로토콜은 사용자 공간을 처리
  - 클라이언트 프로세스와 httpd 프로세스를 통해서 애플리케이션 계층 프로토콜이 http 요청이 통신하는 모습
  - 애플리케이션 자체가 통신구조를 가지지 않고서도 원격지에 있는 서버 애플리케이션과 통신할 수 있다
  - 애플리케이션 계층 프로토콜은 필요한 데이터를 소켓에 기록만 하고, 통신은 TCP/IP에 위임한다

- 소켓 이하는 커널 공간에서 처리
  - 애플리케이션 프로세스는 시스템 콜을 통해서 커널에 TCP/IP 통신을 요청
  - 이때, 접속 대상 서버의 IP 주소와 TCP 포트 두가지 정보가 필요하다
  1. 시스템 콜 경우로 통신하고 싶은 상대를 커널에 지정하고, 소켓이라 불리는 데이터 통로를 만들어 준다
  2. 통신 상대가 보낸 데이터가 소캣을 통해 나온다
  - 이때, 상대방 서버에서도 소켓이 만들어지고 가상 경로가 생성이 된다
  - 실제로는 통신 케이블을 통해서 전송이 되지만, 프로세스 관점에서는 소켓을 통해서 데이터가 통신이 된다
  - 커널이 TCP/IP의 통신 처리를 해서 데이터를 소켓이 넣는 처리를 한다
  - 최종적으로는 NIC로 부터 데이터가 전송이 된다
  - 데이터는 도중에 다양한 경로를 거친다

