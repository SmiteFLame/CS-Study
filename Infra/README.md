# Infra(인프라)

IT 인프라 - IT의 기반으로 되어 있는 방대한 데이터들을 관리<br>
인프라 아키텍처 - IT인프라의 구조

## 아키텍처의 종류

### 집약형 아키텍처

해당 주요 업무들을 모두 한대로 처리를 하는 작업

- 리소스 관리 -> 고부하 처리 요구가 왔지만 다른 처리에 영향을 주지 않는다.
  - 하나의 처리가 실수로 대령의 요청을 보내더라도 다른 처리에 영향을 주지 않는다.
- 이중화 -> CPU 하나가 망가져도 멈추지 않는다.
- '기간 시스템'으로 불리는 업무 시스템에서 이용하고 있는 경우가 많다.(은행의 계정시스템)
- 장점
  - 한 대의 대형 컴퓨터만 있으면 되므로 구성이 간단하다
  - 대형 컴퓨터의 리소스 관리나 이중화에 의해 안정성이 높고 고성능이다
- 단점
  - 대형 컴퓨터의 도입 비용과 유지비용이 비싸다
  - 확장성의 한계가 있다

### 분할형 아키텍처

여러 대의 컴퓨터를 조합하여 하나의 시스템을 구축하는 구조

- 소형 컴퓨터도 성능을 구현할 수 있지만 여러개를 묶어서 더 특화 시킨다
- 장점
  - 낮은 비용으로 시스템을 구축할 수 있다.
  - 서버 대수를 늘릴 수 있어서 확장성이 좋다
- 단점
  - 대수가 늘아나면 관리 구조가 복잡해진다.
  - 한 대가 망가지면 영향 범위를 최소화 하기 위한 구조를 검토해야 한다.

### 물리 서버 VS 논리 서버

서버 - 분할형 아키텍처에서 이용되고 있는 컴퓨터, 컴퓨터 자체(물리) 혹은 동작하는 소프트웨어(논리)를 의미

- 웹 서버: 인터넷 접속시 HHTML 생성을 담당하는 것 / DB 서버: 대량의 데이터를 저장해서 요청에 따라 데이터를 제공하는 것
  <br>
  컴퓨터 자체를 가리키는 경우 - '물리 서버'라고 부른다

## 수직 분할형 아키텍처

- 각각의 서버가 유사한 작업을 하는지, 전혀 다른 작업을 하는지에 따라 나뉘게 된다

### 클라이언트 - 서버형 아키텍처

수직 분할형 서버

- 킅라이언트는 소형 컴퓨터(PC), 스마트 폰에 설치
- 서버는 업무 애플리케이션, 미들웨어, 데이터베이스 등의 소프트웨어를 '물리 서버' 상에서 구현
- 클라이엉ㄴ트 측에서 전용 소프트 웨어를 설치하고 사용을 해야 한다.(즉, 정기적인 업데이트가 필요)
- 장점
  - 클라이언트 측에서 많은 처리를 실행 할 수 있어서 소수의 서버로 다수의 클라이언트 처리 가능
- 단점
  - 클라이언트 측의 소프트웨어 정기 업데이트가 필요하다
  - 서버 확장성의 한계가 발생할 수 잇다.

### 3계층형 아키텍처

수직 분할형 서버

- 프레젠테이션 계층
  - 사용자 입력을 받는다
  - 웹 브라우저 화면을 표시한다
- 애플리케이션 계층
  - 사용자 요청(Request)에 따라 업무를 처리한다.
- 데이터 계층
  - 애플리케이션 계층의 요청에 따라 입출력을 한다.
- 장점
  - 서버 부하 집중 개선
  - 클라리언트 단말의 정기 업데이트가 불필요
  - '처리 반환'에 의한 서버 부하 저감
- 단점
  - 구조가 클라이언트-서버보다 복잡하다

## 수평 분할형 아키텍처

용도가 같은 서버를 늘려나가는 방법<br>
대수가 늘어나면서 한 대가 시스템에 주는 영향력이 낮아진다.<br>
또한, 처리를 담당하는 서버 대수가 늘어나면 전체적인 성능 향상도 실현할 수 있다.

### 단순 분할형 아키텍처

"Sharding(샤딩)" 혹은 "Partitioning(파니셔닝)" 이라고 부른다.

- 시스템이 둘로 분할 됨으로써 시스템의 전체 처리 성능을 두배로 향샹 시클 수 있다.
- 두개의 독립적인 시스템이 생성되기 때문에 서로 장애의 영향을 받지 않는다.
- 장점
  - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
  - 분할된 시스템이 독립적으로 운영되므로 서로 영향을 주지 않는다.
- 단점
  - 데이터를 일원화 해서 볼 수 없다.
  - 애플리케이션 업데이트는 양쪽을 동시에 진행을 해야 한다.
  - 처리량이 균등하게 분할돼 잇지 않으면 서버별 처리양에 치우침이 생간다.

### 공유형 아키텍처

단순 분할형과 다르게 일부 계층에서 상호 접속이 이루어진다.

- 장점
  - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
  - 분할한 시스템이 서로 다른 시스템의 데이터를 참조할 수 있다.
- 단점
  - 분할한 시스템 간 독립성이 낮아진다.
  - 공유한 계층의 확장성이 낮이진다.

## 지리 분할형 아키텍처

업부 연속성 및 시스템 가용성을 높이기 위한 방식

### 스탠바이형 아키텍처

스탠바이 구성, HA구성, 액티브-스탠바이 구성으로만 이루어져 있다.

- 최소 두 대 물리 서버가 있어 한대가 고장나면 가동 중인 소프트웨어를 다른 한 대로 옮겨서 운영하는 방식("재시작" = "Failover")
- 장점
  - 물리 서버 고장에 대처를 할 수 있따
- 단점
  - 보통 페일 오버 대상 서비스가 놀고 있는 상태가 되기 때문에 리소스 측면에서 낭비된다.
- 스탠바이를 따로 두지 않고 동시에 교차로 사용하다가, 고장나면 페일 오버를 진행한다.

### 재해 대책형 아키텍처

재해에 대해서 복구 구성을 취하고 있다.

- 서버 장비를 최소 구성 및 동시 구성으로 별도 사이트를 배치하고, 소프트 웨어도 상용 환경과 동일하게 설정한다.
- 데이터는 매일 갱신되야 되기 때문에 저장소 장비 기능, OS기능, 데이터베이스 기능 등 동기 처리를 위한 방법은 여러가지가 있다.
- 각각의 비용, 대상 데이터, 동기 연장 특성 등을 고려하여 결정

<hr>

# 서버

서버는 랙(Lack)이라는 것이 장차괸다, 서버 외에도 HDD가 가득 장착돼 저장소나 인터넷 및 LAN을 연결하기 위한 네트워크 스위치도 탑재

- 서버, 소비 전력, 중량이 매우 중요하다

## 서버의 구성

- 서버와 PC는 물리적으로는 기본 구성이 같다.
- 정눵니 이중화 되어 있고, 대용량 CPU가 탑재 되어 있는 정도가 다르다

## CPU(Central Processing Unit)

- 서버 중심에 위채헛 연산 처리를 실시한다.
- 명령과 데이터는 기억 장치나 입출력 장치를 통해 전달된다.
- CPU를 '코어'라고 하며 하나의 CPU에 여러 개의 '코어'가 존재하는 멀티 코어도 있다.

## 메모리

- 기억 명령을 수행을 한다.
- CPU옆에 위치를 하며 CPU에 전달하는 내용이나 데이터를 저장하거나 처리 결과를 받는다.
- 메모리에 저장되는 정보는 영구성이 없다(서버가 재시작되면 없어진다)
- CPU자체에도 메모리를 존재한다(레지스터 L1/L2 캐시, 빠르지만 용량이 작다)
- 매모리가 여러 단계로 분리가 되어 있다.
  - 고속 CPU는 처리 지연을 허락하지 않는다.
  - 엑세스 속도를 위해서 영역을 여러 단계로 나눈다.
    - 캐시 메모리가 커질 수록 엑세스 속도가 커진다.
  - 그래서 바로 쓸 수 있는 것은 L1, 근처에 두고 싶은 것은 L2에 둔다.

### 메모리 인터리빙(Memory Interleaving)

- 메모리에 데이터를 미리 CPU에 전달하여 처리 지연을 줄이는 기능
- EX)
  - 3개의 채널을 사용하여 데이터 1을 요구하면 2와 3을 같이 보낸다.
  - 데이터가 연속해서 엑세스 된다는 규칙
  - 먼저 읽어서 처리 지연을 줄여 준다.
- 모든 채널의 동일 뱅크에 메모리를 채워야 한다.
- 다단계 구조를 가지고 각각의 엑세스 속도에 맞게 사용되기

## I/O 장치

### HDD

- 서버에서는 메모리에 비해 CPU에서 멀리 떨어진 곳에 HDD가 배치된다.
- 장기 저장 목적의 데이터 저장 장소로 사용한다.
- 전기가 없을 경우 메모리는 사라지지만, 디스크는 유지 된다.
- 자기 원반이 여러개 들어 있어, 고속으로 회전해서 읽기/쓰기를 한다
- 회전 구조 때문에 물리 법칙에 좌우되며, 메모리 처럼 순식간에 엑세스 할 수 없다
- 최근에는 물리적인 회전 요소를 사용하지 않는 SSD를 사용한다
- 하드웨어(스토리지)
  - I/O의 서브시스템이라고 불리는 장치로, 내부에서는 CPU와 캐시가 존재하고 수많은 HDD외에도 여러 기능를 탑재한다.
- 서버와 I/O에서는 HDD가 직접 데이터를 교환하는 것이 아니라 캐시를 이용해서 한다.
  - CPU 캐시와 이용방법이 동일하다 메모리 처럼 고속으로 I/O가 가능하다
- 파이버 채널(Fiber Channel)
  - 대형 저장소와 연결해서 케이블을 애용해서 SAN이라는 네트워크와 연동된다
  - SAN에 접속하기 위한 파이버 채널 인테페이스를 FC 포트라고 한다.
- I/O 읽기
  - 읽기 캐시 경우에는 캐시상에 데이터 복사본만 있으면 된다.
- I/O 쓰기
  - 쓰기 캐시 경우에는 데이터를 기록했다고 간주하는 경우 데이터를 잃을 수 있다.
  - 이러한 쓰기 I/O를 라이트백(Write Back)이라고 한다
- 라이트 스루(Write Through)
  - I/O는 캐시와 HDD에 모두 엑세스 한다.
  - 쓰기에는 디스크를 모두 읽어서 라이트 백과 비교한다
  - 이 경우에는 쓰기 캐시의 장점이 없어진다.
- 기본적으로 캐시의 장점을 살리기 위해 라이트백으로 설정한다

### 네트워크 인터페이스

서버와 외부 장비를 연결하기 위한 것으로 외부 접속용 인터페이스

### I/O 제어

I/O 버스는 PCI의 x8, x16 - I/O 회선의 개수를 의미한다

- 각 CPU/칩섹 구조마다 PCI를 연결할 수 있는 회선이 정해져 있다.
- 단, 각 서버에는 내부적인 사용 용도도 있으므로 외부 연결을 위해 사용할 수 있는 PCI 회전 수는 CPU가 처리할 수 있는 총량보다 적다

-- 이해가 안되서 추가 공부

## 버스

서버 내부에 잇는 컴포넌트들을 서로 연결시키는 회선

- 중요한 점: 버스가 어느 정도의 데이터 전송 능력(대역)을 가지고 있는가

### 대역 (처리량(Throughput))

데이터 전송 능력

- 한번에 데이터를 보낼 수 있는 데이터 전송의 폭(전송폭) X 1초에 전송할 수 있는 횟수(전송횟수)
- 전송 횟수는 '1초 / 1 처리당 소요시간(응답시간)' 으로도 표현한다
- EX) PCI Express 3.0은 1회선당 2GB/s
  - x8은 8회선으로 8배의 능력을 가지고 있다

### 버스 대역

CPU에 가까운 쪽이 1초당 전송량이 크다

- CPU와 메모리는 대량으로 데이터를 교환해서 매우 빠른 전송 능력이 요구 되어서 바로 앞에 위치한다
- USB 3.0 포트는 500MB/s이므로 저속이여서 PCH앞에 배치해도 상관 없다

- EX) 광랜 인터넷 - 최대 1GBps = 12MB/s 대역으로 통신이 가능하다
- 데이터 전송 속도와 전기적 신호 속도가 다르다는 견해로 버스 전송 속도는 기가트랜스러를 사용할 수도 있다
- 버스 흐름에서 가장 중요한 부분은 CPU와 장치 사이에 병목 현상이 없어야 한다.

  - 데이터 전송이 어떤 이유로 막혀 있는 상태가 있으면 안된다

- 예시 다시 공부

## 3계층형 서비스

웹 서버, AP 서버, DB 서버<br>
각각의 서버는 CPU, 메모리, 디스크, NIC/HBA 같은 하드웨어 부품이 나열되어 있다.(물리장치들)

### 프로세스와 스레드

프로세스 및 스레드는 실팽 파일 자체가 아니라 OS상에서 시행돼서 어느정도 독립성을 가지고 동작한다

- 활동하기 위해서는 메모리 공간이 필요하고 커널에 의해 메모리 상으로 확보가 된다
- 메모리 공간을 통해서 데이터를 주고 받고 사용할 수 있다
- 메모리 공간은 프로세스 시작 시에 공간이 확보가 된다

프로세스의 시작

1. OS상에서 프로세스가 시작돼서 사용자 요청을 받을 수 있다.
2. 시작 의뢰가 있으면 커널이 프로세스를 요청하고 요청 분량만큼 메모리를 할당한다
3. 프로그램은 서버 내부의 디스크 상에 설치된다

프로세스와 스레드 메모리 공간의 차이

- 하나의 프로세스사 동작하고 있으면 메모리 공간을 점유하는 스레드 하나가 동작하고 있다.
- 각 스레드는 메모리 공간을 공유한다. 스레드 시작시에는 신규 메모리 공간은 필요 없지만, 다른 스레드에 이상이 발생하면 영향을 받는다.

웹서버: Htptpd 프로세스들로 이루어져 있다 <br>
AP서버: 스레드들이 하나의 메모리 공간을 공유하고 있다.<br>
DB서버: 공유메모리들이 존재하고 여러 포르세스들이 참조한다<br>

1. 오라클 DB는 각 프로세스별 메모리(PGA), 전체가 공유하는 메모리(SGA)가 나누어져 있다.
2. SGA는 디스크상의 데이터 캐시나 실행 완료된 SQL 캐시, 테이블 인덱스 등이 저장
3. PGA는 해당 프로세스 SQL이 이용하는 소트 영역이나 테이블 결합에 사용하는 메모리 영역이 저장된다(다른 메모리 접근 불가)

프로세스와 스레드의 차이점
||장점|단점|
|---|---|---|
|프로세스|개별 처리 독립성이 높다|생성시 CPU 부하가 높다|
|스레드|생성시 CPU 부하가 낮다| 메모리 공간을 공유하기 때문에 원하지 않는 데이터를 읽을 수 있다|

- 프로세스는 연결 풀링(Pooling)이라는 것을 통해서 미리 생성하여 생성 부담을 낮춘다
- 프로세스별 독자 메모리 영역도 있어서 용도별로 나누어서 사용한다.
  - 캐시로 저장하고 있는 데이터는 공유 메모리상에 둔다

## OS 커널
