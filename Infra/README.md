# Infra(인프라)

IT 인프라 - IT의 기반으로 되어 있는 방대한 데이터들을 관리<br>
인프라 아키텍처 - IT인프라의 구조

## 아키텍처의 종류

### 집약형 아키텍처

해당 주요 업무들을 모두 한대로 처리를 하는 작업

- 리소스 관리 -> 고부하 처리 요구가 왔지만 다른 처리에 영향을 주지 않는다.
  - 하나의 처리가 실수로 대령의 요청을 보내더라도 다른 처리에 영향을 주지 않는다.
- 이중화 -> CPU 하나가 망가져도 멈추지 않는다.
- '기간 시스템'으로 불리는 업무 시스템에서 이용하고 있는 경우가 많다.(은행의 계정시스템)
- 장점
  - 한 대의 대형 컴퓨터만 있으면 되므로 구성이 간단하다
  - 대형 컴퓨터의 리소스 관리나 이중화에 의해 안정성이 높고 고성능이다
- 단점
  - 대형 컴퓨터의 도입 비용과 유지비용이 비싸다
  - 확장성의 한계가 있다

### 분할형 아키텍처

여러 대의 컴퓨터를 조합하여 하나의 시스템을 구축하는 구조

- 소형 컴퓨터도 성능을 구현할 수 있지만 여러개를 묶어서 더 특화 시킨다
- 장점
  - 낮은 비용으로 시스템을 구축할 수 있다.
  - 서버 대수를 늘릴 수 있어서 확장성이 좋다
- 단점
  - 대수가 늘아나면 관리 구조가 복잡해진다.
  - 한 대가 망가지면 영향 범위를 최소화 하기 위한 구조를 검토해야 한다.

### 물리 서버 VS 논리 서버

서버 - 분할형 아키텍처에서 이용되고 있는 컴퓨터, 컴퓨터 자체(물리) 혹은 동작하는 소프트웨어(논리)를 의미

- 웹 서버: 인터넷 접속시 HHTML 생성을 담당하는 것 / DB 서버: 대량의 데이터를 저장해서 요청에 따라 데이터를 제공하는 것
  <br>
  컴퓨터 자체를 가리키는 경우 - '물리 서버'라고 부른다

## 수직 분할형 아키텍처

- 각각의 서버가 유사한 작업을 하는지, 전혀 다른 작업을 하는지에 따라 나뉘게 된다

### 클라이언트 - 서버형 아키텍처

수직 분할형 서버

- 킅라이언트는 소형 컴퓨터(PC), 스마트 폰에 설치
- 서버는 업무 애플리케이션, 미들웨어, 데이터베이스 등의 소프트웨어를 '물리 서버' 상에서 구현
- 클라이언트 측에서 전용 소프트 웨어를 설치하고 사용을 해야 한다.(즉, 정기적인 업데이트가 필요)
- 장점
  - 클라이언트 측에서 많은 처리를 실행 할 수 있어서 소수의 서버로 다수의 클라이언트 처리 가능
- 단점
  - 클라이언트 측의 소프트웨어 정기 업데이트가 필요하다
  - 서버 확장성의 한계가 발생할 수 잇다.

### 3계층형 아키텍처

수직 분할형 서버

- 프레젠테이션 계층
  - 사용자 입력을 받는다
  - 웹 브라우저 화면을 표시한다
  - 주로 웹 서버를 의미한다
- 애플리케이션 계층
  - 사용자 요청(Request)에 따라 업무를 처리한다.
  - 비즈니스 록직을 주로 처리한다
  - 동적인 데이터를 제공한다
- 데이터 계층
  - 애플리케이션 계층의 요청에 따라 입출력을 한다.
- 장점
  - 서버 부하 집중 개선
  - 클라리언트 단말의 정기 업데이트가 불필요
  - '처리 반환'에 의한 서버 부하 저감
  - 웹 디자이너, 소프트웨어 엔지니어, DB 관리자가 역할 분담을 하여 일을 효율적으로 할 수 있다
- 단점
  - 구조가 클라이언트-서버보다 복잡하다

## 수평 분할형 아키텍처

용도가 같은 서버를 늘려나가는 방법<br>
대수가 늘어나면서 한 대가 시스템에 주는 영향력이 낮아진다.<br>
또한, 처리를 담당하는 서버 대수가 늘어나면 전체적인 성능 향상도 실현할 수 있다.

### 단순 분할형 아키텍처

"Sharding(샤딩)" 혹은 "Partitioning(파니셔닝)" 이라고 부른다.

- 시스템이 둘로 분할 됨으로써 시스템의 전체 처리 성능을 두배로 향샹 시클 수 있다.
- 두개의 독립적인 시스템이 생성되기 때문에 서로 장애의 영향을 받지 않는다.
- 장점
  - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
  - 분할된 시스템이 독립적으로 운영되므로 서로 영향을 주지 않는다.
- 단점
  - 데이터를 일원화 해서 볼 수 없다.
  - 애플리케이션 업데이트는 양쪽을 동시에 진행을 해야 한다.
  - 처리량이 균등하게 분할돼 잇지 않으면 서버별 처리양에 치우침이 생간다.

### 공유형 아키텍처

단순 분할형과 다르게 일부 계층에서 상호 접속이 이루어진다.

- 장점
  - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
  - 분할한 시스템이 서로 다른 시스템의 데이터를 참조할 수 있다.
- 단점
  - 분할한 시스템 간 독립성이 낮아진다.
  - 공유한 계층의 확장성이 낮이진다.

## 지리 분할형 아키텍처

업부 연속성 및 시스템 가용성을 높이기 위한 방식

### 스탠바이형 아키텍처

스탠바이 구성, HA구성, 액티브-스탠바이 구성으로만 이루어져 있다.

- 최소 두 대 물리 서버가 있어 한대가 고장나면 가동 중인 소프트웨어를 다른 한 대로 옮겨서 운영하는 방식("재시작" = "Failover")
- 장점
  - 물리 서버 고장에 대처를 할 수 있따
- 단점
  - 보통 페일 오버 대상 서비스가 놀고 있는 상태가 되기 때문에 리소스 측면에서 낭비된다.
- 스탠바이를 따로 두지 않고 동시에 교차로 사용하다가, 고장나면 페일 오버를 진행한다.

### 재해 대책형 아키텍처

재해에 대해서 복구 구성을 취하고 있다.

- 서버 장비를 최소 구성 및 동시 구성으로 별도 사이트를 배치하고, 소프트 웨어도 상용 환경과 동일하게 설정한다.
- 데이터는 매일 갱신되야 되기 때문에 저장소 장비 기능, OS기능, 데이터베이스 기능 등 동기 처리를 위한 방법은 여러가지가 있다.
- 각각의 비용, 대상 데이터, 동기 연장 특성 등을 고려하여 결정

<hr>

# 서버

서버는 랙(Lack)이라는 것이 장차괸다, 서버 외에도 HDD가 가득 장착돼 저장소나 인터넷 및 LAN을 연결하기 위한 네트워크 스위치도 탑재

- 서버, 소비 전력, 중량이 매우 중요하다

## 서버의 구성

- 서버와 PC는 물리적으로는 기본 구성이 같다.
- 정눵니 이중화 되어 있고, 대용량 CPU가 탑재 되어 있는 정도가 다르다

## CPU(Central Processing Unit)

- 서버 중심에 위채헛 연산 처리를 실시한다.
- 명령과 데이터는 기억 장치나 입출력 장치를 통해 전달된다.
- CPU를 '코어'라고 하며 하나의 CPU에 여러 개의 '코어'가 존재하는 멀티 코어도 있다.

## 메모리

- 기억 명령을 수행을 한다.
- CPU옆에 위치를 하며 CPU에 전달하는 내용이나 데이터를 저장하거나 처리 결과를 받는다.
- 메모리에 저장되는 정보는 영구성이 없다(서버가 재시작되면 없어진다)
- CPU자체에도 메모리를 존재한다(레지스터 L1/L2 캐시, 빠르지만 용량이 작다)
- 매모리가 여러 단계로 분리가 되어 있다.
  - 고속 CPU는 처리 지연을 허락하지 않는다.
  - 엑세스 속도를 위해서 영역을 여러 단계로 나눈다.
    - 캐시 메모리가 커질 수록 엑세스 속도가 커진다.
  - 그래서 바로 쓸 수 있는 것은 L1, 근처에 두고 싶은 것은 L2에 둔다.

### 메모리 인터리빙(Memory Interleaving)

- 메모리에 데이터를 미리 CPU에 전달하여 처리 지연을 줄이는 기능
- EX)
  - 3개의 채널을 사용하여 데이터 1을 요구하면 2와 3을 같이 보낸다.
  - 데이터가 연속해서 엑세스 된다는 규칙
  - 먼저 읽어서 처리 지연을 줄여 준다.
- 모든 채널의 동일 뱅크에 메모리를 채워야 한다.
- 다단계 구조를 가지고 각각의 엑세스 속도에 맞게 사용되기

## I/O 장치

### HDD

- 서버에서는 메모리에 비해 CPU에서 멀리 떨어진 곳에 HDD가 배치된다.
- 장기 저장 목적의 데이터 저장 장소로 사용한다.
- 전기가 없을 경우 메모리는 사라지지만, 디스크는 유지 된다.
- 자기 원반이 여러개 들어 있어, 고속으로 회전해서 읽기/쓰기를 한다
- 회전 구조 때문에 물리 법칙에 좌우되며, 메모리 처럼 순식간에 엑세스 할 수 없다
- 최근에는 물리적인 회전 요소를 사용하지 않는 SSD를 사용한다
- 하드웨어(스토리지)
  - I/O의 서브시스템이라고 불리는 장치로, 내부에서는 CPU와 캐시가 존재하고 수많은 HDD외에도 여러 기능를 탑재한다.
- 서버와 I/O에서는 HDD가 직접 데이터를 교환하는 것이 아니라 캐시를 이용해서 한다.
  - CPU 캐시와 이용방법이 동일하다 메모리 처럼 고속으로 I/O가 가능하다
- 파이버 채널(Fiber Channel)
  - 대형 저장소와 연결해서 케이블을 애용해서 SAN이라는 네트워크와 연동된다
  - SAN에 접속하기 위한 파이버 채널 인테페이스를 FC 포트라고 한다.
- I/O 읽기
  - 읽기 캐시 경우에는 캐시상에 데이터 복사본만 있으면 된다.
- I/O 쓰기
  - 쓰기 캐시 경우에는 데이터를 기록했다고 간주하는 경우 데이터를 잃을 수 있다.
  - 이러한 쓰기 I/O를 라이트백(Write Back)이라고 한다
- 라이트 스루(Write Through)
  - I/O는 캐시와 HDD에 모두 엑세스 한다.
  - 쓰기에는 디스크를 모두 읽어서 라이트 백과 비교한다
  - 이 경우에는 쓰기 캐시의 장점이 없어진다.
- 기본적으로 캐시의 장점을 살리기 위해 라이트백으로 설정한다

### 네트워크 인터페이스

서버와 외부 장비를 연결하기 위한 것으로 외부 접속용 인터페이스

### I/O 제어

I/O 버스는 PCI의 x8, x16 - I/O 회선의 개수를 의미한다

- 각 CPU/칩섹 구조마다 PCI를 연결할 수 있는 회선이 정해져 있다.
- 단, 각 서버에는 내부적인 사용 용도도 있으므로 외부 연결을 위해 사용할 수 있는 PCI 회전 수는 CPU가 처리할 수 있는 총량보다 적다

-- 이해가 안되서 추가 공부

## 버스

서버 내부에 잇는 컴포넌트들을 서로 연결시키는 회선

- 중요한 점: 버스가 어느 정도의 데이터 전송 능력(대역)을 가지고 있는가

### 대역 (처리량(Throughput))

데이터 전송 능력

- 한번에 데이터를 보낼 수 있는 데이터 전송의 폭(전송폭) X 1초에 전송할 수 있는 횟수(전송횟수)
- 전송 횟수는 '1초 / 1 처리당 소요시간(응답시간)' 으로도 표현한다
- EX) PCI Express 3.0은 1회선당 2GB/s
  - x8은 8회선으로 8배의 능력을 가지고 있다

### 버스 대역

CPU에 가까운 쪽이 1초당 전송량이 크다

- CPU와 메모리는 대량으로 데이터를 교환해서 매우 빠른 전송 능력이 요구 되어서 바로 앞에 위치한다
- USB 3.0 포트는 500MB/s이므로 저속이여서 PCH앞에 배치해도 상관 없다

- EX) 광랜 인터넷 - 최대 1GBps = 12MB/s 대역으로 통신이 가능하다
- 데이터 전송 속도와 전기적 신호 속도가 다르다는 견해로 버스 전송 속도는 기가트랜스러를 사용할 수도 있다
- 버스 흐름에서 가장 중요한 부분은 CPU와 장치 사이에 병목 현상이 없어야 한다.

  - 데이터 전송이 어떤 이유로 막혀 있는 상태가 있으면 안된다

- 예시 다시 공부

## 3계층형 시스템

웹 서버, AP 서버, DB 서버<br>
각각의 서버는 CPU, 메모리, 디스크, NIC/HBA 같은 하드웨어 부품이 나열되어 있다.(물리장치들)

- 계층(Tier): 컴포넌트들의 물리적인 분리
- 층(Layer): 컴포넌트들의 논리적인 분리

### 1계층 구조

- 한 클라이언트 컴퓨터에 3가지 로직을 다 구현한 것
- 한 클라이언트 서버에서 모든 걸 지원하므로 한 가지 로직을 바꾸려면 다른 로직도 바꿔야 한다

### 2계층 구조

- Client Tier와 Data Tier로 2개의 물리적 컴퓨터로 구분된다.
- 클라이언트와 서버를 분리하여 어플리케이션과 데이터베이스가 분리되어 있기 때문에 데이터베이스의 변경이 편리한 장점을 가지고 있다

### 3계층 구조

- 2계층에 비해서 개발 편의정은 더 복잡해진다
- 동일한 비즈니스 로직을 필요로 하는 프레젠테이션 로직을 다양하게 구현할 수 있다
- 비즈니스 로직을 모듈화하여 클라이언트 / 서버 환경과 웹 환경에서 동시 사용 가능
- 동시 사용자 수가 증가해도 일정한 응답 속도와 처리량을 보장한다
- 미들웨어에서 부하 분산, 큐잉 메커니즘을 통해 효율적으로 자원을 활용한다
- 처리되고 있는 애플리케이션 정보, 프로그램별 처리 건수 등 다양하게 모니터링이 가능하다

- 장점
  - 신속한 개발: 각 계층이 서로 다른 팀에서 개발될 수 잇으므로 빠르게 시장에 출시할 수 있다
    - 각각 팀에서 원하는 언어와 툴을 사용하면서 개발할 수 있다
  - 확장성 개선: 필요에 따라 임의의 계층을 다른 계층과 독립적으로 확장할 수 있다
  - 안정성 향상: 한 계층의 가동 중단은 다른 계층을 가용성 또는 성능에 별로 영향을 미치지 않는다
  - 보안성 강화: 프레젠테이션 계층과 데이터 계층이 직접 통신할 수 없으므로, 내부 방화벽의 일종이 작동하여 SQL 인젝션, 기타 악의적 행위를 방지할 수 있다

쿠키: 클라이언트 로컬에 저장되는 Key-Value쌍의 작은 데이터 파일

- 쿠키 이름, 값, 만료 시간, 전송할 도메인 명, 전송할 경로, 보안 연결 여부, HttpOnly여부

1. 클라이언트가 서버에 로그인 요청
2. 서버는 클라이언트 요청의 유효성을 확인하고 응답헤더에 set-cookie에 추가 하여 응답
3. 클라이언트는 이후 서버에 요청할 때 전달받은 쿠키를 자동으로 요청 헤더에 추가하여 요청

세션: 브라우저가 종료되기 전까지 클라이언트의 요청을 유지하게 해주는 기술

1. 클라이언트가 서버에 로그인 요청
2. 서버는 클라이언트의 요청의 유효성을 확인하고 unique한 id를 sessionid 이름으로 저장
3. 서버가 응답할 때 응답 헤더에 set-cookie: sessionId:qwefasd를 추가
4. 클라이언트는 이후 서버에 요청할 떄 전달받은 sessionId 쿠키를 자동으로 요청 헤더에 추가한다
5. 서버에서는 요청 헤더에 sessionId값을 저장된 세션 저장소를 찾아보고 유효한지 확인 후 요청을 처리하고 응답

Web Server: http를 다루기 위한 미들 웨어

- 주로 웹 페이지를 클라이언트에 전달하는 역할을 하게 된다
- 그림, CSS, 자바 스크립트를 포함한 HTML 문서가 클라이언트로 전달이 된다
- 특징
  - 직렬 / 병렬 - 멀티 스레딩 - 스레드 풀
  - 큐, 캐시, 압축
  - APP가 없어도 바로 가능하다
- 공통적이고 핵심적인 내용을 http 요청을 안정적으로 처리할 수 있는 서버
- 웹 서버는 HTTP만 전문적으로 받는다

- WAS와의 차이
  - Web Server: HTTP 프로토콜을 기반으로 하여 클라이언트의 요청을 서비스하는 기능
  - WAS: DB 조회나 로직 처리를 요구하는 동적인 컨텐츠를 제공하기 위해 만들어진 Application Server
    - WAS = Web Server + Web Container
    - Web Container: Servlet, JSP를 실행할 수 있는 소프트웨어
      - Web Server에서 JSP를 요청하면 Web Container에서는 JSP 파일을 Serlvet 파일로 변환 한뒤 컴파일하여 실행 결과를 Web Server에 전달

APP Server: 실제 구현 비즈니스 로직을 위한 서버

httpd: HTTP PROTOCOL을 지원하는 Daemon, 즉, HTML 파일을 전송해주는 규약

- FTP를 지원하는 daemon은 ftpd이며, telnet을 지원하는 daemon은 telentd이다
- 즉, http를 지원하는 서버이며, Web Server를 구축한다는 말은 httpd를 수행하는 말과 같다
- EX) Apache Server도 Linux의 기본 httpd이다
- background에서 Apache를 받아들이고 동작을 해석한다
  - 해석 결과를 다시 Apache에게 전달한다
  - Apache가 내부적으로 httpd를 실행할 수 있도록 되어 있다
- 즉, http의 프로토콜을 받아드리고 http요청을 보낼 수 있도록 하는 구현체
  - Apache에서는 httpd를 구현하였고 다른 서버에서는 다른 이름으로 존재한다
- 즉, Web Server는 http를 다루기 위한 웹 서버이다

daemon: 서비스의 요청에 대해 응답하는 오랫동안 실행중인 백그라운드(background) 프로세스다.

- 유닉스(리눅스 포함) 운영체제에서 이름이 "d"로 끝나는 프로세스(inetd, httpd, nfsd, sshd, named, lpd 등)이다.
- 부팅 때 자동으로 켜져 백그라운드에서 계속 실행되면서 꺼지지 않고 실시간으로 클라이언트와 통신을 계속 해야하는 서버 프로세스
- 시스템 구동시키기 위해서 필수적으로 백그라운드에서 돌아야 되는 프로세스

background process: 입력장치에 대해 터미널과 관계를 끊은 모든 프로세스

- 사용자에게 무언가를 키보드를 통해 전달받지 않고 스스로 동작하는 프로세스
- 눈에 보이진 않지만 뒷 지역, 배경(Background)에서 묵묵히 할 일 하는 프로세스

NIC: Network Interface Controller

- LAN의 연결지점으로 제공하기 위해 컴퓨터에 설치하는 어뎁터
- 물리 계층과 데이터 계층서비스를 제공하다
- 장비와 LAN 사이의 통신을 제공한다

### 프로세스와 스레드

프로세스 및 스레드는 실팽 파일 자체가 아니라 OS상에서 시행돼서 어느정도 독립성을 가지고 동작한다

- 활동하기 위해서는 메모리 공간이 필요하고 커널에 의해 메모리 상으로 확보가 된다
- 메모리 공간을 통해서 데이터를 주고 받고 사용할 수 있다
- 메모리 공간은 프로세스 시작 시에 공간이 확보가 된다

프로세스의 시작

1. OS상에서 프로세스가 시작돼서 사용자 요청을 받을 수 있다.
2. 시작 의뢰가 있으면 커널이 프로세스를 요청하고 요청 분량만큼 메모리를 할당한다
3. 프로그램은 서버 내부의 디스크 상에 설치된다

프로세스와 스레드 메모리 공간의 차이

- 하나의 프로세스사 동작하고 있으면 메모리 공간을 점유하는 스레드 하나가 동작하고 있다.
- 각 스레드는 메모리 공간을 공유한다. 스레드 시작시에는 신규 메모리 공간은 필요 없지만, 다른 스레드에 이상이 발생하면 영향을 받는다.

논리 구성<br>
웹서버: OS안에 Httpd 프로세스들로 이루어져 있다 <br>
AP서버: OS안에 스레드들이 하나의 메모리 공간을 공유하고 있다.<br>
DB서버: DB안에 공유메모리들이 존재하고 여러 포르세스들이 참조한다<br>

- 각각의 서버들은 스위치를 경유해서 연결돼 있다

  - 각각의 서버를 보면 CPU, 메모리, 디스크, NIC/HBA 같은 하드웨어 부품이 나열돼 있다

- 오라클 DB에서는 여러 프로세스가 '공유 메모리 공간'을 이용할 수도 있다

1. 오라클 DB는 각 프로세스별 메모리(PGA), 전체가 공유하는 메모리(SGA)가 나누어져 있다.
2. SGA는 디스크상의 데이터 캐시나 실행 완료된 SQL 캐시, 테이블 인덱스 등이 저장
3. PGA는 해당 프로세스 SQL이 이용하는 소트 영역이나 테이블 결합에 사용하는 메모리 영역이 저장된다(다른 메모리 접근 불가)

SGA(System Global Area) - 모든 사용자가 공유 가능하여 사용<br>
PGA(Program Global Area) - 사용자마다 공유하지 않고 개별적으로 사용

- 이와 별도로 프로세스별 독자 메모리 영역도 있어서 용도별로 나누어 사용하고 있다
- 프로세스 간 공유하고 싶은 데이터(캐시를 저장하는 데이터)는 공유 메모리에 둔다

프로세스와 스레드의 차이점
||장점|단점|
|---|---|---|
|프로세스|개별 처리 독립성이 높다|생성시 CPU 부하가 높다|
|스레드|생성시 CPU 부하가 낮다| 메모리 공간을 공유하기 때문에 원하지 않는 데이터를 읽을 수 있다|

## OS 커널

OS에서 커널 자체를 '인프라'이다.

- 하드웨어와 응용 프로그램 간의 인터페이스 역할을 수행한다

  - 유일한 목적: 사용자 수준의 소프트웨어와 하드웨어(CPU, 메모리) 간의 통신을 관리하는 것이다
  - 인터페이스로써 응용 프로그램 수행에 필요한 여러가지 운영체제 서비스를 제공하며, 메모리 주소 공간 등 리소스를 관리한다

- 뒤에서 무슨 일이 벌어지는지 은폐하면서도 편리한 인터페이스를 제공한다
- 커널이 존재하기 때문에 개발자는 하드웨어나 다른 애플리케이션에 끼치는 영향을 의식하지 않고 애플리케이션을 만들 수 있다

### 시스템 콜 인터페이스

프로세스나 스레드로 부터 명령을 받는 인터페이스

- User Mode Application이 kernel Mode로 모드를 변경한 상태에서 OS 운영체제 서비스를 호출하는 것
- 애플리케이션이 OS를 통해 어떤 처리를 하고 싶으면 시스템 콜이라는 명령을 이용해서 커널에 명령을 내린다
  - 시스템 콜: 커널 영역의 기능을 사용자 모드가 사용 가능하도록한다. 즉, 프로세스가 하드웨어에 직접 접근해서 필요한 기능을 사용할 수 있게 해준다
- EX) 디스크상의 데이터를 읽고 싶거나 네트워크 통신을 하고 싶을 때, 새로운 프로세스를 생성하고 싶을 때
- 디스크 읽기 쓰기는 네트워크 읽기 쓰기와 같이 프로세스 관점에서는 동일한 시스템 콜이다

  - 둘 다 커널을 통해서 명령처리 되어서 뒤 프로세스를 인식할 필요가 없기 때문이다

- OS 커널의 역할 6가지
  - 시스템 콜 인터페이스, 프로세스 관리, 메모리 관리, 네트워크 스택, 파일 시스템 관리, 장치 드라이버

### 프로세스 관리

프로세스를 관리한다

- OS상에서 수십, 수백, 수천개의 프로세스를 가동할 수 있다
- 물리 서버는 CPU 코어의 개수가 적는데, 처리 순서를 어떻게 처리할 것인지 결정한다
- 가동되고 있는 프로세스 관리와 CPU 이용 우선순위 등을 스케줄한다

### 메모리 관리

메모리 영역을 관리

- 서버상의 메모리를 단위 크기 블록으로 분할해서 프로세스에 할당한다
- 물리 메모리 공간의 최대치를 고려한다.
- 프로세스가 이용하는 독립 메모리 공간을 확보하거나 상호 간의 참조 영역을 지키기 위해 독립성을 관리하는 등의 메모리 관리 역할을 한다
- 메모리 관리가 없으면 각 프로세스는 자신 이외의 프로세스가 사용하고 있는 메모리 영역을 파악해야 한다

### 네트워크 스택

네트워크를 관리

### 파일 시스템 관리

OS 기능의 하나로서 물리 디스크에 제공된 데이터를 관리하는 기능이다

- 디렉토리 구조제공, 엑세스 관리, 고속화 안정성 기능이 있다
- 프로레스 관점의 파일 시스템
  - 프로세스(스레드)는 편리성 때문에 파일 단위로 생각
  - 파일 시스템은 여러 프로세스가 공유한다
  - 자주 사용하는 내용은 메모리상에서 캐시하고 있다
  - 커널이 파일 시스템의 인터페이스로 동작한다
  - 프로세스는 물리 디스크 구조나 데이터 배치 상태를 의식할 필요가 없다

### 장치 드라이버

디스크나 NIC등의 물리 장치용 인터페이스를 제공한다

- NIC나 디스크는 다수의 제조사가 족자제품을 제공하고 있다.
- 각각에 대응하는 애플리케이션을 개발하는 것은 현실적이지 못하기 때문에 커널은 장치 드라이버를 이용해서 물리장치를 은폐
- 장치 제조사가 OS에 대응하는 장치 드라이버를 제공해서 OS당 표준 장차로서 커널을 경유해 이용할 수 있다

### 커널 구성 방식

1. 모놀로식 커널

- OS의 주요 구성 요소를 모두 하나의 메모리 공간을 통해 제공한다
- 명칭이 가진 의미대로 한 명의 '왕자'가 모든 기능을 제공하고 있다
- Application을 제외한 모든 System(VFS, IPC, File System 등)을 커널이 직접 관리
  - 커널 내부에서 서비스들이 서로 시스템 자원을 공유하며 효율적으로 관리한다
  - OS서비스들을 시스템 콜 형태로 사용할 수 있다
- EX) LINUX OS

2. 마이크로 커널

- 다양한 OS 서비스들을 User Mode에서 처리하는 커널 구조
  - 핵심 서비스(Process / Memory / Network Management)를 제외하고 나머지는 가볍게 만든 최소한의 커널이다
- 기본의 서비스(VFS, IPC, Device Driver)는 커널위에서 개별적인 서버를 존재한다
- 커널의 기능을 최소화 하였기 떄문에 리얼 타임성이 강하다
- 대신 프로세스간 통신 (IPC)을 통해 대부분의 서비스가 수행되도록 하기 떄문에 메시지 전송과 컨텍스트 스위칭이 많이 발생한다
  - 시스템 복잡도가 증가될수록 시스템 부하, 오버헤드가 급격히 증가하도록 만든다
- 프로세스가 각각의 서버 영역에서 수행되기 때문에 하나의 서비스가 오동작을 해도 시스템이 다운되거나, 커널 전체가 패닉 되지 않는다
- 최소한의 기능만 커널이 제공, 그 외 기능은 커널 밖에서 제공한다
- 커널 자체가 작아지기 때문에 더 심플하다
- EX) MAX OS

## 웹데이터 흐름

### 클라이언트 PC부터 웹 서버까지

클라이언트 PC에서 웹 브라우저를 실행해서 웹 서버에 요청을 보내고 AP서버에 질의 하기 까지의 흐름

1. 웹 브라우저가 요청을 발행한다

- 특정 인터넷 사이트를 요청한다

2. 이름 해석을 한다

- 해당 사이트가 어디에 있는지 이름 해석한다
- 이 결과를 가지고 웹 서버에게 요청한다

3. 웹 서버가 요청을 접수한다

- 'httpd' 프로세스가 요청을 접수한다

4. 웹 서버가 동적 콘텐츠인지 정적 컨텐츠인지 확인한다

- httpd 프로세스가 내용을 판단한다
- 정적: 변화가 없는 콘텐츠, html, css, js와 같이 미리 서버를 저장하고 서버의 요청을 바로 응답하는 컨텐츠
  - 실시간으로 변경할 필요가 없는 데이터
- 동적: 서버의 요청마다 결과값을 다르게 부여주는 형식, 사용자가 맞춤형 콘텐츠를 제공할 수 있도록 한다
  - 높은 빈도로 변경되는 데이터

5. 필요한 경로로 데이터를 엑세스 한다

- 정적인 정보이면 디스크로부터 읽는다
- 동적인 정보는 네트워크를 경유해서 다른 서버에 요청을 보낸다

`http://www.naver.com`을 입력하는 것은 HTTP를 이용해서 `www.naver.com` 서버 접속하는 것을 의미한다

서버가 아닌 PC에서의 처리 흐름

- 디스크에서 프로그램을 읽어서 프로세스를 시작하고, 메로리 공간을 확보한다

1. PC 내부도 서버와 거의 같은 구조이다
2. 웹 브라우저도 OS의 '프로세스'로 실행된다
3. 프로그램은 원래 디스크에 저장돼 있다. 이것을 읽어서 메모리에 상주시키고 실행하는 OS이다
4. 웹 브라우저 화면에서 링크를 클릭하면 웹 서버로 요청을 보낸다
5. 이것도 OS의 '시스템 콜'로 실행되고, 커널을 통해 NIC에 네트워크 통신이 요청된다
6. 네트워크 경유로 웹 서버에 질의를 한다

이름 해석(Name Resolution): 웹 브라우저가 서버를 확인하는 과정

- 인터넷 상 주소는 IP로 되어 있어 문자열 URL과 IP를 연결시켜야 한다

1. 웹 브라우저는 IP 주소를 일단 모른다
2. OS의 호스트명, IP 주소 변환 테이블을 참조해서 존재하지 않는 경우, 외부의 DNS서버에 요청을 던진다

- DNS 서버에 호스트명이 아닌 IP주소로 지정돼 있는 것은 이 때문이다

3. 전 세계에 있는 DNS 서버는 Root DNS를 기준으로 트리 구조로 돼있다

- 개별 DNS 서버는 정기적으로 부모 DNS서버에서 데이터를 받아서 최신 IP주소 목록을 유지한다

4. IP 주소 검색 결과가 반환된다

- 웹 서버의 역할은 HTTP 요청에 대해 적절한 파일이나 콘텐츠를 반환
- HTTP(HyperText Transfer Protocol)의 프로토콜을 가리킨다
- 웹 서버에는 Http를 처리할 수 있는 'httpd 프로세스'가 가동되고 있다.
- 부모/자식 프로세스 중에서는 자식 프로세스가 HTTP 요청을 접수한다

### 웝 서버부터 AP서버 까지

'동적 컨텐츠'를 수행하는 것이 AP서버이다

- 즉, 아직 존재하지 않는 콘텐츠를 가능한 빨리 만들어내는 역할
- 자바를 이용한 AP서버에서는 JVM이 동작한다

1. 웹 서버로부터 요청이 도착한다

- 웝 서버에서 온 요청은 NIC를 경유해서 커널에 의해 끼어들기 처리한다

2. 스레드가 요청 받으면 자신이 계산 가능한지, DB 접속이 필요한지 판단

- 스레드가 요청을 접수한다

3. DB 접속이 필요한 연결 풀에 엑세스 한다

- 동적 데이터를 가져오기 위해 연결 풀이용한다

4. DB에 보내는 접속 요청도 시스템 콜을 사용한다
5. 네트워크 경유로 DB서버에 대한 질의가 이루어진다

- AP서버가 DB서버에 접속하기 위해서 '드라이버'가 필요하다
- 커널의 장치 드라이버와 비슷하다

- 자주 갱신되지 않고 규모가 작은 경우에는 JVM 내부에 캐시로 저장해 두었다가 반환하는 것이 좋다
- 규모가 매우 큰 경우에는 DB서버 외에 CDN(Content Delivery Network)이라 불리는 데이터 전송 전용 서버를 이용한 경우도 있다
  - 대량의 데이터를 전송에 특화 되어 있다, 복사본(캐시)를 배치하는 기술과 병렬 기술을 활용해서 처리를 효율화한다

### AP서버 부터

오라클 DB인 경우 서버가 요청을 접수한다. 요청은 SQL을 통해서 이루어진다

1. AP서버로 부터 요청이 도착한다

- DB서버에서는 DB프로세스가 요청을 접수한다

2. 프로세스가 요청을 접수하고 캐시가 존재하는지 확인한다

- 이전에 사용한 정보는 캐시에 있기 때문에 이 정보를 찾기 위해 일단 공유 메모리를 검색한다

3. 캐시가 없으면 디스크에 엑세스 한다

- 공유 메모리에 데이터가 존재하지 않기 때문에 디스크에서 읽는다
- 이전과 같은 방식으로 시스템 콜을 경유해서 디스크에 요청한다

4. 디스크가 데이터를 반환한다

- 디스크의 데이터는 요청을 보낸 프로세스로 반환된다

5. 데이터를 캐시 형태로 저장한다

- 한번 엑세스한 데이터는 메모리에 캐시 형태로 저장되고 이후 엑세스 시에 재사용 된다

6. 결과를 AP 서버에 반환한다

- 요청을 보낸 AP서버로 데이터를 반환한다

- 웹 서버에서는 개뱔 프러세스가 독립된 형태로 동작하지만, DB서버에서는 여러 개의 프로세스가 역할을 분담하는 경우가 있다
  - 서버 프로세스: SQL의 요청을 받아서 데이터를 검색 가공한다, 디스크에서 메모리를 읽거나 메모리에 캐시를 저장하는 역할도 한다
  - 백그라운드 프로세스: 메모리 상의 차이 정보(REDO)을 관리하거나 데이터를 디스크에 반영하는 일을 한다
  - 개별 서버 프로세스가 아닌 공유화를 통해 효율성 및 비동기성을
- 저장장치에는 다수의 디스크가 설치되어 있다
  - 본질적인 구조는 거의 차이가 존재하지 않는다
  - 메모리에는 데이터를 캐시 형태로 저장하는 구조도 있다

### AP서버에서 웹 서버까지

DB서버에서 데이터가 돌아왔기 떄문에 AP서버의 요청 스레드로 결과가 반환된다

1. DB서버로 부터 데이터가 도착한다

- DB서버에서 돌아온 데이터는 NIC 경유로 원래 스레드로 반환이 된다

2. 스레드가 데이터를 가지고 계산 등을 한 후에 파일 데이터를 생성한다

- DB데이터, JVM의 캐시, 데이터 등을 이용하여 계산 처리, 집계 처리등이 이루어지고 특정 형태의 파일이 생성된다

3. 결과를 웹 서버로 반환한다

- 웝 서버로 데이터들이 반환된다
- 주로 HTML, XML을 이용하거나 동적 이미지 등의 바이너리 데이터를 반환할 수도 있다
- HTTP로 전송 가능한 데이터라면 어떤 형태의 데이터든지 상관없다

### 웝서버에서 클라이언트 PC까지

AP서버에서 돌아온 데이터를 받아서 웹 서버의 httpd 프로세스가 PC의 웹 브라우저로 반환된다

1. AP서버로 부터 데이터가 도착한다

- AP서버에서 돌아온 데이터는 NIC 경우로 원래 스레드에 반환

2. 프로세스는 받은 데이터를 그대로 반환한다

- 필요한 데이터 가공은 모두 AP서버에서 이루어진다 => 그대로 반환한다

3. 결과가 웹 브라우저로 반환되고 화면에 표시된다

- 요청한 데이터를 웹 브라우저로 반환된다
- 웹페이지는 HTML과 다수의 이미지 파일등이 있기 때문에 복수의 요청으로 분할돼서 웹서버에 도착하고, 요청별로 데이터를 반환한다

### 전체 경로

클라이언트 PC -> 웹 서버

1. 웹 브라우저가 요청을 발행

- PC의 웹 브라우저에서 OS의 프로세스를 실행한다
- OS의 시스템 콜을 통해서 커널을 통해 네트워크 통신을 요청

2. 이름 해석을 한다

- DNS 서버에 저장되어 있는 최신 IP주소를 받는다

3. 웹 서버가 요청을 접수한다

- 웹서버, Apache 같은 경우 httpd 프로세스가 http 요청을 판단한다

4. 웹 서버가 정적 콘텐츠인지, 동적 콘텐츠인지 판단한다

- html, css와 같은 정적 컨텐츠는 반환한다
- 동적 컨텐츠가 있는 경우는 AP 서버에 데이터를 요청을 하게 된다

5. 필요한 경로로 데이터를 엑세스 한다

웹 서버 -> AP 서버

6. 동적 컨텐츠를 소화하기 위해 웹 서버로 부터 요청이 도착한다

- JVM이라는 하나의 큰 프로세스에서 하나의 스레드가 요청 받는다
- NIC를 경유하여 커널에 의해 끼어들기 처리 된다

7. 스레드가 요청을 받으면 자신이 계산할 지, DB 접속이 필요한지 판단한다

- AP 서버의 결과를 HTML 등으로 정리하여 반환

8. DB 접속이 필요하면 연결 풀에 엑세스 한다

- DB 접속을 하기 위한 드라이버를 통해서 연결
- 시스템 콜을 이용하여 요청한다
- 데이터베이스 풀이 꽉차 있으면 대기한다

9. DB 서버에 요청을 던진다

AP 서버 -> DB 서버 -> AP 서버

10. AP 서버로 부터 요청이 도착한다
11. 프로세스가 요청을 접수하고 캐시가 존재하는지 확인한다

- 메모리에 캐시로 존자하는 데이터와 디스크에 있는 데이터를 정기적으로 동기화 하는 프로세스도 있다
- 분업을 통해 처리량을 향상 시킬 수 있다

12. 캐시에 없으면 디스크에 엑세스 한다
13. 디스크가 데이터를 반환한다
14. 데이터를 캐시 형태로 저장한다
15. 결과를 AP 서버에 반환한다

AP 서버 -> 웹 서버

16. DB서 서버로부터 데이터가 도착한다
17. 스레드가 데이터를 가지고 계산 등을 한 후에 파일 데이터를 생성한다
18. 결과를 웹 서버로 반환한다

웹 서버 -> 클라이언트 PC

19. AP 서버로 부터 데이터가 도착한다
20. 프로세스는 받은 데이터를 그대로 반환한다
21. 결과를 웹 브라우저에 반환되고 화면에 표시한다

### 웹 데이터 흐름 정리

- 공통점

  - 프로세스나 스레드가 요청을 받는다
  - 도착한 요청을 파악해서 필요에 따라 별도 서버로 요청을 보낸다
  - 도착한 요청에 대해 응답한다

- 3계층 시스템은 사용자 요청이 시발점이 되어 다양한 서버로 전달한다
- 자신이 할 수 없는 처리는 다음 서버에서 그 역할을 떠넘긴다
- 요청 기반 아카텍처이기 떄문에 각 서버는 '문을 열고 기다리고 있는' 상태이다

## 가상화

컴퓨터 시스템에서 물리 리소스를 추상화 하는 것

- 한 대의 서버를 여러 대의 논리 리소스 처럼 보이게 하는 기술

### OS

하드웨어를 이식하지 않고 애플리케이션을 사용가능

- OS의 커널에 의해 하드웨어가 추상화되면서, 컴퓨터에 연결된 기억 장치나 네트워크를 통한 데이터 교환이 하드웨어를 의식하지 않고 이루어지고 있다
  - OS가 없으면 하드웨어의 사양을 고려해서 프로그램을 작성해야 한다
    - 메모리 관리, 멀티 태스크, 파일 시스템등도 별도로 구현해야한다
  - OS에 의해 하드웨어가 추상화돼 있다
    - 메모리의 물리 주소, 하드디스크의 물리 주소를 고려하지 않고 프로그램을 개발할 수 있다
- 하나의 컴퓨터에서 동시에 다수의 프로그램이 움직이고 있으므로 OS는 중요하다
- OS가 있어서 가상 메모리를 사용해 프로세스 및 OS 커널의 메모리 공간을 분리한다
  - 하나의 프로그램이 실패한다고 해도 시스템 전체에 영향을 끼치지 않는다

### 가상 머신

1. 호스트 OS형

- 원도우즈나 리눅스 등의 호스트 OS 상에 가상화 소프트웨어를 설치해서 이용
- VMware Server, Microsoft Virtual Server
- 소프트웨어를 에뮬레이터 하는 것으로 성능면에서 제한이 있다

2. 하이퍼바이저형

- 하드웨어상에서 직접 가상화 소프트웨어를 실행하고 그 위에 가상 머신을 동작시키는 기술이다
- VMware vSphere, Hyper-V, Xen, KVM
- 호스트 OS를 거치지 않으므로 호스트형보다 성능이 우사하다
- 완전 가상화
  - 물리 머신상에서 동작하는 OS나 드라이브를 그래도 게스트로 이용할 수 있다
  - 소프트웨어를 에뮬리이션하기 때문에 성능이 저하된다
- 준 가상화
  - 가상 환경에서 동작시키는 게스트 OS마다 준가상화 전용 드라이버나 준 가상화용으로 최적화된 OS커널을 이용해야 한다

### 컨테이너

리소스가 격리된 프로세스

- 하나의 OS상에서 여러 개의 동시에 가동할 수 있다
- 독립된 루트 파일 시스템, CPU/메모리, 프로세스 공간 등을 사용할 수 있다
- 즉 각 컨테이너가 커널 공간을 공유한다
  - 하이퍼바이저 가상화 같은 경우는 각 게스트가 커널 공간을 가지고 있다
- 각 컨테이너는 커널 공간을 공유한다

- chroot: 프로세스가 OS의 루트 디렉터리 아래에 있는 특정 계층에 접근하지 못하도록 하는 기능
  - 하나의 컴퓨터로 상용, 개발 환경을 함께 사용하면 잘못된 파일을 변경하거나 삭제할 위험을 제거

### Docker

애플리케이션 실행 환경을 자동 구축해 주는 '도커 이미지'라는 기술을 클라우드 이외의 환경에서도 사용할 수 있다

- Docker hub라는 도커 이미지를 공유하면서 더 많이 사용할 수 있다

1. 도커 파일을 통해서 도커 이미지를 작성할 수 있다

- 애플리케이션 프레이워크, 애플리케이션 라이브러리, OS이미지

2. 도커 이미지 공개

- 도커 허브에 도커 이미지들을 저장한다

3. 도커 이미지 배포를 한다

장점

- 컨테이너는 호스트 OS와 OS 커널을 공유하므로 컨테이너 실행이나 정지 속도가 빠르다
- 호스트 OS의 커널을 공유하므로 VM만 사용하는 경우와 비교해 한대의 호스트 머신상에서 훨씬 많은 컨테이너 실행 가능
  - 리소스를 한 곳에서 쉽게 관리할 수 있다
- 도커는 라이브러리나 프레임워크 등을 도커 이미지로 묶어서 공유할 수 있는 것
  - 특정 환경에서는 재현되지만 자신의 개발 환경에서는 재현되지 않은 문제가 발생하기 어렵다
  - 버그를 효율적으로 수정할 수 있다

### 클라우드와 가상화 기술

하이퍼바이저 및 컨테이너 등의 가상화 기술들은 AWS(Amazon), GCP(Google), Azure(Microsoft)등에서 사용하고 있다

- 가상 머신 서비스, 컨테이너 서비스, FasaS 서비스나 다른 기타 서비스를 지탱하는 기술로 이용되고 있다

### IaaS, PaaS, SaaS

On-premis: 하드웨어 푸터 어플리케이션까지 모든 것을 사용자가 처리

IaaS(Infrastructure as a Service): 소프트웨어 및 서비스 구축을 위해 인프라만 제공하는 형태

- 서버, 네트워크 , 스토리지, 메모리, CPU 등 가상 인프라를 빌려주는 서비스
- OS, 미들웨어 등은 사용자가 직접 설치 괸리한다

PaaS(Platform as a Service): 소프트웨어 개발 및 관리에 필요한 환경(Platform)을 서비스별, 기능별로 제공<br>

- 애플리케이션 설계, 개발, 테스트, 배포, 호스팅을 포함하며, 애플리케이션, 서비스를 제공하기 위해 필요한 모든 자원을 빌료주는 것
- 개발 및 운영 환경을 포함한 플랫폼을 제공
- 제공된 플랫폼에서 어플리케이션, 서비스 개발에 집중할 수 있다

SaaS(Software as a Service): 서비스 제공자가 서버 등의 기본 인프라는 물론 바로 상ㅇ할 수 있는 애플리케이션 최종 사용자에게 제공하는 서비스

- 클라우드를 통해 제공되는 소프트웨어로 별도의 설치나 전환 과정 없이 퍼블릭 클라우드에 설치되어 있는 애플리케이션
- 서비스를 인터넷을 통해 제공받는 것

## 로드 밸런싱

하나의 인터넷 서비스가 발생하는 트래픽이 많을 때 여러 대의 서버가 분산하여 서버의 로드율 증가, 부하량 속도 저하등을 고려하여 적절히 분산처리하여 해결해주는 서비스

- Scale-up: Server가 더 빠르게 동작하기 위해 하드웨어 성능을 올리는 방법
- Scale-out: 하나의 Server보다는 여러 대의 Server가 나눠서 일을 하는 방법

  - 하드웨어 서버 향상하는 비용보다 서버 한대 추가 비용이 더 작다
  - 여러 대의 Server 덕분에 무중단 서비스를 제공할 수 있다.
  - 여러 대의 Server에 균등하게 Traffic을 분산시켜주는 역할을 하는 것이 `Load Balancer`이다

- NAT
  - 사설 IP주소를 공인 IP 주소로 바꾸는 데 사용하는 통신망의 주소 변조기
- Tunneling
  - 인터넷 상에서 눈에 보이지 않는 통로를 만들어서 통신할 수 있게 한다
  - 데이터를 캡슐화해서 연결된 상호간에만 캡슐화된 패킷을 구별해 캡슐화를 해제할 수 있다.
- DSR(Dynamic Source Routing Protocol)

  - 로브 밸런서 사용시 클라이언트로 되돌아가는 경우 목적지 주소를 스위치 IP 주소가 아닌 클라이언트 IP 주소로 전달
  - 네트워크 스위치를 거치지 않고 클라리언트를 찾아가는 개념

- RR: 서버에 들어온 요청을 순서대로 돌아가면서 배정하는 방식
- 가중지 RR: 서버마다 가중치를 매기고 가중치가 높은 서버에 클라이언트를 우선적으로 배분
- IP 해시 방식: 클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식
- 최소 연결 방식: 가장 적은 연결 상태를 보이는 서버에 우선적으로 트래픽
- 최소 리스폰 방식: 현재 연결 상태, 응답시간을 고려하여 트래픽 배분

- L4: Transport Layer(IP와 Port) Level에서 Load Balancing
  - IP 주소나 포트 번호, MAC 주소, 전송 프로토콜에 따라 트래픽을 나누는 것이 가능하다
  - 데이터의 내용을 복호화할 필요가 없기에 안전하다
- L7: Application Layer(사용자의 Request) Level에서 Load Balancing
  - 애플리케이션 계층(HTTP, FTP, SMTP)에서 로드를 분산하기 떄문에 HTTP 헤더, 쿠키등과 같은 사용자 요청을 기준으로 특정 서버에 트래픽을 분산 가능
  - 패킷의 내용을 확인하고 그 내용에 따른 특정 서버에 분해하는 것이 가능하다
  - 비정상적인 트래픽을 사전에 필터링이 가능하다

## 직렬 / 병렬 처리

특정 기간 내에 하나의 CPU로 처리할 수 있는 양에는 한꼐가 있지만, 여러 개의 CPU를 배치하면 처리량을 늘릴 수 있다

- 다수의 CPU를 이용할 수 있는 처리여야 한다는 전제 조건이 있다
- 병렬 처리후 직렬 처리으로만 할 수 있는 기능인 경우 병목현상과 같은 문제가 발생한다
- 병렬처리할 때는 가능한 직렬화 부분을 줄이고 무리해서 병렬화 하면 한 곳으로 모일 때 오버헤드가 발새생할 수 있다
- 병렬 처리를 통해 속도는 빨라지지 않지만, 단위 시간당 처리량을 늘릴 수 있다

### 웹 서버와 AP서버

- 웹 서버에는 다수의 이용자가 접속하기 때문에 복수의 프로세스가 병렬처리를 하고 있다
  - httpd 프로세스가 병렬화 되면서 사용중이다
- AP 서버에서는 JVM 프로세스는 하나이지만 복수의 스레드가 병렬 처리하고 있다
- CPU가 여러 개를 사용해야 동시에 여러가지를 사용할 수 있다
  - CPU가 하나인데 여러 개의 프로세스를 사용하게 된다면 소용이 없다

### DB 서버

- 클라이언트 요청을 접수하는 서버 프로세스가 클라이언트 접속 수 만큼 생성이 된다
  - 서버에서 멀티 프로세스 모델 외에도 공유 서버형이라 불리는 하이브리드형이 있다

## 동기 / 비동기

동기: 다른 일을 부탁한 후 끝날 때 까지 아무것도 하지 않고 기다린다

- 대신 그 사이에 아무것도 하지 않는다

비동기: 끝날 때 까지 기다리지 않기 때문에 병렬로 다른 일이 가능하다

- 의뢰한 일이 끝났는지 여부를 확인하고 싶으면 별도의 방법을 찾아야 한다

Ajax 통신 - 비동기 통신을 이용한 병렬처리 가능

- 화면을 보거나 입력 하면서 필요한 부분만 갱신이 가능하다

## 큐

FIFO 원리

사용하는 위치

- CPU 처리를 기다리고 있는 프로세스나 스레드 행렬
- 하드 디스크 등의 저장소 읽기 처리를 기다리고 있는 I/O 요구 행렬
- 네트워크 접속 성립을 기다리고 있는 접속 요구 행렬

## 배타적 제어

여러 사람이 공유하고 있는 물건일 경우, 누군가 사용하고 있으면 다른 사람이 사용 못하게 하는 것

- 병렬처리를 하는 동안에 사용하며, 병목현상이 발생할 수 있다

- 복수의 처리가 공유 자원에 동시에 엑세스 하면 불일치가 발생할 수 있기 때문에 배타적 제어로 보호를 해주어야 한다
- 배타적 제저에서는 특정 처리가 공유하고 있는 자원을 이용하고 잇는 동안 다른 처리가 이용할 수 없게해서 불일치가 발생하지 않도록 한다

### OS 커널에서의 배타적 제어

- 여러 프로세스나 스레드에서 빅 커널락을 이용해서 경합처리를 하면, CPU 코어가 여러 개라도 병렬 처리가 안되고 선행처리가 끝날때 자기 기다려야한다

## Stateful, Stateless

상태 저장: 상태를 고려하기 떄문에 복잡한 처리가 가능하지만 시스템 복잡성이 커진다

상태 비저장: 상태를 고려하지 않기 떄문에 간단하며, 성능이나 안정성 측면에서는 우수

컴퓨터 내부 구조에서는 모든 곳에서 상태 저장이 사용된다

- 일반 CPU는 하나의 CPU에서 복수의 프로세스를 조금씩 처리한다
- 처리하지 않는 프로세스는 대기 상태로 있어야 한다

네트워크 통신 구조에서는 HTTP에서는 세션이라는 개념을 해서 구조를 구현한다

- 로그인 등의 인증을 거치면 서버는 그 상태를 저장함과 동시에 인증 완료 세션 정보를 반환한다

## Scaling

### X-axis Scaling

- 로드 밸런서 뒤에서 여러 개의 애플리케이션을 복사본을 실행하는 것
- N개의 복사 본이 있는 경우 각 복사본은 로드의 1/N을 처리한다
- 각 복사본이 모든 데이터를 잡재적으로 액세스 하기 때문에 캐시가 효과적이기 위해서는 더 많은 메모리가 필요하다

### Y-axis Scaling

- 여러 개의 다른 서비스로 분할한다
- 각 서비스는 하나 이상의 밀접하게 관련된 기능을 담당한다
- 두 가지의 방식
  - 동사 기반의 분해를 사용하고 체크아웃과 같은 단일 사용 사례를 구현 서비스 로 정의
  - 명사별로 응용 프로그램을 분해하고 고객관리 등 특정 법인과 모든 운영을 책임지는 서비스이다.

### Z-axis Scaling (추가 공부)

- 각 서버는 동일한 코드 사본을 실행하는 것으로 X-axis Scaling과 비슷
- 각 서버가 데이터의 일부분만 책임을 진다
- 시스템의 일부 구성요소는 각 요청을 적절한 서버로 라우팅할 책임이 있다.
- Z-axis Scaling은 주로 데이터베이스 축적에 사용된다
  - 데이터는 각 레코드의 속성에 기초하여 서버 집합에 걸쳐서 분할 된다
- 장점
  - 각 서버는 데이터의 서브셋만 처리한다
  - 캐시 활용도가 향상되고 메모리 사용량과 I/O 트래픽이 감소한다
  - 요청이 일반적으로 여러 서버에 분산되기 때문에 트랜잭션 확장성도 향상된다
  - Z-axis Scaling은 장애 발생 시 일부만 데이터를 엑세스할 수 있기 때문에 장애 분리를 개선한다
  - RESTORE 테이블의 기본 키는 서로 다른 두 데이터베이스 서버 사이의 행을 분할하는 데 사용한다
- 단점
  - 애플리케이션의 복잡성이 증가한다
  - 데이터를 다시 분할해야 하는 경우 까다로울 수 있는 분할 방식을 구현해야한다
  - 개발 및 애플리케이션 복잡성이 증가하는 문제를 해결하지 못한다

## MSA(MicroService Architecture)

사용하는 이유 (이전의 Monolithic Architecture의 특징)

- 소프트웨어의 모든 구성요소가 한 프로젝트에 통합되어 있는 형태
- 서비스 / 프로젝트가 커지면 커질 수록, 영향도 파악 및 전체 시스템 구조의 파악에 어려움
- 빌드 시간 및 테스트 시간, 그리고 배포 시간이 기아급수적으로 늘어남
- 서비스를 부분적으로 Scale-out하기가 힘들다
- 부분의 장애가 전체 서비스의 장애로 이어지는 경우가 발생하게 된다

MSA

- 각각의 서비스는 크기가 작을 뿐 서비스 자체는 하나의 모놀리틱 아키텍쳐와 유사한 구조를 가짐
- 각각의 서비스는 독립적으로 배포가 가능해야함
- 각각의 서비스는 다른 서비스에 대한 의존성이 최소화 되어야함
- 각 서비스는 개별 프로세스로 구동되며, REST와 같은 가벼운 방식으로 통신되어야 함

장점

- 배포: 서비스별 배포 가능(배포시 전체 서비스의 중단이 없다)
  - 요구사항을 신혹하게 반영하여 배포할 수 있다
- 확장: 특정 서비스에 대한 확장성이 용이함
  - 클라우드 사용에 적합한 아키텍처
- 장애: 장애가 전체 서비스로 확장될 가능성이 적다
  - 부분적 장애에 대한 격리가 수월함
- 신기술 적용이 유연하고 서비스를 다양한 언어로 개발 운영 할 수 있는 장점이 있다

단점

- 성능: 서비스 간 호출시 API를 사용하기 때문에, 통신 비용이나 Latency가 그만큼 늘어나게 된다
- 테스트 / 트랜잭션: 서비스가 분리되어 있기 떄문에 테스트와 트랜잭션 복잡도가 증가
- 데이터 관리: 데이터가 여러 서비스에 분산되기 떄문에 한 번에 조회하기 어렵고, 정합성 또한 관리하기 어렵다

## 네트워크

서로 다른 장비 간 데이터를 교환할 때 기본적으로는 네트워크를 경유해서 데이터를 송수신할 필요할때 사용

### 계층구조

데이터나 기능 호출 흐름에 따라 계층 간 역할이 나누어진다

- 역할이 나누어져 있기 때문에 각 층은 자신이 담당하는 일만 책임진다
- 상호 연결되어 있는 계층들에서는 교환 방법, 즉 인터페이스만 정해주면 된다

- 각 계층을 나눔으로 써, 계층 간에 서로 영향을 주지 않고 독립적으로 동작할 수 있다
- 상호 간에 내부 처리를 은폐하고 있기 대문에 인터페이스만 바꾸지 않으면 각 계층이 내부적인 처리를 마음대로 바꾸어도 문제 없다
- 대신, 작업 효율을 희생해야 한다

### OSI 7계층 모델

OSI통신을 7개의 계층으로 나눈 것

- 이 계층 구조 개념은 다양한 분야에서 공통적으로 참조할 수 있는 '참조 모델'

1. 애플리케이션 계층

- 애플리케이션 처리

2. 프레젠테이션 계층

- 데이터 표현 방법

3. 세션 계층

- 통신 시작과 종료 순서

4. 전송 계층

- 네트워크 통신 관리

5. 네트워크 계층

- 네트워크 통신 경로 선택

6. 데이터 링크 계층

- 직접 접속돼 있는 기간 처리

7. 물리 계층

- 전기적인 접속

- 시스템이 커질수록 역할별로 계층화 하지 않으면 전체 구조가 복잡해진다
- 서버 한 대의 서버 내부를 살펴봐도 역시 계층주어로 되어 있다

하나의 상자로 표시하고 있는 애플리케이션이나 커널 등도 세분화 된 계층으로 나누고 레이어(Layer)으로 불린다

- 자바 애플리케이션, 애플리케이션 서버, JVM, 커널, 하드웨어로 분리된다
  - 커널과 애플리케이션(JVM)은 시스템 콜이라는 인터페이스로 연결되어 있다

## 프로토콜

컴퓨터가 서로 소통하기 위해 정한 규약

- 통신 매체 프로토콜이 다르면 통신이 불가능하다
- 언어 프로토콜과 그 것을 전달하는 프로토콜이 일치를 해야 한다
- 컴퓨터 상에서 떨어져 있는 두 곳의 장비는 사전에 프로토콜알아 두어야 한다
- 브라우저에서 HTTP 프로토콜을 사용해서 서버에게 웹 페이지를 달라고 요청할 때, 전기 신호나 전파를 이용해서 전달
- 네트워크에서는 제조사마다 서로 일치된 프로토콜을 사용한다
  - IEEE(Institute of Electronics Engineers): 전기 통신을 사용한 프로토콜 표존화, 무선 LAN 프로토콜(LAN 공유기)
  - IETF(Internet Engineering Task Force): 인터넷에서 사용하는 다양한 기술 표준화(RFC)
- 통신 매체가 되는 통신 프로토콜이 있고 통합하면 의미를 전달하는 통신 프로토콜이 있다

- 서버 내부의 프로토콜
  - USB와 PC, 저장소에서 데이터 꺼낼때도 다 프로토콜이 있다
  - SCSI: 저장소용 장비 드라이버가 SCSI 등의 프로토콜을 사용해서 데이터 교환을 한다
  - 멀치 코어 CPU들이 서로 소통하기 위해서도 프로토콜이 존재한다

### TCP/IP

인터넷을 포함해서 현재 네트워크의 필수 프로토콜 (TCP/IP Protocol Suite)

- TCP와 IP의 두가지 프로토콜을 주축으로 만들어진 프로토콜

### TCP/IP 계층 구조

- TCP/IP에서는 반드시 7계층이 아니라 4계층(5계층)으로 불리며 1~2 계층을 모아서 링크, 5~7 계층을 모아서 애플리케이션 계층으로 취급하기도 한다
  <br>

웹 서버에서 HTTP라고 하는 프로토콜을 사용할 때의 계층 구조

1. HTTP

- httpd 프로세스를 사용

2. TCP

- 애플리케이션이 의뢰한 데이터를 책임지고 상대방에게 전달

3. IP

- 데이터를 최종 위치까지 전달

4. 이너넷

- 직접 연결돼 잇는 주변 장비에게 전송
  <br>
- HTTP 통신 데이터를 상대방에게 보내기 위해서 TCP 데이터를 건네지만, 이더넷 계층까지는 OS 커널이 담당한다
  - 커널내에서 TCP, IP, 이더넷을 모두 담당하게 된다, 각 담당하는 기능은 필요한 정보를 데이터에 부여해서 최종적으로 이더넷 프레임이 생성된다
  - 이것이 NIC에 전달돼서 이더넷 케이블 등을 통해 인접 노드를 경유해서 최종 위치로 전달
  - 네트워크에 연결된 컴퓨터 등은 호스트 라고 한다
- 통신하고 싶은 애플리케이션은 독자적으로 통신 구조를 만들 필요 없이 TCP/IP에게 위임할 수 있다
- 간단하게 데이터를 보내기 위해서는 TCP 대신 UDP 혹은 무선으로 통신할 수도 있다

명칭

- L2: 링크 계층, 이더넷 계층
- L3: IP 계층
- L4: 전송 계층(TCP)
- L7: 애플리케이션 계층
  - L5, L6, L7을 모아서 애플리케이션으로 취급한다

### HTTP 처리 흐름 in L7

- 애플리케이션을 시작으로 통신이 시작이 된다
- 애플리케이션이 사용하는 모든 프로토콜을 애플리케이션 계층 프로토콜이라고 부른다
- 자신이 통신하는 것이 아니라 통신은 모두 TCP/IP에 맡긴다
- RFC2616에서 HTTP 사용을 정하고 있다

1. 브라우저에 URL을 입력한다
2. 요청이 전송된다
3. 웹 서버에서는 요청이 해석된다
4. 파일이나 이미지를 응답으로 반환한다
5. 파일 내부를 해석해서 이미지 등이 포함돼 있으면 다시 요청을 보낸다

- 추가 이미지나 스크립트 등이 포함돼 있으면 웹 서버에 이들을 계속 요청을 한다

- Request 요청은 명령으로 구성된다
- Response는 요청에 대한 결과와 그에 대한 상태 정보를 가지고 있다

1. 요청: 서버에 대한 요구 명령, 대상 데이터를 지정

- EX) GET/HTTP/1.1

2. Message-header: 브라우저에 상세한 정보를 전달(표시 대응 브라우저, 데이터 형식, 접속 방식)

- EX) User-Agent: Mozli.....

3. Message-Body

- Request: 브라우저에 입력한 내용이 포함된다
- Reponse: HTML 데이터 등 실제 데이터가 저장된다

- HTTP가 그 하위 계층인 IP나 유선을 통해 명령을 보내거나 통신 제어를 하지 않는다

  - 이 때문에 HTTO 요청은 여러가지 명량만으로 구성돼서 매우 간단하다

- 애플리케이션 프로토콜은 사용자 공간을 처리

  - 클라이언트 프로세스와 httpd 프로세스를 통해서 애플리케이션 계층 프로토콜이 http 요청이 통신하는 모습
  - 애플리케이션 자체가 통신구조를 가지지 않고서도 원격지에 있는 서버 애플리케이션과 통신할 수 있다
  - 애플리케이션 계층 프로토콜은 필요한 데이터를 소켓에 기록만 하고, 통신은 TCP/IP에 위임한다

- 소켓 이하는 커널 공간에서 처리
  - 애플리케이션 프로세스는 시스템 콜을 통해서 커널에 TCP/IP 통신을 요청
  - 이때, 접속 대상 서버의 IP 주소와 TCP 포트 두가지 정보가 필요하다
  1. 시스템 콜 경우로 통신하고 싶은 상대를 커널에 지정하고, 소켓이라 불리는 데이터 통로를 만들어 준다
  2. 통신 상대가 보낸 데이터가 소캣을 통해 나온다
  - 이때, 상대방 서버에서도 소켓이 만들어지고 가상 경로가 생성이 된다
  - 실제로는 통신 케이블을 통해서 전송이 되지만, 프로세스 관점에서는 소켓을 통해서 데이터가 통신이 된다
  - 커널이 TCP/IP의 통신 처리를 해서 데이터를 소켓이 넣는 처리를 한다
  - 최종적으로는 NIC로 부터 데이터가 전송이 된다
  - 데이터는 도중에 다양한 경로를 거친다

### 전송계층 프로토콜 in L4 (TCP)

소켓에 기록된 애플리케이션 데이터는 커널 내에서 통신 대상에게 전달하기 위한 준비를 시작한다

- 제일 먼저 임무를 수행하는 것이 전송 계층 프로토콜인 TCP이다
- TCP(Transmission Control Protocol)는 명칭 그대로 전송을 제어하는 프로토콜
  - 애플리 케이션이 보낸 데이터를 그 형태 그대로 상대방에게 확실하게 전달하는 것
  - 담당: 서버가 송실할 때와 서버가 수신한 후 애플리케이션에게 전달할 상태
  - 상대 서버까지 전송하는 부분은 IP에 모두 위임한다
  - 데이터가 상대방에게 확실히 전달됐는지 확인하는 기능이나 도착한 순서를 파악하기 위해서 TCP를 추가한다
- 주요한 기능
  - 포트 번호를 이용해서 데이터를 전송
  - 연결 생성
  - 데이터 보증과 재 전송 제어
  - 흐름 제어와 폭주 제어
- 커널 공간의 TCP 처리 흐름
  - 소켓에 기록된 애플리케이션 데이터는 소켓의 큐를 경유해서 소켓 버퍼라 불리는 메모리 영역에서 처리된다
  - 소켓 버퍼: 소켓 별로 준비된 전용 메모리 영역으로, 이후 계속되는 IP나 이더넷까지의 일련의 처리도 소켓 버퍼 내에서 이루어진다
  - TCP는 Segement단위로 관리하고 있고 애플리케이션 데이터에 TCP 해더를 붙여서 TCP 세그먼트를 작성한다
  - 헤더에는 도착지점 포트 번호를 포함해서 TCP 최대 데이터 크기(MSS)등을 전송한다
    - MSS는 링크 계층을 사용해서 데이터를 전공하기 떄문에 링크 계층의 최대 크기에 의존한다
    - 링크 계층에서 전송할 수 있는 최대 데이터 크기는 MTU이다
- 커널내의 TCP처리
  1. 소켓에 기록된 데이터는 큐를 경유해서 커널 내 네트워크 처리 부분에 전다로딘다
  2. 커널에 전달된 데이터는 '소켓 버퍼'라는 메모리 영역에서 처리된다
  3. 하나의 TCP 세그먼트로 전송할 수 있는 크기는 MSS이고 MSS를 초과한 데이터는 자동적으로 분할돼서 복수의 TCP 세그먼트가 생성된다
  4. 데이터에 TCP 헤더를 붙여서 TCP 세그먼트를 생성한다. TCP 헤더에는 목적 애플리케이션의 포트 번호 신호를 포함해 TCP 기능에 필요한 정보가 기록된다
- 2000바이트의 데이터를 보낼때 MSS가 1460이라면
  - 1460 + TCP 세그먼트, 540 + TCP 세그먼트로 분리해서 데이터를 전송한다
- 포트 번호를 이용한 데이터 전송
  - 상대 서버에 데이터가ㅣ 도착햇다고 해도 어떤 애플리케이션 용 데이터인지 알 수 없다
  - TCP에서는 포트 번호를 사용해서 어떤 애플리케이션에 데이터를 전달할지 사용한다
  - 도착한 TCP 세그먼트의 목적지 포트 번호를 확인해서 맞는 소켓에 데이터를 전달한다
- 연결 생성
  - TCP는 연결형 프로토콜로 연결이라 불리는 가상 경로를 생성한다
  - 상대로 부터 ACK 사인을 받는 순간 통신은 시작이 된다
  - LISTEN: 서버 측 서켓은 자신이 지정한 포트 번호에 통신이 오는지 기다렸다가 받는다
  - 3-hand shaking
    1. 커널 내 TCP 계층에서는 통신 상대 서버에게 가상 경로를 열어 줄 것을 의뢰 한다
    - 그외의 다른 일은 추가로 다른 일은 하지 않는다
    - 데이터 통신 자체도 IP에 위임하기 때문에 물리적인 경로가 막히거나 전원이 꺼져도 TCP 연결은 유지 된다
    2. 통신을 받는 측은 열어도 된다고 응답한다
    3. 마지막으로 한번 확인했다는 메시지를 보낸다
    - 이 과정을 거치면 가상 경로를 생성되고, 송식 측에서도 포트 번호가 설정된 소켓이 열린다
- 데이터 보증과 재전송 제어
  - 수신 측에서 데이터 세그먼트가 도착하면 수신 측은 송신 측에게 도착했다는 것을 알린다
    - 이때 ACK를 반환하며 TCP 헤더에 ACK 정보를 넣은 세그먼트를 반환한다
  - 재전송이 가능하도록 전송이 끝난 TCP 시그먼트라도 ACK 돌아오기 까지 소켓 버퍼를 남겨둘 필요가 있다
  - TCP 세그 먼트에 시퀀스 번호를 붙혀서 구현
    - TCP 헤더에 기록이 되며 TCP 세그먼트가 가지고 있는 데이터가 몇 번째 데이터 인지 기록 한다
    - 2000바이트를 1460으로 나눠서 보낼때
      - 1번은 1
      - 2번은 1461
    - 수신측은 데이터를 조립한다
  - TCP 재 전송 제어
    - ACK 반환 할때, 다음에 필요한 TCP 세그먼트의 시퀀스 번호도 ACK 번호도 저장한다
    - 1461을 보내면서 다음에 필요하 데이터를 보낼 수 있다
    - 3회 중복 돼서 도착하게 되는 경우 도착 하지 않았다고 가정하여 재전송을 한다(중복 ACK)
      - 3회 정도 기다리는 이유는 도중 도착 지연이 있을 수도 있기 때문이다
    - SACK: 상세한 ACK, 이미 도착했다는 정보를 전달할 수도 있다
      - 송신 측은 도착하지 않은 TCP 세그먼트만 선택해서 재 전송할 수 있다
- 흐름 제어와 폭주 제어
  - 수신 측의 수신 윈도우(RWND), 송신 측의 폭주(송신) 윈도우(CWND)
  - 수신 측은 폭주 윈도우 크기를 조정해서 폭주 윈도우와 수신 윈도우 중 작은 쪽을 송신 윈도우로 채택
    - 이 범위 내에서 ACK를 기다리지 않고 전송한다
  - 슬라이딩 윈도우 -- ??
    - 수신 측에서 설정한 윈도우 크기만큼 송신 측에서 확인 응답(ACK) ㅇ벗이 전공할 수 있게 하여 흐름을 동적으로 조절하는 제어 알고리즘
  - 슬로우 스타트: ACK 반환시마다 윈도우 크기를 2, 4식으로 지수 함수적으로 늘려간다
    - 어느 정도 크기가 되면 1씩 늘려가다가 실패를 하게 된다면 폭주 윈도우 크기를 작게 만들어 송신량을 줄인다
  - AMID(Addtivite Increase / Multicative Decrease): 합 증가 / 곱 감소

### Socket 통신

Domain 통신을 하게 될때 기본 값으로 80(http), 443(https)으로 전송, 이때 IP + Port를 통해서 전송으 한다

- Socket을 이용하면 IP와 Port으로 가상의 Layer가 쌓이게 된다
- Clinet에게 요청은 IP..socketA, IP..sockerB를 요청하게 된다
- Web Server에서는 여러 대의 소켓을 만든다 IP..sockerA\`, IP..sockerB\`을 만들어서 통신한다
- 이제 애플리케이션 간에는 소켓이 연결이 된다

- 클라이언트 하나에도 여러개의 소켓을 동시에 연결을 할 수 있다
  - 이때 Web Server는 해당하는 각각의 소켓을 만들게 된다
- 하나의 소켓을 여러개로 나눌 수 있는 방법은 Time Sharing을 통해서 할 수 있다

- 프로세스가 동작 하기 위해서 Port를 열기 위해서 동작하는 Main Thread가 존재한다
  - 각각 의 소켓이 열리게 된다면 각각 따로 Worker Thread가 추가로 열리게 된다

## Proxy

클라이언트가 자신을 통해서 다른 네트워크 서비스에 간접적으로 접속할 수 있게 해주는 컴퓨터 시스템이나 응용 프로그램

### Forward Proxy

클라이언트가 인터넷에 직접 접근하는 게 아니라 Forward Proxy Server가 요청을 받고 인터넷에 연결하여 결과를 전달(forward) 해준다

- Cache를 사용하여 자주 사용하는 데이터라면 요청을 보내지 않고 캐시에서 가져올 수 있기 떄문에 성능 향상이 가능하다

### Reverse Proxy

클라이언트가 인터넷에 데이터를 요청하면 Rever Proxy가 요청을 받아 내부 서버에서 데이터를 받은 후 클라이언트에 전달

- 클라이언트는 내부 서버에 대한 정보를 알 필요 없이 Reverse Proxy에만 요청하면 된다
- 내부 서버(WAS)에 직접 접근 한다면 DB에 접근이 가능하기 떄문에 중간에 리버스 프록시를 두고 클라이언트와 내부 서버 사이의 통신을 담당한다
- 또한, 내부 서버에 대한 설정으로 로드 밸런싱이나 서버 확장등에 유리하다

### 차이점

- Forward Proxy는 클라이언트가 감춰진다
  - 요청 받는 서버는 Forward Proxy Server를 통해서 요청을 받기 때문에 클라이언트의 정보를 알 수 없다
  - 클라이언트가 요청하는 End Point는 실제 서버 도메인이 된다
- Reverse Proxy는 서버가 감춰진다
  - 클라이언트는 Reverse Porxy Server에게 요청하기 때문에 실제 서버의 정보를 알 수 없다
  - 클라이언트가 요청하는 End Point는 Proxy Server의 도메인이 되고 실제 서버 정보는 알 수 없다

## DNS

- Domain을 입력할 때 IP로 바꾸어 주는 과정

1. Domain을 입력하고 자체의 DNS 주소에 IP주소를 요청한다
2. NS에서는 DNS을 확인하고 알고 있는 IP이면 IP를 전송한다
3. IP를 알고 있지 않은 경우 상위 NS 혹은 다른 NS에 IP 주소 값을 찾느다

- 각 Domain 사이트는 각 나라에서 관리를 하고, 글로벌 Domain도 존재한다
- NS에서 사이트를 스누핑 하기 때문에 변경된 IP 주소로 보낼 수 있다
- https는 도착지를 암호화 해서 전송을 했어서 내용이 약간 다르다

  - 현재는 암호회 키를 교환하는 과정을 감청하여 보내게 된다

- 사용자는 각각의 클라이언트는 NS 주소를 가지고 있어서 요청할 수 있다(DNS 주소 설정)

## 안정화 및 이중화

안전성: 시스템 서비스가 가능한 멈추지 않도록 하는 것

1. 고장, 장애에 의한 정지가 발생하지 않고 복구할 수 있는 것 -> 컴포넌트 이중화
2. 고장, 장애가 발생해도 검출할 수 있는 것 -> 컴포넌트 감시
3. 고장, 장애가 발생해도 데이터가 보호될 것 -> 데이터 백업

이중화: 하나의 기능을 병렬로 나열해서 하나에 장애가 발생해도 다른 것을 이용해서 서비스를 계속 할 수 있는 것

- 병렬로 가동되기 때문에 고가용성에 대한 의미뿐만이 아니라 확장성, 부하 분산 같은 성능에 대한 의미도 가진다
- 부하 분산, 내부적 생존 감시, 마스터 결정, 페일 오버 등의 기능이 있다

### FailOver

장애 대비 기능

- 장애가 오면 미리 준비했던 다른 시스템으로 대체해서 운영하는 것

### 서버 내 이중화

- 네트워크 인터페이스 이중화(하드웨어 관점)
  - PCI 슬롯에 꽂은 카드도 이중화 가능
  - 네트워크 인터페이스나 파이버 채널(케이블 꽂는 곳)에는 이중화 기능이다 이중화 실현하는 소프트웨어가 있다
  - 네트워크 컨트롤과 버스를 통해서 분리를 할 수 있다

### 웹 서버 이중화(소프트웨어 관점)

- 클라이언트의 http 프로토콜 요청을 받는 웹 서버
- 아파치에서는 어느쪽이든 미리 여러개를 가동 시켜 두어서 클라이언트 요청에 빠르게 대응할 수 있는 구성을 가지고 있다
- 여러개를 가동시켜 두면 프로세스/스레드 중 하나에 장애가 발생해도 다른 프로세스/스레드가 가동되고 있기 때문에 웹 서버의 서비스 전체가 정지 되는 일이 없다
  - 스레드인 경우에는 하나의 프로세스에서 동작하기 때문에 PID가 일치하다
  - 프로세스이 경우는 PID가 전부 다르다
- 시스템 리소스에 여유가 있으면 가동 프로세스/데몬 수의 최소값 최대값이 같다.
  - 동일 값으로 하면 프로세스나 스레드의 가동/정지 오버헤드를 줄일 수 있다
- 장애가 발생하는 경우(httpd 프로세스가 요청을 받지 못하는 경우) 400번대, 500번대 오류가나오게 된다

1. DNS를 이용한다

- 하나의 호스트명에 대해 복수 IP 주소로 반환하는 것이다
- DNS가 서버 상태를 감시하지 않고 정지해도 주소를 반환하기 떄문에 부적합하다
- 웹 서버에 동적 컨텐츠가 있어 세션 상태를 저장하고 있어야 하는 경우 DNS RR방식은 부적합하다

2. 로드밸런서를 이용한 웝 서버

- 클라이언트 측에서 쿠키 사용을 허가하면 두 번째 점속부터 HTTP 요청 헤더에 쿠키를 저장해서 접속
- 로드밸런서는 쿠키를 읽어서 같은 서버에 요청을 하게 되는 것이다
- 이를 통해서 세션 상태를 저장할 수 있다
  1. 2번째 DNS 접속
  2. DNS 테이블에서 IP를 전송
  3. 클라이언트는 IP와 함께 쿠키를 다시 전송
  4. 쿠키에 다른 IP가 적혀있으면 그 IP로 접속
- 로드 밸런스는 임시 대응 관료포로 세션 테이블을 만든다
  - 클라이언트에 요청을 반환할때 이 테이블을 참조 한다
- 세션 상태 저장을 실현하는 기능을 부하분산 장치에서는 '퍼시스턴스'라고 한다
  - 소스 IP주소: 클라이언트 IP 주소를 기반으로 요청을 할당할 웹 서버를 결정한다
  - 쿠키: HTTP 헤더 내에 접속한 웹 서버 정보를 저장한다
  - URL: URL 구조내에 접속한 웹 서버 정보를 저장한다
- 장애 발생시
  - 로드 밸런스는 웹 서버의 가동 상태를 감시할 수 있다.
  - 장애 발견시에 다른 서버에 할당(페일오버)를 할 수 있다
- 동적 컨텐츠이면 세션 정보가 사라지기 때문에 세션 정보가 사라지게 된다

### AP 서버 이중화

1. 웹 서버와 같이 로드 밸런서를 이용해서 AP서버가 가진 웹 서버 요청 이중화 기능을 이용해서 AP 서버를 분산
2. 세션 정보 이중화, (세션 정보: 애플리케이션의 상태 - 애플리케이션 상태를 일시적으로 기억하는 구조)

- 요청의 분산 및 세션 정보 이중화 기능을 사용해서 AP 서버를 이중화 할 수 있다
- EX) Oracle WebLogic Server, 웹로직
  1. AP 서버를 선정해서 요청을 AP서버에 리디렉션 한다
  - L2 스위치에 데이터를 보낸다
  2. 세션 정보를 작성해서 클러스터 내 다른 서버에 복제한다
  3. 세션 정보가 저장된 서버(기본/보조) 정보를 쿠키의 JSESSIONID에 추가해서 반환한다
  - AP 서버1에는 기본으로 세션1과 세션3을 보조로 가지고 있는다
  - 쿠키 정보에는 기본을 AP1 서버, 보조를 AP1 서버 복제한다
    - 세션 정보는 접속된 AP 서버를 기본으로 하고 보조 세션을 복사해준다
    - 서버 정보는 쿠키에 저장돼서 클라이언트에게 반환된다
- 장애 발생시
  1. 쿠키 정보로 부터 AP1 서버에서 리디렉션해서 실패를 감지
  2. 보조 세션이 승격해서 기본 세션이 돼서 리디렉션된다
  3. AP서버 3에는 세션 정보가 없기 떄문에 AP1에서 복제해서 가져온다
  4. 세션 정보가 저장돼 잇는 서버(기본/보조) 정보를 쿠키의 JSESSIONID에 추가해서 반환한다
     (기본: AP서버3, 보조 AP서버 2)
- 세션 정보를 복제하면 이를 위한 메모리나 네트워크 리소스 소비량이 늘어나기 때문에 주의

3. DB 연결 이중화

- AP 서버가 DB 서버에 접속하는 경우릉 이중화 한다
- Connection Pooling이라고 하여, 웹 로직의 데이터 소스를 설정해서 이용한다.
  - 데이터 소스를 이용하는 장점은 애플리케이션이 DB 서버의 IP나 포트 등을 몰라도 된다는 점이다
- Connection 객체의 getConnection 및 Close 메소드를 통해서 데이터를 바로 해제할 수 있다
  1. 지정한 소켓을 사전에 생성한다.
  2. 데이터 소스에게 대기중인 연결을 사용해 GET으로 데이터 베이스에 접속한다
  3. 불 필요해지면 CLOSE하여 다른 애플리케이션이 사용할 수 있도록 한다
- 비어 있는 연결이 없으면 애플리케이션 스레드가 Queuing 되어 대기 상태가 된다
- 최소값과 최대값을 동일하게 설정한다
  - 연결을 생성하거나 제거할 때 발생하는 오버헤드를 가능한 경감시킨다
- 방화벽 유무를 확인한다
  - 중간에 방화벽이 있다면 오랫동안 사용하지 않은 세션을 자동으로 제거하는 경우가 잇기 떄문에 방화벽 유무를 확인해야한다
  - 의도하지 않는 절단을 방지하기 위해서 정기적으로 폴링을 해줘야 한다

### DB 이중화

서버 이중화(액티브-스탠바이)

- 액티브-스탠바이의 클러스터 구성,
- 하트비트(인터커넥터)를 통해서 상호 간의 정상 동작 하는지 확인하기 위해 정보를 공유한다

페일 오버 과정

1. 액티브 DB가 장애를 감지하게 된다
2. 각 노드의 상태가 기록된다
3. 장애를 감지하면 서비스를 정지하거나 OS를 재시작한다
4. 액티브 측이 정지된 것을 파악하고 스탠바이가 액티브가 된다

서버 이중화(액티브-액티브)

1. 액티브와 액티브가 하나의 데이터베이스를 공유

- 디스크, 데이터를 모든 노드가 공유 한다
- 장애가 발생해도 다른 노드로 쉽게 처리 가능하다

2. 액티브와 액티브가 서로 공유 하지 않는다

- 각 노드별로 디스크를 가지고 있어서 데이터바 분산된다
- 노드를 배치하기 쉽다

### 사이트 이중화

대규모 재해가 발생하면 센터 전체가 가동되지 않을 수도 있다

- 글로벌 서버분산

- 클라이언트가 IP 주소를 받았을 때 가장 가까운 위치(물리적)에 있는 곳으로 접속을 하게 된다
- 동기와 비동기 여부가 매우 중요하다

## 감시

시스템 컴포넌트가 정상 동작하는지 확인하는 감시 기능

### 생존 감시

ping 명령어를 정기적으로 실행해서 서버 인터페이스에 대한 통신을 확인하는 감시

- 실행 중인 모든 프로세스를 감시하는 것이 아니라 중요한 것만 추려서 감시하는 것이 좋다
- 해당 프로세스가 장애가 발생하면 어떤 영향이 있는지, 어떤 대책이 필요한지와 같은 관저에서 생각하는 것이 중요

- OS의 명령을 실행해서 프로세스가 있으면 정상

### 로그 감시

OS나 미들웨어가 출력하는 로그 파일에는 시스템 유지를 위한 중요 정보가 포함돼 있다

- 미들 웨어 오류나 영역 고달 등 생존 감시로는 알 수 없는 정보가 로그 파일로 출력된다
  - 장애 원인 분석에도 도움이 된다
- 로그 파일에 새로운 출력이 있으면 패턴에 해당하는 내용이 있는지 확인한다
  - 해당하는 경우 통지를 보낸다
- 로그 감시 프로세스는 중요하다고 인지하고 있는 로그 출력문을 미리 저장해두고 있다가 실제 로그 파일이 출력되는 내용을 저장해 둔 것과 비교한다

### 성능 감시

디스크 사용률, 메모리 사용 현황, 디스크 코갈 등의 리소스 상태 파악과 네트워크 엑세스 지연, 디스크 엑세스 시간등의 응답 상태를 파악

- df 명령 등의 OS 명령을 정기적으로 실행하거나 vmstat 명령이나 sar 명령 등의 통계 정보를 취득해서 상황을 통계적으로 판단하는 등 다양한 방식이 필요
- 감시 항목
  - CPU: CPU 사용률, CPU 대기 행렬
  - 메모리: 빈 메모리 양
  - DISK: 남은 용량, 디스크 캑세스 시간
  - 네트워크: I/F 인바운드 아웃바운드 대역 사용률, 패킷 손실
  - HTTP(웹 서버 고유): HTTP 요청의 응답시간, 초당 HTTP 요청 처리수, 초당 HTTP 세션 수
  - JAVA(AP 서버 고유): 메모리 힙(Heap) 크기, 가비지 컬렉션 횟수
  - DATABASE(DB 서버 고유): 영역의 남은 용량, 캐시 사용률, SQL 응답
- 성능 감시의 감시 항목 선별 및 경계값 설정, 이상 값 분석은 각각의 미들웨어와 시스템 아키텍처를 고려해서 실시해야 한다

### SNMP

감시 전용 프로토콜

- 네트워크 장비나 서버 가동 상태
- 서비스 가동 상태
- 시스템 리소스
- 네트워크 트래픽

- 네트워크 장비와 서버를 일괄 감시해서 관리할 수 있는 것이 특징
- MIB(관리 정보 기반)으로써 규정된 정보를 수집하여 매니저에게 통지한다
1. 리스너가 다운되면 통지와 OID를 보낸다
2. 감시 대상 서버는 감시 대방 서버에게 리스너 다운 OID와 관련 정보를 전송한다
3. 트랩이 오면 매니저 프로세스는 OID를 확인한다

### 콘텐츠 감시

웹 화면이 정상적으로 보여지는지 확인하기 위한 웹 시스템 특유의 감시

- 클라이언트에게 정상적으로 응답을 반환하면 웹 시스템이 정상 가동하고 있다고 볼수 있다
- 일반 적으로 부하 분산 장치에서 확인한다

- 부하 분산 장치에서 URL을 등록해 둔다
- HTTP의 GET 요청을 해서 정상적으로 응답이 있으면 웹 서버 + AP 서버가 정상 가동 되고 있다고 판단한다
- 응답이 오지 않으면 부하분산 장치가 해당 웹서 서버에는 요청을 할당하지 않는다

## 백업

이중화와 크게 다른 점은 데이터를 복제해서 별도의 장소에 보관한다

복구 지표
1. 복구 목표 시간(RTO: Recovery Time Objective): 복구에 어느 정도 시간이 걸리나?
2. 복구 기준 시점(RPO: Recovery Point Objective): 어느 시점으로 복구할 것인가?
- RTO가 짧으면 짧을 수록 설게 난이도가 높고 백업 시스템 가격도 비싸진다

### 시스템 백업

OS나 미들웨어 등 일반 서버의 로컬 디스크 영역을 백업하는 것이다

- OS나 미들웨어는 한 번 설치해서 설정이 끝난 후에는 많은 변경이 일어나지 않는다
- 이 때문에 백업 빈도는 데이터에 비해 적은 편이다
- 백업 시점
  - 초기 구축 후
  - 일괄 처리 적용 시
  - 대규모 구성 변경시
- 취득 방법
  - OS 명령
  - 백업 소프트웨어
- OS 백업 명령과 백업 소프트웨어 모두 압축 백업이 가능하다
- 기록 속도는 미디어의 쓰기 속도, 디스크의 쓰기 속도에 의존한다
- 백업은 데이터 갱신이 발생하지 않고 평상시에는 사용하지 않는 데이터로 가능한 작은 크기로 저장해 주고 싶은 데이터이기 떄문
- 압축은 압축 할때는 물론 해제시에도 CPU 사용률이 늘어나고 실행 시간도 길어지는 경향이 있다
- 시스템 백업 취득 시의 유의점은 서버의 서버스를 정지할 필요가 있다는 것
- 가동 중인 서비스는 백업할 수 없다
  - 임시 파일이나 프로세스 가동 정보를 취득하게 돼서 복구 시 정상 가동되지 않는 경우가 있기 때문이다

### 데이터 백업

매일 변경되는 데이터가 손실되지 않도록 하는 것으로 취득 빈도가 높다

- 정지하기 힘든 시스템은 서비스가 가동 중인 상태라도 백업이 가능한 구조가 핑요하다
  - 데이터 일치성을 보장해야 하며, 데이터베이스 시스템에 있어서는 일치성 보장 기능이 필수다

## 캐시

자주 사용하는 데이터나 값을 미리 복사해 놓는 임시 장소

- 저장 공간이 작고 비용이 비싼 대신 빠른 성능을 제공한다
- 접근 시간에 비해 원래 데이터 접근 시간이 오래 걸리는 경우
- 반복적으로 동일한 결과를 돌려 주는 경우

사용 빈도가 높은 데이터를 고숙으로 엑세스 할 수 있는 위치에 둔다

CPU의 1차 캐시, 2차 캐시, 저장소 캐시, OS 페이지 캐시, 데이터베이스 버퍼 캐시등 다양하게 있다

- 데이터가 실제 데이터와 캐시라는 이중 구조로 저장되기 때문에 리소스 소비가 늘어난다
  - 설계시 어떤 데이터를 캐시하는 것이 효과적인지 검토해야 한다
- 시스템 가동 직후 등에는 캐시에 데이터가 없기 때문에 원하는 성능이 안나온다
- 캐시 계층이 늘어나기 때문에 시스템 성능 문제나 데이터 불일치 문제가 발생한 경우는 문제 발생을 야기한 용의자가 늘어난다
- 캐시의 데이터가 손실되는 경우 대비해서 복구 순서를 설계 시에 확립해야 한다
- 갱신 데이터를 캐시할 떄 캐시가 여러개 있으면 갱신된 최신 데이터를 서로 뺏으려는 상태가 발생하지 않도록 해야 한다

### Local Cache

- 로컬 장비 내에서만 사용되는 캐시
- 로컬에서만 작동하기 떄문에 빠르다
- 다른 서버와 데이터 공유가 어렵다

### Global Cache

- 여러 서버에 캐시 서버에 접근하여 분산된 서버에 데이터를 저장하고 조회 가능
- 네트워크를 통해서 가져오므로 상대적으로 느리다
- 캐시 서버를 사용하기 때문에 서버 간의 데이터 공유가 쉽다

## 인터럽트

어떤 원인으로 인해 지금 하고 있는 일을 중단하고 급히 다른 일을 하는 것

- 급한일을 먼저 할 수 있도록 CPU에 알리는 역할을 한다
- 즉, 급한 일을 먼저 실행을 한 후 다시 원래의 일을 돌아가서 처리를 한다

1. 이더넷 프레임이 NIC에 도착을 하게 된다면 인터럽트에 의해 CPU에 통지되고 데이터가 수신된다
2. CPU를 사용하고 있는 프로세스 정보는 메모리로 옮겨지고 전송된 데이터가 커널 모드로 처리된다
3. 끝나면 중단된 프로세스가 재개된다

- 어떤 일이 발생하면 생기게 되는 이벤트 구조

## 폴링(Pooling)

정기적으로 질의하므로써 상대가 어떤 상태이고, 어떤 요구를 가지고 있는 지 확인 할 수 있다

- 특징
  - 질의 방향은 단방향이다
  - 질의는 일정 간격을 따라 정기적으로 발생한다
- 장점
  - 반복만 하면 되기에 프로그래밍이 쉽다
  - 상대가 응답하는지 확인할 수 있다
  - 모아서 일괄적으로 처리할 수 있다

## 저널링

- 저널: 트랜잭션이나 매일 갱신되는 데이터의 변경이력
- 저널링: 저널을 남겨두는 것
- 시스템에 장애가 발생했을 때 어디까지 정상처리가 되었는지 어디부터 재실행하면 좋을지 알 수 있게 하는 기능이다

저널의 특징

- 데이터 자체가 아닌 트랜잭션 내용을 기록한다
- 데이터 일관성이나 일치성이 확보되면 필요 없어진다
- 데이터 복구 시 롤백, 롤포워드에 이용된다

- 장점
  - 시스템 장애시 복구가 빠르다
  - 데이터 복제보다도 적은 리소스를 소비해서 데이터를 보호할 수 있다

- 주의점
  - 저널 데이터는 메모리에 일단 저장이 된다, 정보가 디스크에 기록되지 않으면 장애 시에 잃을 수 있다. 시스템 요건에 따라 버퍼의 디스크 기록 시점을 검토 조정해야 한다
  - 트랜잭션 단위로 일치성을 보증하기 때무에 트랜잭션 도중에 장애가 발생하면 종료되지 않은 트랜잭션은 파괴된다

### 사용되는 위치

- 웹 로직 서버의 내부 감시 기능에 있다 (AP 서버와 DB 서버)
1. JDBC MBean 객체가 접속 풀의 '테스트 빈도'에 설정한 값(초깃값 120초)을 따라 미사용 접속을 사용해서 SQL을 실행한다
2. 서버 프로세스에서 오류를 발생한다
3. AP서버는 다시 요청을 실시한다
4. 또 오류가 발생하면 접속을 끊고 재접속을 한다
- 미리 접속되어 있는 접속 풀을 끊고 다시 접속을 하게 된다
- 미리 연결된 접속 풀이 정상인지 웹로직이 정기적으로 검사를 하게 되는 것이다       

1. NTP 데몬은 NTP서버에 정기적으로 시간을 요청한다
2. NTP 서버가 시간을 반환한다
3. 시간 차이가 있으면 시스템 시계의 시간을 보정한다

## I/O 크기

1회의 I/O에 필요한 사이즈, 즉 데이터를 주고 받을 때 사용되는 I/O의 크기
- 인프라 설계나 성능 튜닝에 있어 중요한 개념이다

- 데이터를 운반할 때 상자에 넣으면 효율적으로 관리할 수 있다
- 운반한는 양의 따라서 상자 크기를 선택하면 효율적으로 운반할 수 있다

### 오라클 데이터베이스

- 오라클 DB가 데이터 파일을 읽기/쓰기 하는 최소 단위를 블록
- I/O 크기가 작을 때는 블록 크기를 작게, I/O 클때는 블록 크기도 크게하는 것이 좋다

### 네트워크

브라우저가 인터넷에 있는 웹 사이트를 볼때 PC 내 메모리에 있는 데이터가 NIC를 통해서 밖으로 나오고, 스위치나 라우터를 경유해서 웹 서버에 도착한다
- 이떄 데이터는 상자에 든채 운반된다

웹 브라우저가 데이터를 전송할 떄에는 OS의 소켓이라는 구조를 사용한다
- 웹 브라우저는 OS에 의뢰해서 소켓을 만들어서 통신한다
- 웹 브라우저가 송신하는 경우도 송신 버퍼에 쓴다
- 버퍼가 차게 된다면 OS에 의해 TCP 세그먼트라는 상자로 분할되고 TCP, IP, MAC 헤더라는 편지 수신자 같은 정보를 붙여서 이더넷이라는 프레임이라는 상자에 넣어서 전송한다

## 응답과 처리량

- 응답: 처리 하나당 소요 시간을 의미
  - 검색 버튼을 누른 후 검색 결과가 표시되기까지 걸리는 시간
  - '서비스를 사용하는 사용자의 입장'
- 처리량: 단위 시간당 처리하는 양
  - 이 검색 엔진이 초당 받아 들이는 사용자 수에 해당
  - '서비스 제공자의 입장'

응답시간에 포함되는 내용

- 웹 브라우저에서 화면을 클릭한후 요청이 실행되기 까지의 시간
- 클라이언트 <-> 웹, 웹 <-> AP, AP <-> DB간의 네트워크 통신 시간
- 웝 서버, AP 서버, DB 서버의 처리 시간
- 결과를 표시하는 기간

인터넷 경유라면 여기서 몇 번 이고 스위치를 경유 한다

응답과 처리량은 밀접한 관계가 있다

- 응답이 매우 느린 시스템에서는 다수의 사용자 요청이 시스템 내에 누적되므로 전체 처리량도 낮아진다
- 처리량이 포화된 상태가 되면 리소스 부족하여 응답도 함계 늦어진다
- 성능 병목 현상을 개선하려면 반드시 양쪽을 고려해서 진행해야 한다

### 병목현상

처리량을 제한하고 있는 요인

- AP서버에서 CPU 사용률이 높아져서 처리량이 한계에 다다르고 있다고 할때
- 처리량이 포화 상태이기 때문에 AP 서버의 응답 시간도 악화된다
- 응답 시간이 전체적으로 지연되고 있을 때 병목 현상

해결 방법

1. 병목현상이 일어나는 위치를 정확히 파악하기

- 각 서버의 처리량이나 응답 상황 로그를 취득해서 어느 서버에서 병목지점이 일어나는지 찾아야 한다

2. 문제를 해결하기

- 튜닝 하는 방법
  - 1: 병목 위치를 작은 단위로 세분화 하여 병목 여역을 더 집중적으로 파헤치는 접근법 필요
  - 2: 시스템의 이용자 수를 제한(유량 제어), 적절한 계층에서 이용자 수를 제한하는 접근 방법
    - 수평 분할을 통해 서버를 증설함으로써 시스템 전체 허용량을 늘리는 접근법이다
