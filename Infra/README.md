# Infra(인프라)

IT 인프라 - IT의 기반으로 되어 있는 방대한 데이터들을 관리<br>
인프라 아키텍처 - IT인프라의 구조

## 아키텍처의 종류

### 집약형 아키텍처

해당 주요 업무들을 모두 한대로 처리를 하는 작업

- 리소스 관리 -> 고부하 처리 요구가 왔지만 다른 처리에 영향을 주지 않는다.
  - 하나의 처리가 실수로 대령의 요청을 보내더라도 다른 처리에 영향을 주지 않는다.
- 이중화 -> CPU 하나가 망가져도 멈추지 않는다.
- '기간 시스템'으로 불리는 업무 시스템에서 이용하고 있는 경우가 많다.(은행의 계정시스템)
- 장점
  - 한 대의 대형 컴퓨터만 있으면 되므로 구성이 간단하다
  - 대형 컴퓨터의 리소스 관리나 이중화에 의해 안정성이 높고 고성능이다
- 단점
  - 대형 컴퓨터의 도입 비용과 유지비용이 비싸다
  - 확장성의 한계가 있다

### 분할형 아키텍처

여러 대의 컴퓨터를 조합하여 하나의 시스템을 구축하는 구조

- 소형 컴퓨터도 성능을 구현할 수 있지만 여러개를 묶어서 더 특화 시킨다
- 장점
  - 낮은 비용으로 시스템을 구축할 수 있다.
  - 서버 대수를 늘릴 수 있어서 확장성이 좋다
- 단점
  - 대수가 늘아나면 관리 구조가 복잡해진다.
  - 한 대가 망가지면 영향 범위를 최소화 하기 위한 구조를 검토해야 한다.

### 물리 서버 VS 논리 서버

서버 - 분할형 아키텍처에서 이용되고 있는 컴퓨터, 컴퓨터 자체(물리) 혹은 동작하는 소프트웨어(논리)를 의미

- 웹 서버: 인터넷 접속시 HHTML 생성을 담당하는 것 / DB 서버: 대량의 데이터를 저장해서 요청에 따라 데이터를 제공하는 것
  <br>
  컴퓨터 자체를 가리키는 경우 - '물리 서버'라고 부른다

## 수직 분할형 아키텍처

- 각각의 서버가 유사한 작업을 하는지, 전혀 다른 작업을 하는지에 따라 나뉘게 된다

### 클라이언트 - 서버형 아키텍처

수직 분할형 서버

- 킅라이언트는 소형 컴퓨터(PC), 스마트 폰에 설치
- 서버는 업무 애플리케이션, 미들웨어, 데이터베이스 등의 소프트웨어를 '물리 서버' 상에서 구현
- 클라이엉ㄴ트 측에서 전용 소프트 웨어를 설치하고 사용을 해야 한다.(즉, 정기적인 업데이트가 필요)
- 장점
  - 클라이언트 측에서 많은 처리를 실행 할 수 있어서 소수의 서버로 다수의 클라이언트 처리 가능
- 단점
  - 클라이언트 측의 소프트웨어 정기 업데이트가 필요하다
  - 서버 확장성의 한계가 발생할 수 잇다.

### 3계층형 아키텍처

수직 분할형 서버

- 프레젠테이션 계층
  - 사용자 입력을 받는다
  - 웹 브라우저 화면을 표시한다
- 애플리케이션 계층
  - 사용자 요청(Request)에 따라 업무를 처리한다.
- 데이터 계층
  - 애플리케이션 계층의 요청에 따라 입출력을 한다.
- 장점
  - 서버 부하 집중 개선
  - 클라리언트 단말의 정기 업데이트가 불필요
  - '처리 반환'에 의한 서버 부하 저감
- 단점
  - 구조가 클라이언트-서버보다 복잡하다

## 수평 분할형 아키텍처

용도가 같은 서버를 늘려나가는 방법<br>
대수가 늘어나면서 한 대가 시스템에 주는 영향력이 낮아진다.<br>
또한, 처리를 담당하는 서버 대수가 늘어나면 전체적인 성능 향상도 실현할 수 있다.

### 단순 분할형 아키텍처

"Sharding(샤딩)" 혹은 "Partitioning(파니셔닝)" 이라고 부른다.

- 시스템이 둘로 분할 됨으로써 시스템의 전체 처리 성능을 두배로 향샹 시클 수 있다.
- 두개의 독립적인 시스템이 생성되기 때문에 서로 장애의 영향을 받지 않는다.
- 장점
  - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
  - 분할된 시스템이 독립적으로 운영되므로 서로 영향을 주지 않는다.
- 단점
  - 데이터를 일원화 해서 볼 수 없다.
  - 애플리케이션 업데이트는 양쪽을 동시에 진행을 해야 한다.
  - 처리량이 균등하게 분할돼 잇지 않으면 서버별 처리양에 치우침이 생간다.

### 공유형 아키텍처

단순 분할형과 다르게 일부 계층에서 상호 접속이 이루어진다.

- 장점
  - 수평으로 서버를 늘리기 때문에 확장성이 향상된다.
  - 분할한 시스템이 서로 다른 시스템의 데이터를 참조할 수 있다.
- 단점
  - 분할한 시스템 간 독립성이 낮아진다.
  - 공유한 계층의 확장성이 낮이진다.

## 지리 분할형 아키텍처

업부 연속성 및 시스템 가용성을 높이기 위한 방식

### 스탠바이형 아키텍처

스탠바이 구성, HA구성, 액티브-스탠바이 구성으로만 이루어져 있다.

- 최소 두 대 물리 서버가 있어 한대가 고장나면 가동 중인 소프트웨어를 다른 한 대로 옮겨서 운영하는 방식("재시작" = "Failover")
- 장점
  - 물리 서버 고장에 대처를 할 수 있따
- 단점
  - 보통 페일 오버 대상 서비스가 놀고 있는 상태가 되기 때문에 리소스 측면에서 낭비된다.
- 스탠바이를 따로 두지 않고 동시에 교차로 사용하다가, 고장나면 페일 오버를 진행한다.

### 재해 대책형 아키텍처

재해에 대해서 복구 구성을 취하고 있다.

- 서버 장비를 최소 구성 및 동시 구성으로 별도 사이트를 배치하고, 소프트 웨어도 상용 환경과 동일하게 설정한다.
- 데이터는 매일 갱신되야 되기 때문에 저장소 장비 기능, OS기능, 데이터베이스 기능 등 동기 처리를 위한 방법은 여러가지가 있다.
- 각각의 비용, 대상 데이터, 동기 연장 특성 등을 고려하여 결정

<hr>

# 서버

서버는 랙(Lack)이라는 것이 장차괸다, 서버 외에도 HDD가 가득 장착돼 저장소나 인터넷 및 LAN을 연결하기 위한 네트워크 스위치도 탑재

- 서버, 소비 전력, 중량이 매우 중요하다

## 서버의 구성

- 서버와 PC는 물리적으로는 기본 구성이 같다.
- 정눵니 이중화 되어 있고, 대용량 CPU가 탑재 되어 있는 정도가 다르다

## CPU(Central Processing Unit)

- 서버 중심에 위채헛 연산 처리를 실시한다.
- 명령과 데이터는 기억 장치나 입출력 장치를 통해 전달된다.
- CPU를 '코어'라고 하며 하나의 CPU에 여러 개의 '코어'가 존재하는 멀티 코어도 있다.

## 메모리

- 기억 명령을 수행을 한다.
- CPU옆에 위치를 하며 CPU에 전달하는 내용이나 데이터를 저장하거나 처리 결과를 받는다.
- 메모리에 저장되는 정보는 영구성이 없다(서버가 재시작되면 없어진다)
- CPU자체에도 메모리를 존재한다(레지스터 L1/L2 캐시, 빠르지만 용량이 작다)
- 매모리가 여러 단계로 분리가 되어 있다.
  - 고속 CPU는 처리 지연을 허락하지 않는다.
  - 엑세스 속도를 위해서 영역을 여러 단계로 나눈다.
    - 캐시 메모리가 커질 수록 엑세스 속도가 커진다.
  - 그래서 바로 쓸 수 있는 것은 L1, 근처에 두고 싶은 것은 L2에 둔다.

### 메모리 인터리빙(Memory Interleaving)

- 메모리에 데이터를 미리 CPU에 전달하여 처리 지연을 줄이는 기능
- EX)
  - 3개의 채널을 사용하여 데이터 1을 요구하면 2와 3을 같이 보낸다.
  - 데이터가 연속해서 엑세스 된다는 규칙
  - 먼저 읽어서 처리 지연을 줄여 준다.
- 모든 채널의 동일 뱅크에 메모리를 채워야 한다.
- 다단계 구조를 가지고 각각의 엑세스 속도에 맞게 사용되기

## I/O 장치

### HDD

- 서버에서는 메모리에 비해 CPU에서 멀리 떨어진 곳에 HDD가 배치된다.
- 장기 저장 목적의 데이터 저장 장소로 사용한다.
- 전기가 없을 경우 메모리는 사라지지만, 디스크는 유지 된다.
- 자기 원반이 여러개 들어 있어, 고속으로 회전해서 읽기/쓰기를 한다
- 회전 구조 때문에 물리 법칙에 좌우되며, 메모리 처럼 순식간에 엑세스 할 수 없다
- 최근에는 물리적인 회전 요소를 사용하지 않는 SSD를 사용한다
- 하드웨어(스토리지)
  - I/O의 서브시스템이라고 불리는 장치로, 내부에서는 CPU와 캐시가 존재하고 수많은 HDD외에도 여러 기능를 탑재한다.
- 서버와 I/O에서는 HDD가 직접 데이터를 교환하는 것이 아니라 캐시를 이용해서 한다.
  - CPU 캐시와 이용방법이 동일하다 메모리 처럼 고속으로 I/O가 가능하다
- 파이버 채널(Fiber Channel)
  - 대형 저장소와 연결해서 케이블을 애용해서 SAN이라는 네트워크와 연동된다
  - SAN에 접속하기 위한 파이버 채널 인테페이스를 FC 포트라고 한다.
- I/O 읽기
  - 읽기 캐시 경우에는 캐시상에 데이터 복사본만 있으면 된다.
- I/O 쓰기
  - 쓰기 캐시 경우에는 데이터를 기록했다고 간주하는 경우 데이터를 잃을 수 있다.
  - 이러한 쓰기 I/O를 라이트백(Write Back)이라고 한다
- 라이트 스루(Write Through)
  - I/O는 캐시와 HDD에 모두 엑세스 한다.
  - 쓰기에는 디스크를 모두 읽어서 라이트 백과 비교한다
  - 이 경우에는 쓰기 캐시의 장점이 없어진다.
- 기본적으로 캐시의 장점을 살리기 위해 라이트백으로 설정한다

### 네트워크 인터페이스

서버와 외부 장비를 연결하기 위한 것으로 외부 접속용 인터페이스

### I/O 제어

I/O 버스는 PCI의 x8, x16 - I/O 회선의 개수를 의미한다

- 각 CPU/칩섹 구조마다 PCI를 연결할 수 있는 회선이 정해져 있다.
- 단, 각 서버에는 내부적인 사용 용도도 있으므로 외부 연결을 위해 사용할 수 있는 PCI 회전 수는 CPU가 처리할 수 있는 총량보다 적다

-- 이해가 안되서 추가 공부

## 버스

서버 내부에 잇는 컴포넌트들을 서로 연결시키는 회선

- 중요한 점: 버스가 어느 정도의 데이터 전송 능력(대역)을 가지고 있는가

### 대역 (처리량(Throughput))

데이터 전송 능력

- 한번에 데이터를 보낼 수 있는 데이터 전송의 폭(전송폭) X 1초에 전송할 수 있는 횟수(전송횟수)
- 전송 횟수는 '1초 / 1 처리당 소요시간(응답시간)' 으로도 표현한다
- EX) PCI Express 3.0은 1회선당 2GB/s
  - x8은 8회선으로 8배의 능력을 가지고 있다

### 버스 대역

CPU에 가까운 쪽이 1초당 전송량이 크다

- CPU와 메모리는 대량으로 데이터를 교환해서 매우 빠른 전송 능력이 요구 되어서 바로 앞에 위치한다
- USB 3.0 포트는 500MB/s이므로 저속이여서 PCH앞에 배치해도 상관 없다

- EX) 광랜 인터넷 - 최대 1GBps = 12MB/s 대역으로 통신이 가능하다
- 데이터 전송 속도와 전기적 신호 속도가 다르다는 견해로 버스 전송 속도는 기가트랜스러를 사용할 수도 있다
- 버스 흐름에서 가장 중요한 부분은 CPU와 장치 사이에 병목 현상이 없어야 한다.

  - 데이터 전송이 어떤 이유로 막혀 있는 상태가 있으면 안된다

- 예시 다시 공부

## 3계층형 서비스

웹 서버, AP 서버, DB 서버<br>
각각의 서버는 CPU, 메모리, 디스크, NIC/HBA 같은 하드웨어 부품이 나열되어 있다.(물리장치들)

### 프로세스와 스레드

프로세스 및 스레드는 실팽 파일 자체가 아니라 OS상에서 시행돼서 어느정도 독립성을 가지고 동작한다

- 활동하기 위해서는 메모리 공간이 필요하고 커널에 의해 메모리 상으로 확보가 된다
- 메모리 공간을 통해서 데이터를 주고 받고 사용할 수 있다
- 메모리 공간은 프로세스 시작 시에 공간이 확보가 된다

프로세스의 시작

1. OS상에서 프로세스가 시작돼서 사용자 요청을 받을 수 있다.
2. 시작 의뢰가 있으면 커널이 프로세스를 요청하고 요청 분량만큼 메모리를 할당한다
3. 프로그램은 서버 내부의 디스크 상에 설치된다

프로세스와 스레드 메모리 공간의 차이

- 하나의 프로세스사 동작하고 있으면 메모리 공간을 점유하는 스레드 하나가 동작하고 있다.
- 각 스레드는 메모리 공간을 공유한다. 스레드 시작시에는 신규 메모리 공간은 필요 없지만, 다른 스레드에 이상이 발생하면 영향을 받는다.

웹서버: Htptpd 프로세스들로 이루어져 있다 <br>
AP서버: 스레드들이 하나의 메모리 공간을 공유하고 있다.<br>
DB서버: 공유메모리들이 존재하고 여러 포르세스들이 참조한다<br>

- 오라클 DB에서는 여러 프로세스가 '공유 메모리 공간'을 이용할 수도 있다

1. 오라클 DB는 각 프로세스별 메모리(PGA), 전체가 공유하는 메모리(SGA)가 나누어져 있다.
2. SGA는 디스크상의 데이터 캐시나 실행 완료된 SQL 캐시, 테이블 인덱스 등이 저장
3. PGA는 해당 프로세스 SQL이 이용하는 소트 영역이나 테이블 결합에 사용하는 메모리 영역이 저장된다(다른 메모리 접근 불가)

- 이와 별도로 프로세스별 독자 메모리 영역도 있어서 용도별로 나누어 사용하고 있다
- 프로세스 간 공유하고 싶은 데이터(캐시를 저장하는 데이터)는 공유 메모리에 둔다

프로세스와 스레드의 차이점
||장점|단점|
|---|---|---|
|프로세스|개별 처리 독립성이 높다|생성시 CPU 부하가 높다|
|스레드|생성시 CPU 부하가 낮다| 메모리 공간을 공유하기 때문에 원하지 않는 데이터를 읽을 수 있다|

## OS 커널

OS에서 커널 자체를 '인프라'이다.

- 뒤에서 무슨 일이 벌어지는지 은폐하면서도 편리한 인터페이스를 제공한다
- 커널이 존재하기 때문에 개발자는 하드웨어나 다른 애플리케이션에 끼치는 영향을 의식하지 않고 애플리케이션을 만들 수 있다

### 1. 시스템 콜 인터페이스

프로세스나 스레드로 부터 명령을 받는 인터페이스

- 애플리케이션이 OS를 통해 어떤 처리를 하고 싶으면 시스템 콜이라는 명령을 이용해서 커널에 명령을 내린다
- EX) 디스크상의 데이터를 읽고 싶거나 네트워크 통신을 하고 싶을 때, 새로운 프로세스를 생성하고 싶을 때
- 디스크 읽기 쓰기는 네트워크 읽기 쓰기와 같이 프로세스 관점에서는 동일한 시스템 콜이다

### 2. 프로세스 관리

프로세스를 관리한다

- OS상에서 수십, 수백, 수천개의 프로세스를 가동할 수 있다
- 물리 서버는 CPU 코어의 개수가 적는데, 처리 순서를 어떻게 처리할 것인지 결정한다

### 3. 메모리 관리

메모리 영역을 관리

- 물리 메모리 공간의 초디ㅐ치를 고려한다.
- 프로세스가 이용하는 독립 메모리 공간을 확보하거나 상호 간의 참조 영역을 지키기 위해 독립성을 관리하는 등의 메모리 관리 역할을 한다
- 메모리 관리가 없으면 각 프로세스는 자신 이외의 프로세스가 사용하고 있는 메모리 영역을 파악해야 한다

### 4. 네트워크 스택

### 5. 파일 시스템 관리

OS 기능의 하나로서 물리 디스크에 제공된 데이터를 관리하는 기능이다

- 디렉토리 구조제공, 엑세스 관리, 고속화 안정성 기능이 있다
- 프로레스 관점의 파일 시스템
  - 프로세스(스레드)는 편리성 때문에 파일 단위로 생각
  - 파일 시스템은 여러 프로세스가 공유한다
  - 자주 사용하는 내용은 메모리상에서 캐시하고 있다
  - 커널이 파일 시스템의 인터페이스로 동작한다
  - 프로세스는 물리 디스크 구조나 데이터 배치 상태를 의식할 필요가 없다

### 6. 장치 드라이버

디스크나 NIC등의 물리 장치용 인터페이스를 제공한다

- NIC나 디스크는 다수의 제조사가 족자제품을 제공하고 있다.
- 각각에 대응하는 애플리케이션을 개발하는 것은 현실적이지 못하기 때문에 커널은 장치 드라이버를 이용해서 물리장치를 은폐
- 장치 제조사가 OS에 대응하는 장치 드라이버를 제공해서 OS당 표준 장차로서 커널을 경유해 이용할 수 있다

- NIC: Network Interface Controller
  - LAN의 연결지점으로 제공하기 위해 컴퓨터에 설치하는 어뎁터
  - 물리 계층과 데이터 계층서비스를 제공하다
  - 장비와 LAN 사이의 통신을 제공한다
  

### 커널 구성 방식

1. 모놀로식 커널

- OS의 주요 구성 요소를 모두 하나의 메모리 공간을 통해 제공한다
- 명칭이 가진 의미대로 한 명의 '왕자'가 모든 기능을 제공하고 있다
- EX) LINUX OS

2. 마이크로 커널

- 최소한의 기능만 커널이 제공, 그 외 기능은 커널 밖에서 제공한다
- 커널 자체가 작아지기 때문에 더 심플하다
- EX) MAX OS

## 웹데이터 흐름

### 클라이언트 PC부터 웹 서버까지
클라이언트 PC에서 웹 브라우저를 실행해서 웹 서버에 요청을 보내고 AP서버에 질의 하기 까지의 흐름

1. 웹 브라우저가 요청을 발행한다
  - 특정 인터넷 사이트를 요청한다
2. 이름 해석을 한다
  - 해당 사이트가 어디에 있는지 이름 해석한다
  - 이 결과를 가지고 웹 서버에게 요청한다
3. 웹 서버가 요청을 접수한다
  - 'httpd' 프로세스가 요청을 접수한다
4. 웹 서버가 동적 콘텐츠인지 정적 컨텐츠인지 확인한다
  - httpd 프로세스가 내용을 판단한다
  - 정적: 변화가 없는 콘텐츠, html, css, js와 같이 미리 서버를 저장하고 서버의 요청을 바로 응답하는 컨텐츠
    - 실시간으로 변경할 필요가 없는 데이터
  - 동적: 서버의 요청마다 결과값을 다르게 부여주는 형식, 사용자가 맞춤형 콘텐츠를 제공할 수 있도록 한다
    - 높은 빈도로 변경되는 데이터
5. 필요한 경로로 데이터를 엑세스 한다
  - 정적인 정보이면 디스크로부터 읽는다
  - 동적인 정보는 네트워크를 경유해서 다른 서버에 요청을 보낸다

httpd: HTTP PROTOCOL을 지원하는 Daemon, 즉, HTML 파일을 전송해주는 규약
  - FTP를 지원하는 daemon은 ftpd이며, telnet을 지원하는 daemon은 telentd이다
  - 즉, http를 지원하는 서버이며, Web Server를 구축한다는 말은 httpd를 수행하는 말과 같다
  - EX) 아파치 서버도 Linux의 기본 httpd이다

daemon: 서비스의 요청에 대해 응답하는 오랫동안 실행중인 백그라운드(background) 프로세스다.
- 유닉스(리눅스 포함) 운영체제에서 이름이 "d"로 끝나는 프로세스(inetd, httpd, nfsd, sshd, named, lpd 등)이다.

background process: 입력장치에 대해 터미널과 관계를 끊은 모든 프로세스
  - 사용자에게 무언가를 키보드를 통해 전달받지 않고 스스로 동작하는 프로세스

`http://www.naver.com`을 입력하는 것은 HTTP를 이용해서 `www.naver.com` 서버 접속하는 것을 의미한다

서버가 아닌 PC에서의 처리 흐름
- 디스크에서 프로그램을 읽어서 프로세스를 시작하고, 메로리 공간을 확보한다
1. PC 내부도 서버와 거의 같은 구조이다
2. 웹 브라우저도 OS의 '프로세스'로 실행된다
3. 프로그램은 원래 디스크에 저장돼 있다. 이것을 읽어서 메모리에 상주시키고 실행하는 OS이다
4. 웹 브라우저 화면에서 링크를 클릭하면 웹 서버로 요청을 보낸다
5. 이것도 OS의 '시스템 콜'로 실행되고, 커널을 통해 NIC에 네트워크 통신이 요청된다
6. 네트워크 경유로 웹 서버에 질의를 한다

이름 해석(Name Resolution): 웹 브라우저가 서버를 확인하는 과정
- 인터넷 상 주소는 IP로 되어 있어 문자열 URL과 IP를 연결시켜야 한다
1. 웹 브라우저는 IP 주소를 일단 모른다
2. OS의 호스트명, IP 주소 변환 테이블을 참조해서 존재하지 않는 경우, 외부의 DNS서버에 요청을 던진다
  - DNS 서버에 호스트명이 아닌 IP주소로 지정돼 있는 것은 이 때문이다
3. 전 세계에 있는 DNS 서버는 Root DNS를 기준으로 트리 구조로 돼있다
  - 개별 DNS 서버는 정기적으로 부모 DNS서버에서 데이터를 받아서 최신 IP주소 목록을 유지한다
4. IP 주소 검색 결과가 반환된다

- 웹 서버의 역할은 HTTP 요청에 대해 적절한 파일이나 콘텐츠를 반환
- HTTP(HyperText Transfer Protocol)의 프로토콜을 가리킨다
- 웹 서버에는 Http를 처리할 수 있는 'httpd 프로세스'가 가동되고 있다.
- 부모/자식 프로세스 중에서는 자식 프로세스가 HTTP 요청을 접수한다

### 웝 서버부터 AP서버 까지
'동적 컨텐츠'를 수행하는 것이 AP서버이다
- 즉, 아직 존재하지 않는 콘텐츠를 가능한 빨리 만들어내는 역할
- 자바를 이용한 AP서버에서는 JVM이 동작한다
1. 웹 서버로부터 요청이 도착한다
  - 웝 서버에서 온 요청은 NIC를 경유해서 커널에 의해 끼어들기 처리한다
2. 스레드가 요청 받으면 자신이 계산 가능한지, DB 접속이 필요한지 판단
  - 스레드가 요청을 접수한다
3. DB 접속이 필요한 연결 풀에 엑세스 한다
  - 동적 데이터를 가져오기 위해 연결 풀이용한다
4. DB에 보내는 접속 요청도 시스템 콜을 사용한다
5. 네트워크 경유로 DB서버에 대한 질의가 이루어진다
- AP서버가 DB서버에 접속하기 위해서 '드라이버'가 필요하다
- 커널의 장치 드라이버와 비슷하다

- 자주 갱신되지 않고 규모가 작은 경우에는 JVM 내부에 캐시로 저장해 두었다가 반환하는 것이 좋다
- 규모가 매우 큰 경우에는 DB서버 외에 CDN(Content Delivery Network)이라 불리는 데이터 전송 전용 서버를 이용한 경우도 있다
  - 대량의 데이터를 전송에 특화 되어 있다, 복사본(캐시)를 배치하는 기술과 병렬 기술을 활용해서 처리를 효율화한다
### AP서버 부터
오라클 DB인 경우 서버가 요청을 접수한다. 요청은 SQL을 통해서 이루어진다
1. AP서버로 부터 요청이 도착한다
  - DB서버에서는 DB프로세스가 요청을 접수한다
2. 프로세스가 요청을 접수하고 캐시가 존재하는지 확인한다
  - 이전에 사용한 정보는 캐시에 있기 때문에 이 정보를 찾기 위해 일단 공유 메모리를 검색한다
3. 캐시가 없으면 디스크에 엑세스 한다
  - 공유 메모리에 데이터가 존재하지 않기 때문에 디스크에서 읽는다
  - 이전과 같은 방식으로 시스템 콜을 경유해서 디스크에 요청한다
4. 디스크가 데이터를 반환한다
  - 디스크의 데이터는 요청을 보낸 프로세스로 반환된다
5. 데이터를 캐시 형태로 저장한다
  - 한번 엑세스한 데이터는 메모리에 캐시 형태로 저장되고 이후 엑세스 시에 재사용 된다
6. 결과를 AP 서버에 반환한다
  - 요청을 보낸 AP서버로 데이터를 반환한다

- 웹 서버에서는 개뱔 프러세스가 독립된 형태로 동작하지만, DB서버에서는 여러 개의 프로세스가 역할을 분담하는 경우가 있다
  - 서버 프로세스: SQL의 요청을 받아서 데이터를 검색 가공한다, 디스크에서 메모리를 읽거나 메모리에 캐시를 저장하는 역할도 한다
  - 백그라운드 프로세스: 메모리 상의 차이 정보(REDO)을 관리하거나 데이터를 디스크에 반영하는 일을 한다
  - 개별 서버 프로세스가 아닌 공유화를 통해 효율성 및 비동기성을 
- 저장장치에는 다수의 디스크가 설치되어 있다
  - 본질적인 구조는 거의 차이가 존재하지 않는다
  - 메모리에는 데이터를 캐시 형태로 저장하는 구조도 있다

### AP서버에서 웹 서버까지
DB서버에서 데이터가 돌아왔기 떄문에 AP서버의 요청 스레드로 결과가 반환된다
1. DB서버로 부터 데이터가 도착한다
  - DB서버에서 돌아온 데이터는 NIC 경유로 원래 스레드로 반환이 된다
2. 스레드가 데이터를 가지고 계산 등을 한 후에 파일 데이터를 생성한다
  - DB데이터, JVM의 캐시, 데이터 등을 이용하여 계산 처리, 집계 처리등이 이루어지고 특정 형태의 파일이 생성된다
3. 결과를 웹 서버로 반환한다
  - 웝 서버로 데이터들이 반환된다
- 주로 HTML, XML을 이용하거나 동적 이미지 등의 바이너리 데이터를 반환할 수도 있다
- HTTP로 전송 가능한 데이터라면 어떤 형태의 데이터든지 상관없다

### 웝서버에서 클라이언트 PC까지
AP서버에서 돌아온 데이터를 받아서 웹 서버의 httpd 프로세스가 PC의 웹 브라우저로 반환된다
1. AP서버로 부터 데이터가 도착한다
  - AP서버에서 돌아온 데이터는 NIC 경우로 원래 스레드에 반환
2. 프로세스는 받은 데이터를 그대로 반환한다
  - 필요한 데이터 가공은 모두 AP서버에서 이루어진다 => 그대로 반환한다
3. 결과가 웹 브라우저로 반환되고 화면에 표시된다
  - 요청한 데이터를 웹 브라우저로 반환된다
- 웹페이지는 HTML과 다수의 이미지 파일등이 있기 때문에 복수의 요청으로 분할돼서 웹서버에 도착하고, 요청별로 데이터를 반환한다

### 웹 데이터 흐름 정리
- 공통점
  - 프로세스나 스레드가 요청을 받는다
  - 도착한 요청을 파악해서 필요에 따라 별도 서버로 요청을 보낸다
  - 도착한 요청에 대해 응답한다

- 3계층 시스템은 사용자 요청이 시발점이 되어 다양한 서버로 전달한다
- 자신이 할 수 없는 처리는 다음 서버에서 그 역할을 떠넘긴다
- 요청 기반 아카텍처이기 떄문에 각 서버는 '문을 열고 기다리고 있는' 상태이다
## 로드 밸런싱

하나의 인터넷 서비스가 발생하는 트래픽이 많을 때 여러 대의 서버가 분산하여 서버의 로드율 증가, 부하량 속도 저하등을 고려하여 적절히 분산처리하여 해결해주는 서비스

- Scale-up: Server가 더 빠르게 동작하기 위해 하드웨어 성능을 올리는 방법
- Scale-out: 하나의 Server보다는 여러 대의 Server가 나눠서 일을 하는 방법

  - 하드웨어 서버 향상하는 비용보다 서버 한대 추가 비용이 더 작다
  - 여러 대의 Server 덕분에 무중단 서비스를 제공할 수 있다.
  - 여러 대의 Server에 균등하게 Traffic을 분산시켜주는 역할을 하는 것이 `Load Balancer`이다

- NAT
  - 사설 IP주소를 공인 IP 주소로 바꾸는 데 사용하는 통신망의 주소 변조기
- Tunneling
  - 인터넷 상에서 눈에 보이지 않는 통로를 만들어서 통신할 수 있게 한다
  - 데이터를 캡슐화해서 연결된 상호간에만 캡슐화된 패킷을 구별해 캡슐화를 해제할 수 있다.
- DSR(Dynamic Source Routing Protocol)

  - 로브 밸런서 사용시 클라이언트로 되돌아가는 경우 목적지 주소를 스위치 IP 주소가 아닌 클라이언트 IP 주소로 전달
  - 네트워크 스위치를 거치지 않고 클라리언트를 찾아가는 개념

- L2: Mac주소를 바탕으로 Load Balancing
- L3: IP 주소를 바탕으로 Load Balancing
- L4: Transport Layer(IP와 Port) Level에서 Load Balancing
- L7: Application Layer(사용자의 Request) Level에서 Load Balancing

## Scaling

### X-axis Scaling

- 로드 밸런서 뒤에서 여러 개의 애플리케이션을 복사본을 실행하는 것
- N개의 복사 본이 있는 경우 각 복사본은 로드의 1/N을 처리한다
- 각 복사본이 모든 데이터를 잡재적으로 액세스 하기 때문에 캐시가 효과적이기 위해서는 더 많은 메모리가 필요하다

### Y-axis Scaling

- 여러 개의 다른 서비스로 분할한다
- 각 서비스는 하나 이상의 밀접하게 관련된 기능을 담당한다
- 두 가지의 방식
  - 동사 기반의 분해를 사용하고 체크아웃과 같은 단일 사용 사례를 구현 서비스 로 정의
  - 명사별로 응용 프로그램을 분해하고 고객관리 등 특정 법인과 모든 운영을 책임지는 서비스이다.

### Z-axis Scaling (추가 공부)

- 각 서버는 동일한 코드 사본을 실행하는 것으로 X-axis Scaling과 비슷
- 각 서버가 데이터의 일부분만 책임을 진다
- 시스템의 일부 구성요소는 각 요청을 적절한 서버로 라우팅할 책임이 있다.
- Z-axis Scaling은 주로 데이터베이스 축적에 사용된다
  - 데이터는 각 레코드의 속성에 기초하여 서버 집합에 걸쳐서 분할 된다
- 장점
  - 각 서버는 데이터의 서브셋만 처리한다
  - 캐시 활용도가 향상되고 메모리 사용량과 I/O 트래픽이 감소한다
  - 요청이 일반적으로 여러 서버에 분산되기 때문에 트랜잭션 확장성도 향상된다
  - Z-axis Scaling은 장애 발생 시 일부만 데이터를 엑세스할 수 있기 때문에 장애 분리를 개선한다
  - RESTORE 테이블의 기본 키는 서로 다른 두 데이터베이스 서버 사이의 행을 분할하는 데 사용한다
- 단점
  - 애플리케이션의 복잡성이 증가한다
  - 데이터를 다시 분할해야 하는 경우 까다로울 수 있는 분할 방식을 구현해야한다
  - 개발 및 애플리케이션 복잡성이 증가하는 문제를 해결하지 못한다
