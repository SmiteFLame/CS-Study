# 빅데이터

디지털 환경에서 발생하는 대량의 모든 데이터

- 데이터에서 가치를 추출하고 결과를 분석하는 기술

## 4V

1. Velocity(속도): 데이터가 쌓이는 속도도 빠르고, 사라지는 속도도 빠름
2. Volume(양): TB에서 XB의 데이터
3. Variety(다양성): 정형, 비정형 데이터, 수치화가 힘든 데이터도 포함된다.
4. Veracity(진실성): 표본이 커서 정확성이 높다
5. Value(가치): 유용한 정보를 제공해야 한다.

## Data-Lake

대규모의 다양한 원시 데이터 세트를 기본 형식으로 저장하는 데이터 리포지토리 유형

- 정제되지 않은 데이터를 볼수 있고, 데이터에 대해 전체적인 대규모 리포지토리를 엔터프라이즈 환경에서 데이터 관리 전력을 보편화할 수 있다.

### 장점

1. 모든 데이터를 사유할 수 있다: 향후 데이터를 어떻게 사용할지 사전에 추측할 수 있다.
2. 모든 데이터를 공유할 수 있다: 모든 데이터가 모든 실무자와 연구자에게 열려있다.
3. 모든 데이터 접근 방식이 가능하다: 다양한 처리 엔진과 애플리케이션을 이용해 데이터를 탐색하고 필요에 따라 처리할 수 있다.

## Hadoop

분산 환경에서 빅데이터를 저장하고 처리할 수 있는 자바 기반의 오픈소스 프레임 워크

- 장애 허용: 확장성을 높이려고 하드 디스크 손상 같은 장비나 노드의 장애를 당연히 발생할 수 있는 일로 간주한다.
- 하둡 소프트웨어 라이브러리는 간단한 프로그래밍 모델을 사용하여 여러 대의 컴퓨터 클러스터에 대규모 데이터 세트를 분산 처리할 수 있게 해주는 프레임 워크이다.

### RDBS과의 차이점

1. 데이터 타입

- Hadoop: 정형, 반정형, 비정형 데이터
- RDBS: 정형 데이터

2. 스키마 적용하는 시기

- Hadoop: 읽을때 스키마 적용
- RDBS: 쓸때 스키마 적용

3. 좋은 사용법

- Hadoop: 대용량 데이터 처리
- RDBS: OLPT 데이터 처리나 복잡한 ACID 트랜잭션 적용

4. 속도

- Hadoop: 쓸 때 빠르다
- RDBS: 읽을 때 빠르다

### 하둡 분산형 파일 시스템(HDFS)

- 데이터 중복 저장이란 개념을 바탕으로 한 대규모 분산 파일 시스템
- 일반적인 파일 시스템을 가진 여러 노드를 묶어 하나의 분산 파일 시스템을 구축하도록 설계되었다.
- 하둡 네트워크 연결된 기기에 데이터를 저장하는 분산 시스템
- HDFS는 여러 기계에 대용량 파일을 나눠서 저장한다.
- 데이터를 여러 서버에 중복해서 저장함으로써 데이터 안정성을 얻는다.

1. 데이터의 풀 스캐닝을 지원하기 위해 파일 순차 읽기 속도가 빨라야 한다.
2. 데이터가 계산이 수행되는 곳으로 옮겨지는 게 아니라, 데이터가 저장된 곳에서 계산이 수행될 수 있게 파일 시스템의 노드들이 각자 자신이 저장한 데이터의 위치 정보를 충분히 교환해야 한다.
3. 노드의 장애를 소프트웨어 레이어에서 극복 해야한다.

- 네임노드: HDFS의 메타데이터를 관리하고 클라이언트가 HDFS에 저장된 파일에 접근할 수 있도록 한다.
  - 데이터를 저장할 떄 블록으로 나누어진 데이터를 여러 데이터 노드에 분산하여 저장한다.
- 데이터노드: 주기적으로 핫빗과 블록의 몰록 리포트를 보낸다. 네임노드드는 핫빗을 통해 데이터노드가 정상적으로 작동하는 지 확인한다.

- 데이터는 HDFS 내부에 Block 형태로 저장되며, HDFS에 의해 투명하게 복제되어 여러 노드에 분산된다.
- 분산 파일 시스템의 데이터를 읽거나 저장하려는 클라이언트는 필요한 HDFS 일부분과 직접 통신한다.
  - 단순히 파이 목록만 필요한 클라이언트는 네임노드에 직접 접속해 메타데이터를 요청한다.
  - 데이터를 읽거나 저장하려는 클라이언트는 네임노드에 필요한 블록의 위치를 요청한 후 이 블록들을 저장하는 서버들과 직접 통신한다.
  - 이러한 HDFS의 아키텍처는 병목현상의 가능성을 최대한 억제하면서 시스템 일부를 필요한 만큼만 사용할 수 있다는 장점이 있다.

추가 내용

1. HDFS는 데이터를 저장하면, 다수의 노드에 복제 데이터도 함께 저장해서 데이터 유실을 막는다.
2. HDFS에 파일을 저장하거나, 저장된 파일을 조회하려면 스트리밍 방식으로 데이터에 접근해야 한다.
3. 한번 저장된 데이터를 수정할 수 없고 읽기만 가능해서 데이터 무결성을 유지한다.
4. 데이터 수정은 불가능 하지만 파일 이동, 삭제, 복사할 수 있는 인터페이스르 제공한다.

- Master/slave 구조를 통해서 하나의 네임 노드와 파일 시스템을 관리하고 클라이언트의 접근을 통제하는 마스터 서버로 구성된다.

- 위치 투명성: 파일의 물리적인 섹터가 여러 장소에 나눠 저장해도 파일 이름만으로 파일에 접근할 수 있는 특징

- 사용자는 필요한 파일을 로컬 파일 시스템에서 HDFS로 직접 복사하거나, HDFS에서 로컬 파일 시스템으로 복사해야한다.
- HDFS는 파일의 데이터를 슬라이스로 분할해 하둡 클러스터의 여러 서버에 이중으로 저장한다.
- 데이터 분할과정에서 대용량 파일은 작은 단위의 블록으로 나눠 클러스터 노드에 '투명하게' 저장한다.
- HDFS는 여러 슬라이스를 동시에 병렬로 처리하므로 파일 연산을 더 빠르게 처리할 수 있다.

### Yarn

스케줄링과 리소스 관리로 데이터 지역성을 극대화 하고 계산량이 많은 애플리케이션이 리소스를 독점하지 않게 한다.

- 교체 가능한 스케줄링을 지원하며, 사용자당 리소스 제한이나 작업 대기열당 리소스 할당량 등 공용 리소스 시스템의 스케줄링에 필요한 기본적인 환경 설정을 입력할 수 있다.

- 클로스터의 리소스를 컨테이너로 분리한다.
- 컨테이너는 기본적으로 할당되는 CPU 코어 수와 메모리 용량으로 정의되며 추가 리소스가 포함될 수 있다.
- 실행중인 컨테이너들을 모니터링 하면서 컨테이너가 최대 할당량을 초과하지 않게 억제한다.

- YARN 애플리케이션은 특정 컨테이너가 특정 데이터를 저장하고 있는 서버에서 실행되도록 요청할 수 있다.

### Hive 테이블

HDFS에 저장된 파일과 디렉터리 구조에 대한 메타 정보를 저장한다.

- Hive는 HiveSQL이라는 SQL과 유사한 언어를 제공한다는 특징이 있다.

1. HDFS에 저장되어 수정할 수 없기 떄문에 UPDATE, DELETE는 불가능하다.
2. INSERT할 떄 빈 테이블에 입력하거나 입력된 데이터를 덮어쓰는 경우만 가능하다
3. HiveQL은 FROM 절에만 서브 쿼리를 사용할 수 있다.
4. HiveQL VIEW는 읽기 번용이다.
5. SELECT문을 사용할 때 HAVING절을 사용할 수 없다.
6. Stored Procedure를 제공하지 않으며 MapReduce 스크립트를 실행할 수 있다.

### 맵 리듀스(MapReduce)

- 대용량의 처리를 위한 분산 프로그래밍 모델, 소프트웨어 프레임워크
- 맵 리듀스 프레임워크를 이용하면 대규모 분산 컴퓨터 환경에서 대량의 데이터를 병렬로 분석 가능
- 프로그래머가 직접 작성하는 맵과 리듀스라는 두 개의 메소드로 구성

1. 흩어져 있는 데이터를 수직화
2. 그 데이터를 각각의 종류 별로 모은다(Map)
3. 필터링과 Sorting을 거쳐 데이터를 뽑아낸다(Reduce)

- 각각의 상태는 무생태성이거나 극히 제한적인 상태만 유지한다.
- 계산하는 Mapper나 Reducer는 현재 입력 받은 데이터를 이전에 받는 데이터와 무관하게 처리한다.
  - 각 단계의 Mapper 또는 Reducer가 어느 노드에서 실행될지 모르기 때문이다

과정

1. 텍스트 데이터가 HDFS에 저장
2. 하둡은 자동으로 데이터를 불록 단위로 쪼갠뒤에 HDFS 서버로 분산해 중복 저장
3. 여러 개로 분산된 매퍼가 각 블록의 병렬로 읽어 들여 텍스트 데이터에 포함된 단어를 Key-Value 쌍 하나로 만든다.
4. Key-Value가 생성되면 같은 키를 모두 모아 셔플링 한 후 Reducer에 전달한다.
5. 결과적으로 Reducer에 입력 데이터는 특정 단어를 가진 모든 Key-Value가 된다.

- Map단계: 입력 리스트들은 독립적인 블록으로 나뉘어 HDFS에 저장되어 있다. Mapper함수는 각 블록에 맞게 병렬로 저장된다.
- Reduce단계: Map단계의 출력 리스트가 Reduce 단계의 입력 리스트로 연결된다. 여러 Reduce가 사용될 경우, 입력 리스트는 키 값에 묶여 특정 Reducer로 전달된다.

- 반복이 많은 작업에 적합하지 않다
- 반복의 중간 결과를 항상 파일로 저장하고 프로그래머가 직접 여러 단계의 맴 리듀스의 워크 플로우를 관리하며 작업이 실패할 때

### 장점

1. 오픈 소스 라이선스에 대한 비용 부담이 적음
2. 시스템을 중단하지 않고, 장비의 추가가 용이(Scale Out)
3. 일부 장비에 장애가 발생하더라도 전체 시스템 사용성에 영향이 적음
4. 저렴한 구축 비용과 비용 대비 빠른 데이터 처리

### 단점

1. HDFS에 저장된 데이터 변경 불가
2. 실시간 데이터 분석 같이 처리해야 하는 작업에는 부적합
3. 너무 많은 버전과 부실한 서포트
4. 설정의 어려움

### Hadoop이 유리한 이유

1. 애플리케이션/트랜잭션 정보는 매우 크다 -> 대용량 파일을 저장할 수 있는 분산 파일 시스템을 제공한다.
2. I/O 집중적이면서 CPU를 많이 사용한다 -> 멀티 노드로 부하를 분산시켜 처리한다.
3. Scale Out에 유리하다 -> 장비를 추가하면 성능이 선형적으로 증가한다.
4. DB는 소프트웨어와 하드웨어가 비싸다 -> 저렴한 장비로도 처리가능하다.

## HBase

Hadoop의 HDFS위에 만들어진 분산 컬럼 기반의 데이터 베이스

- 구조화된 대용량 데이터에 빠른 임의 접근을 제공하는 구글의 빅 테이블과 비슷한 데이터 모델을 가지며, HDFS의 데이터에 대한 실시간 임의 읽기/쓰기 기능을 제공
- 사용자는 HBase나 HDFS에 직접 데이터를 저장할 수 있고, 사용자는 데이터를 읽고 접근하는 것은 HBase를 통한 임의 접근을 이용한다.

- 고정 컬럼 스키마가 없다.
- 수평적으로 확장성이 있어 큰 테이블에 적합하다.

- Transaction이 존재하지 않는다.
- RDBMS에 비해서 덜 구조화된 데이터에 적합하다

## Spark(Apache Spark)

인 메모리 기반의 대용량 데이터 고속 처리 엔진으로 범용 분산 클러스터 컴퓨팅 프레임 워크

- DISK I/O 기반으로 동작하는 Hadoop과 다르게 인메모리를 사용하여 속도가 최소 1000배는 빠르다.
- 데이터 실시간 스트리밍 처리 니즈를 충족한다.
- 하둡 + 스파크: 하둡의 Yarn 위에 Spark를 얹고, 실시간성이 필요한 데이터는 스파크로 처리하는 방식

### 등장 배경

- 하둡의 HDFS가 DISK I/O를 기반으로 동작하고 있는데 실시간 성 데이터에 대한 니즈가 급격히 들어나면서 하둡으로 처리하기에는 속도 측면에서 부적합하다.
- Spark는 DISK가 아닌 인메모리에서 사용하기 떄문에 반복적인 처리가 필요한 작업에서 속도가 빨라진다.
- 그래서 이제 하둡 + 스파크 라는 둘의 연계가 하나의 큰 흐름으로 자리 잡았다.

### Spark Application

실제 일을 수행하는 역할을 담당한다

1. Driver: 한 개의 노드에서 실행되며, 스파크 전체의 main 함수를 실행한다.

- 어플리케이션 내 정보의 유지 관리, 익스 큐터의 실행 및 실행 분석, 배포 등의 역할을 수행한다.

2. Executor: 다수의 worker 노드에서 실행되는 프로세스

- Driver가 할당한 작업을 수행하여 결과를 반환한다.
- Worker: 클러스터 내에서 Application을 수행 가능한 노드

- 1개의 스카프 어플리케이션은 1개의 Driver와 N개의 Executor가 존재한다.
- Executor는 Cluster Manager에 의하여 해당 스파크 어플리케이션에 할당된다.

- 해당 스파크 어플리케이션이 완전히 종료된 후 할당에서 해방된다
- 다른 스파크 어플리케이션 간의 직접적인 데이터 공유는 불가능하다.

- 즉, Driver는 main을 가동시키는 프로세스, Executor는 데이터를 디스크에 유지하는 프로세스

- SparkContext: 애플리케이션 간 리소를 제공하는 여러 유형의 클러스터 관리자에 연결할 수 있다.

  - 사용자의 주 함수를 실행하고 작업자 노드에서 다양한 병렬 작업을 실행한다.
  - 그리고 SparkContext 는 작업 결과를 수행한다.

- 드라이버 프로그램들은 연산 클러스터에 대한 연결을 나타내는 SparkContext 객체를 통해 스파크에 접속한다.

### Cluster Manager

스파크 어플리케이션 사이에 자원을 중계해주는 역할을 담당한다.

- 스파크 어플리케이션의 리소스를 효율적으로 분배하는 역할을 담당한다.
- Executor에 Task를 할당하고 관리하기 위해서 클러스터 매니저에 의존한다.

- 사용 가능한 클러스터 매니저: Spark StandAlone, Hadoop Yarn, Mesos, Kubernetes등

### 실행 과정

1. 사용자가 Spark-submit을 통해 어플리케이션을 제출한다.
2. Spark Driver가 main을 실행하며, Spark Context를 생성한다.
3. Spark Context가 Cluster Manager와 연결된다.
4. Spark Driver가 Cluster Manager로 부터 Executor 실행을 위한 리소스를 요청한다.
5. Spark Context는 작업 내용을 task 단위로 분할하여 Excutor에 보낸다
6. 각 Executor는 작업을 수행하고, 결과를 저장한다.

- 즉, 사용자 프로그램을 수행하기 위해서, Spark Driver 내의 Spark Context가 Job을 task 단위로 쪼갠다.
  - Cluster Maanger로 부터 할당받은 Executor로 task를 넘긴다.

### 구성요소

1. Spark Core: 메인 컴포넌트로 작업 스케쥴링, 메모리 관리, 장애 복구와 같은 기본적인 기능을 제공하고, RDD, Dateset, DataFrame을 이용한 스파크 연산을 처리한다.
2. Spark Library: 빅데이터 처리를 위한 라이브러리
   - park SQL: 이를 이용하여 작업을 생성하고 처리한다.
   - park Streaming: 실시간 데이터 스트림을 처리하는 컴포넌트이다.
   - MLib: 스파크 기반의 머신러닝 기능을 제공하는 컴포넌트이다.
   - GraphX: 분산형 그래프 프로세싱이 가능하게 해주는 컴포넌트이다.
3. Cluster Manager: 스파크 작업을 운영하는 클러스터 관리지이다

### 장점

1. 인메모리 기반의 데이터 처리로 빠르다

- 인메모리: 데이터스토리지의 메인 메모리에 설치되어 운영되는 방식의 데이터베이스 방식 관리 시스템
  - 즉, 하드 디스크가 아닌 메인 메모리에 올려서 서비스를 수행 하는 것을 말한다.

2. 어플리케이션 형태의 빅데이터 통합환경을 제공
3. 실시간 데이터 프로세싱 지원
4. sparkml이라는 머신러닝 패키지 지원
5. Scala기반으로 작성되어 있음, 어플리케이션 코드로는 JAVA, Python 지원
6. Hadoop의 데이터 저장소와 아주 쉽게 연동된다.

### 단점

1. 자체 파일 시스템이 존재하지 않는다: 데이터를 가져오거나 저장할 때 Hadoop을 연동하여 사용해야 한다.
2. 비싸다: 데이터가 클 경우 병목현상이 일어난다.
3. 빈약학 ML 알고리즘
4. 데이터 처리가 유저에게 편리하지 않다.
5. 학습 비용이 크다.

## Kafka

LinkedIn에서 개발한 분산 메시징 시스템으로 대용량 실시간 로그처리에 특화된 아키텍처 설계를 통하여 기존 메시징 시스템보다 우수한 TPS를 보여준다.

- 분산 스트리밍 플랫폼
- 데이터 파이프 라인 구성시, 주로 사용되는 오픈소스 솔루션
- 대용량의 실시간 로그처리에 특화되어 있는 솔류션
- 데이터 유실없이 안적하게 전달하는 것이 주목적인 메시지 시스템
- 클러스티링이 가능하므로, Fault-Tolerant한 안정적인 아키텍처와 빠른 퍼포먼스로 데이터처리
- 수평적으로 서버의 Scale-Out이 가능함
- pub-sub 모델의 메시지 큐

### 구성 요소

- Event: Consumer가 데이터를 주고 받는 단위
- Producer: 이벤트를 게시(Post)하는 클라이언트 어플리케이션을 의미한다.
- Consumer: 이러한 Topic을 구독하고 이로 부터 얻어낸 Event를 처리하는 클라이언트 어플리케이션
- Topic: Event가 쓰이는 곳, Producer는 이 Topic에 Event를 게시한다.
  - Consumer는 Topic으로 부터 이벤트를 가져와 ㅓ리한다.

### 빅데이터 관련 내용 정리

- Hadoop: 대용량의 데이터를 적은 비용으로 더 빠르게 분석할 수 있는 플랫폼
  - 여러 대의 컴퓨터로 데이터를 분석하고 저장하는 방식(HDFS)
- HBase: HDFS위에 만들어진 분산 컬럼 기반의 데이터베이스
- Kafka: 실시간으로 기록 스트림을 게시, 구독, 저장 및 처리할 수 있는 분산 데이터 스트리밍 플랫폼
- Spark: 빅데이터 처리를 위한 오픈소스 분산 처리 플랫폼
  - Spark는 MapReduce에 대한 Hadoop 강화 기능이다.
  - Spark는 데이터를 처리하고 메모리에 보관하면서 속도가 최대 100배 정도 빠르다
