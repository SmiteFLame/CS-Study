# 운영체제

- 컴퓨터 시스템의 자원들을 효율적으로 관리하고 사용자가 컴퓨터를 편리하고 효과적으로 사용할 수 있도록 환경을 제공해주는 프로그램들의 모임
- 컴퓨터 사용자와 컴퓨터 하드웨어간의 인터페이스로서 동작하는 시스템 소프트웨어의 일종, 다른 응용프로그램이 유용한 작업을 할 수 있도록 환경을 제공해준다

<br>

## 프로세스

- 실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU의 할당을 받을 수 있는 것을 말한다.
- 운영체제로 부터 주소공간, 파일, 메모리등을 할당받으며 이것들을 총칭하여 프로세스라고 한다.

PCB

- 특정 프로세스에 대한 중요한 정보를 저장하고 있는 운영체제의 자료구조
- 프로세스 전환이 발생하게 되면 진행 중인 작업을 PCB에 저장하고 CPU를 반환한다.
  - PID - 프로세스 식별번호
  - 운영체재는 프로세스를 관리하기 위해 프로세스 생성과 동시에 고유한 PCB를 생성한다.
  - 프로세스 상태 (NEW, READY, RUNNING, WAITING, TERMINATED)
  - 프로그램 카운터 - 프로세스가 다음에 실행할 명령어 주소
  - CPU 래지스터
  - CPU 스캐쥴링 정보 - 프로세스의 우선순위, 스케쥴 큐에 대한 포인터 등
  - 메모리 관리 정보 - 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보 포함
  - 입출력 상태 정보 - 프로세스에 할당된 입출력 장치들과 열린 파일 목록
  - 어카운팅 정보 - 사용된 CPU 시간, 시간제한, 계정정보 등

<hr>

## 스레드

- 프로세스의 실행단위
- 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유할 수 있다.
  - 스레드 ID
  - 프로그램 카운터
  - 레지스터 집합
  - 스택
- 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션 열린 파일이나 신호과 같은 OS자원 공유
- 멀티 스레딩인 경우 독립적인 자원을 수행해야 하기 때문에 각각의 스택과 PC 래지스터를 가지고 있다.

스택을 스레드마다 독립적으로 할당하는 이유

- 스택은 함수 호출시 전달되는 인자, 되돌아갈 주소값 및 함수 내에 선언하는 변수를 저장하기 위해 사용되는 메모리 공간이므로 독립적인 함수 호출이 가능하다. 스레드마다 독립적인 변수와 함수 호출을 가능하게 하기 위해서 독립된 스택을 가지고 있다.

PC Register를 스레드마다 독립적으로 할당하는 이유

- PC값은 스레드가 명령어의 어디까지 수행하였는지 나타나게 한다. 스레드는 CPU를 할당했다가 스케줄어에 의해 다시 선점된다. 그렇기 때문에 명령어가 연속적으로 수행되지 못했기 때문에 어느 부분까지 수행했는지 기억할 필요가 있다.

### Context Switching (OS 스케쥴러 주체)

- 필요한 이유
  - 해당 Task(Process, Thread)가 끝날 떄 까지 다음 Task를 기다릴 수 없다.
  - CPU가 task를 바꿔가면서 시행하기 위해서 사용한다.
- 현재 진행하고 있는 Task의 상태를 저장하고 다음 진행할 Task 상태의 값을 읽어 적용하는 과정
- Task의 대부분의 정보는 Register에 저장되고 PCB로 관리되고 있다.
- 현재 실행하고 있는 Task의 PCB정보를 저장한다(Process Stack, Ready Queue)
- 다음 실행할 PCB 정보를 읽어 Register에 적재하고 CPU가 이전에 진행했던 과정을 연속으로 수행할 수 있다.
- Process가 Thread보다 많이 든다.
  - Thread는 Stack영역을 제외한 모든 메모리를 공유하기 때문
  - Context Switching 발생시 Stack영역만 변경하면 되기 때문에

### Interrupt

- CPU가 프로그램을 실행하고 있을 때 실행중인 프로그램 밖에서 예외 상황이 발생하여 처리가 필요한 경우 CPU에게 알려 예외상황을 처리
- 어떤 인트럽트 요청이 와야 Context Switching이 일어나는지
  - I / O 요청
  - CPU시간 만료
  - 자식 프로세스를 만들 떄
  - 인터럽트 처리를 기다릴 때

<hr>

## 멀티 스레드

장점

- 프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모가 줄어든다.
- 스레드간 통신이 필요한 경우에도 별도의 자원 공간을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 Heap영역을 이용하여 데이터를 주고 받을 수 있다.
- 스레드의 context switch는 프로세스 context switch와 달리 캐시 메모리를 비울 필요가 없어서 더 빠르다.
- 결론: 시스템의 throughtput(처리량)이 향상되고 자원 소모가 줄어들어 자연스럽게 프로그램 응답시간이 단축된다.

단점

- 멀티 프로세스 기반으로 프로그래밍 할 때는 프로세스간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일이 없지만 멀티 스레드는 이 부분을 신경 써야 한다.
- 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다.
- 멀티스레딩 환경에서는 동기화 작업이 필요하다. 동기화를 통해 작업 처리 순서를 컨트롤 하고 공유 자원에 대한 접근을 컨트롤 하는 것이다.
- 하지만 이로 인해 병목현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 락으로 인한 병목현상을 줄여야 한다.

### 프로그램과 프로세스의 차이

프로그램 - 파일 시스템에 존재하는 실행파일 - 동작되고 있지 않은 정적인 객체

프로세스 - 그 프로그램을 실행 시키는 주체, 메모리에 올라와서 CPU를 할당받고 프로그램이 실행되고 있는 것으로 실행중인 프로그램을 의미한다. - 동작하고 있는 동적인 객체

### 프로세스와 스레드의 차이

프로세스 - 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램, 운영체제로 부터 시스템 자원을 할당받는 작업의 단위

스레드 - 프로세스 내에서 실행되고 있는 여러 흐름 단위, 프로세스가 할당받은 자원을 이용하는 실행의 단위

### 멀티 프로그래밍 VS 멀티 프로세싱

멀티 프로그래밍은 하나의 프로세서에 하나 이상의 프로그램을 동시에 수행시킨다. 멀티 프로그래밍 시스템은 여러 개의 프로그램을 메인 메모리에 저장해 놓고 프로세서를 여러 개의 프로그램들 사이로 빠르게 스위치하여 프로그램을 동작시킨다.

멀티 프로세싱은 하나의 프로세스가 아닌 여러개의 프로세스들을 가지고 하나 이상의 프로그램을 수행할 때 사용한다. 여러개의 프로세스가 협력하여 프로그램을 동시에 수행함으로써 효율적이고 빠르게 프로그램을 진행할 수 있다.

### 멀티 스레드 VS 멀티 프로세스

- 멀티스레드는 적은 메모리 공간을 차지하여 문맥 전환이 빠르다. 반면에, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료되는 점과 동기화문제를 가지고 있다.
- 멀티프로세스는 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼지치 않고 정상적으로 수행된다는 장점이 잇지만, 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지하는 단점이 존재한다.

- 멀티 프로레스는 OS에서 할당 받은 자신의 메모리를 가지고 실행하기 떄문에 독립적
- → 하나 오류나도 독립적으로 다른 프로세스들이 실행될 수 있다.

- 동시에 여러 작업을 수행한다는 점에서는 같지만 적용해야되는 시스템에 따라 적합/부적합이 구분된다. 시스템의 특징에 따라서 잘 골라야 된다.
- 프로그램을 여러개 키는 것보다 하나의 프로그램 안에서 여러 작업을 해결하는 것이 좋다.

결론

1. 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어든다.
2. 프로세스 간의 통신(IPC)보다 스레드 간의 통신의 비용이 적으므로 작업들 간의 통신 부담이 줄어든다.

동시성 - 단일 CPU 코어에서 두 개의 task가 동시에 진행되는 것 처럼 보이게 한다.

병렬처리 - 둘 이상의 CPU 코어에서 두 개의 task가 동시에 진행되고 있다.

<hr>

## 스캐줄러

1. Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
2. Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
3. Device Queue: Device I/O 작업을 대기하고 있는 프로세스의 집합

장기 - 저장되어 있는 프로세스중에서 어떤 프로세스스를 Ready Queue로 보낼지

단기 - Ready Queue에서 어떤 프로세스를 running시킬지 결정

중기 - 여유 공간을 위해서 어떤 프로세스를 메모리에서 디스크로 보낼지

### 장기 스케줄러(Job Scheduler)

- 메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라온 경우, 대용량 메모리에 임시 저장
- 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 Ready Queue로 보낼지 결정하는 역할
  - 메모리와 디스크 사이의 스케줄링 할당
  - 프로세스에 memory를 할당
  - 실행중인 프로세스의 수 제어
  - 프로세스의 상태 (new → ready)

### 단기 스케줄러(CPU scheduler)

- CPU와 메모리 사이의 스케줄링 담당
- Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running시킬지 결정
- 프로세스에 CPU를 할당
- 프로세스의 상태 (Ready → Running → Waiting → Ready)

### 중기 스케줄러(Swapper)

- 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄(Swapping)
- 프로세스에게서 memory를 deallocate
- degree of Multiprogramming 제어
- 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러
- 프로세스 상태(Ready → Suspened)

Suspened(Stopped)

- 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 swap out된다.
- blocked상태는 다른 I/O 작업을 기다리는 상태로 스스로 Ready State로 돌아갈 수 있지만 Suspened는 외부적인 이유이기 때문에 스스로 돌아갈 수 없다.

비선점형 스케줄링 - 일단 CPU를 잡으면 CPU brust가 완료될 때 까지 CPU 반환하지 않는다.

<hr>

## CPU Scheduler

FCFS

- 먼저 온 고객을 먼저 서비스해주는 형식
- 비선점형 스케쥴링
- 문제점
  - Convoy Effect: 소요시간이 긴 프로세스가 먼저 도다하여 효율성을 낮추는 현상이 발생한다.

SJF

- 다른 프로세스가 먼저 도착했어도 CPU burst time이 가장 짧은 프로세스에게 선 할당
- 비선점형 스케줄링
- 문제점
  - Stravation: 사용시간이 긴 프로세스는 거의 영원히 CPU를 할당 받을 수 없다.

SRTF

- 새로운 프로세스가 도착할 때마다 새로운 스케쥴링이 이루어진다.
- 선점형 스케줄링
  - 현재 수행중인 프로세스의 남은 burst time보다 더 짧은 CPU burst time을 가지는 새로운 프로세스가 도착하면 CPU를 뺏긴다.
- 문제점
  - Stravation
  - 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time을 측정할 수 없다.

Priority Scheduling

- 우선순위가 높은 프로세스에게 CPU를 할당하는 스케줄링
- 선점형 스케줄링
  - 더 높은 우선순위가 도착하면 CPU 선점 교체
- 비선점형 스케줄링
  - 더 높은 우선순위가 도착하면 Ready Queue의 Head에 넣는다.
- 문제점
  - Stravation
  - Indefinite blocking: 실행 준비는 되어 있으나 CPU를 사용못하는 프로세스를 CPU가 무기한 대기하는 상태

Round Robin

- 현대적인 CPU 스케줄링
- 각 프로세스는 동일한 크기의 할당 시간을 갖게 된다.
- 할당 시간이 지나면 프로세스는 선점당하고 Ready Queue의 제일 뒤에 가서 줄을 선다
- RR은 CU 사용시간이 랜덤한 프로세스들이 섞여 있을 경우에 효율적
- RR이 가능한 이유는 프로세스의 context를 save할 수 있기 때문
- 장점
  - Response time이 빨리진다
  - n개의 프로세스가 ready queue에 있고 할당시간이 q인 경우 각 프로세스는 q단위로 CPU 시간의 1/n을 얻는다. 어떤 프로세스도 (n - 1)
- time quantunm이 너무 커지면 FCFS와 같아진다. 너무 작으면 context switch가 너무 많아서 overhead가 발생하므로 적당한 사이즈를 찾아야 한다.

<hr>

## 동기, 비동기

동기 - 메소드 실행함으로써 반환값을 기대한다

요청과 결과가 동시에 알어난다

비동기 - 메소드를 실행함으로써 반환값을 기대하지 않는다.

다른 스레드에게 요청하면 지금 스레드는 논블록 상태가 된다.

- 메소드를 실행시킴과 동시에 반환 값을 기대하고 있는 경우를 동기, 아니면 비동기라고 한다
- 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 blocking되어 있다는 것을 의미한다.
- 비동기의 경우, blocking되지 않는 이벤트 큐에 넣거나 백 그라운드 스레드에게 해당 task를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값을 바로 반환되지 않는다.

동기

- 동시에 일어나는 일- 요청과 결과가 동시에 일어난다.

비동기

- 동시에 일어나지 않는 것(비동기화) → CS같은 곳에 넣어주는 것
- 다른 스레드에게 요청하면 지금 스레드는 논블록 상태가 된다.

## 프로세스 동기화

Critical Section

- 멀티 스레딩에 문제점에서 나오듯, 동일한 자원을 동시에 접근하는 작업을 실행하는 코드 영역을

상호배제, 진행, 한정된 대기

Critical Secion 문제 해결 기본 조건

1. Mutual Exclusion(상호 배제) - 프로세스 P1이 실행중이라면 다른 프로세스는 들어갈 수 없다.
2. Progress(진행) - CS에 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스만 CS 진입 후보가 된다.
3. Bounded Waiting(한정된 대기) - P1가 CS에 진입 신청 후 받아 들여질 때까지, 다른 프로세스들이 CS에 진입하는 회수는 제한이 있어야 된다.

해결책

1. Lock - 하드웨어 기반 해결책으로써, 동시에 공유 자원에 접근하는 것을 막기 위해 CS에 진입하는 프로세스는 Lock을 획득하고 CS을 빠져 나올 때, Lock을 방출함으로써 동시에 접근이 되지 않도록 한다
   1. 한계 - 다중 처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없다.
2. Semaphores(세마포어)

   1. 소프트웨어 상에서 CS문제를 해결하기 위한 동기화 도구

3. Counting Semaphores
   1. 가용한 개수를 가진 자원에 대한 접근 제어용으로 사용되며, 세마포어는 그 가용한 개수로 초기화 한다. 자원을 사용하면 세마포어가 감소, 방출하면 세마포어가 증가한다.
4. Binary Semaphores(Mutex)
   1. 상호배제의 머리글자를 따서 만들어 졌으며, 이름 그대로 0과 1 사이의 값만 가능하다. 다중 프로세스 사이에서 CS문제를 해결하기 위해 사용한다.

### 세마포어 VS 뮤텍스

- 여러 프로세스나 쓰레드가 공유 자원에 접근하는 것을 제어하는 방법

세마포어 - 공유 자원에 세마포어의 변수만큼의 Task가 접근 할 수 있다.

다른 프로세서가 세마포어를 해제할 수 있다.

뮤텍스- 오직 1개의 Task만 접근 할 수 있다.

락을 획득한 프로세스가 반드시 그 락을 해제해야한다.

단점 - Busy Waiting(바쁜 대기)

- Spin Lock이라 불리는 Semphores 초기버전은 CS에 진입해야 하는 프로세스는 진입 코드를 계속 반복 실행해야 되어 시간 낭비를 했었다. 이를 Busy Waiting이라고 부른다.
- 이제 한번 CS진입에 시도하면 block에 두었다가 CS에 자리가 나오면 다시 깨우는 방식으로 Busy Waiting으로 인한 시간 낭비 문제가 해결된다.

Deadlock(교착상태)

- 세마포어가 ReadyQueue에 있고, 둘 이상의 프로세스가 cS진입을 무한정 기다리고 있고, CS에 실행되는 프로세스는 진입 대기 중인 프로세그가 실행되어야만 빠져 나올 수 있는 상황을 지칭한다.

교착 상태 조건

1. 상호 배제 - 한 번에 한 프로세스만 공유 자원할 수 있다.
2. 점유 대기 - 공유 자원에 대한 접근 권한을 갖고 있는 프로세스가, 그 접근 권한을 양보하지 않은 상태에서 다른 자원에 대한 접근 권한을 요구할 수 있다.
3. 비선점 - 한 프로세스가 다른 프로세스의 접근 권한을 강제로 취소할 수 없다.
4. 순환대기 - 두 개 이상의 프로세스가 자원 접근을 기다리는데, 그 관계에 사이클이 존재한다.

모니터

- 고급 언언의 설계 구조물로서, 개발자의 코드를 상호 배제 하게끔 만든 추상화된 데이터 형태이다.
- 공유자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다. (세마포어는 직접 키 해제와 공유 자원 접근 처리가 필요하다.)

해결방법

1. 교착 상태 예방, 회피

- 예방: 교착 상태 조건중 하나의 조건들 중에서 하나를 무시한다.
- 회피: 교착 상태를 예상하여 안전한 상태에서만 자원을 요청한다.
  - 자원 할당 알고리즘
  - 은행원 알고리즘

2. 교착 상태 탐지, 복구

- 탐지
  - 대기 그래프
  - 은행원 알고리즘
- 복구
  - 프로세스 종료
  - 자원 선점
    - 희생자 선택: 최소의 피해를 줄 수 있는 프로세스를 선택
    - 롤백: 선점된 프로세스는 문제 없던 이전 상태로 롤백
    - 기아 상태: 한 프로세스가 계속 선점되는 것을 방지

3. 교착 상태 무시

<hr>

## 메모리 영역

1. 코드 영역 - 실행할 프로그램의 코드가 저장되는 영역

   사용자가 프로그램 실행 명령을 내리면 OS가 실행코드를 올리고 CPU는 코드 영역의 저장된 명령어를 하나식 처리한다.

2. 데이터 영역 - 프로그램의 전역(global), 정적(static) 변수가 저장되는 영역
   - 프로그램 시작과 동시에 할당되며, 프로그램이 종료되면 소멸
3. 힙 영역 - 프로그래머가 직접 관리할 수 있는 메모리 영역, 동작 할당되는 영역\

   반드시 사용자가 직접 관리할 수 있는 그리고 해야만 하는 영역

   JAVA는 가비지 컬랙터가 자동을 해제해준다.

   힙 영역은 스택 영여과 달리 낮은 주소에서 높은 주수로 메모리가 할당된다.

   - 직접 관리할 수 있는 영역, 사용자에 의해 메모리 공간이 동적으로 할당된다.

4. 스택 영역 - 함수의 호출과 함께 할당되며 지역 변수와 매개 변수가 저장되는 영역

   스택 영역에 호출 정보를 스택 프레임이라고 한다.

   스택 영역은 함수의 호출이 완료되면 소멸한다.

   스택 영역은 높은 주소에서 낮은 주소로 메모리가 할당 된다.

   - 함수의 호출과 함께 할당되며 함수의 호출이 완료되면 소멸

데이터 영역 - 프로그램 시작과 동시에 할당, 종료되면 소멸 (전역, static)

힙 - 할당해야 할 메모리 크기를 프로그램 실행중에 결정

스택 - 함수 호출시 생성(지역, 매개)

낮은 주소 - 코드영역 → 데이터 영역 → 힙 영역 → 스택 영역 → 높은 주소

높은 주소 → 함수가 호출 될 때 스택 메모리를 반활 할대 전체적인 스택 메모리 상의 변경이 없어야 되기 때문

→ 중요한 커널 영역을 침범하지 않으면서 전체적인 영역을 일정하게 하기 위해

### 스택 VS 힙

힙

- 메모리 크기 제한 없음, 변수를 전역적으로 액세스 할 수 있다.

스택

- 매우 빠른 액세스, 지역변수만, 크기조정 X
- 공간은 CPU에 의해 효율적으로 관리, 단편화 X

<hr>

## 메모리 관리 전략

각각의 프로세스는 독립된 메모리 공간을 갖고

운영 체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다.

단지, 운영체제만이 운영체제 메모리 영역과 메모리 영역의 접근에 제약을 받지 않는다

### Swapping

- 메모리 관리를 위해 사용 되는 기법, 표준 Swapping으로는 RR과 같은 스케쥴링의 다줄 프로그래밍 환경에서 CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억 장치로 내보내고 다른 프로세스의 메모리를 불러 들일 수 있다.
- 즉, 일부의 작업만 메인 메모리에 올리고 나머지는 다른 저장 공간에 필요할 떄 불러와 사용하게 된다.

### 단편화

- 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 만큼의 자유 공간들이 늘어나게 되는 현상
- 외부 단편화
  - 메모리 공간 중 사용하지 못하게 되는 일부분, 물리 메모리에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 분산되어 있을 때 발생한다
- 내부 단편화
  - 프로세스 사용하는 메모리 공간에 포함된 남는 부분. 예를 들어 메모리 분할 자유 공간이 10000B있고 ProcessA가 9998B를 사용하게 되면 남은 2B차이가 존재한다. 이를 내부 단편화라고 한다.
- 압축 - 외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유 공간을 확보하는 방법론이지만, 작업 효율이 좋지 한다.

### 페이징(Paging) - 외부 단편화 해결

- 하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없애는 메모리 관리 방법이다.
- 외부 단편화와 압축 작업을 해소하기 위해서 생긴 방법론으로, 물리 메모리는 Frame이라는 고정 크기로 분리되어 있고, 논리 메모리는 페이지라 불리는 고정 크기 블록으로 분리 된다.
- 페이징 기법을 사용함으로써 논리 메모리는 물리 메모리에 저장될때 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결할 수 있다는 큰 장점
- 하나의 프소세스가 사용하는 공간은 여러개의 페이지로 나뉘어서 관리되고(논리 메모리에서), 개별 페이지는 순서에 상관 없이 물리 메모리에 있는 프레임 mapping되어 저장된다고 볼 수 있다.
- 단점: 내부 단편화 문제의 비중이 늘어나고 있다. 예를 들어 페이지 크기가 1024B이고 프로세스 A가 3172B의 메모리를 요구한다면 3개의 페이지 프레임(1024 \* 3 = 3072)하고도 100B가 남기 때문에 4개의 페이지 프레임이 필요하다 결론적으로 4번째 프레임은 924B의 여유 공간이 남게 되는 내부 단편화가 생긴다

### 세그멘테이션(Segmentation) - 내부 단편화 해결

- 페이징 처럼 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트(Segment)로 분할 사용자가 두 개의 주소를 지정(세그먼트 번호 + 변위) 세그먼트 테이블에는 각 세그먼트의 기준과 한계를 저장
- 단점: 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되면, 자유 공간들이 많은 수의 작은 조각들로 나누어져 못쓰게 될 수 있다.

### 페이징 VS 세그먼테이션

페이징은 가상 메모리에서도 물리 메모리와 마찬가지로 고정된 크기인 프레임 단위로 나눠서 관리하는 것이고 세그멘테이션은 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌 서로 다른 크기의 논리적 단위인 세그먼트로 분할이된다.

<hr>

## 가상메모리

- 다중 프로그래밍을 실행하기 위해서 많은 프로세스들을 동시에 메모리에 올려두어야 한다.
- 가상 메모리는 프로세스는 프로세스 전체가 메모리내에 올라오지 않더라도 실행가능하도록 하는 기법

- 실행되는 코드를 전부 물리 메모리에 올리지 않고 메모리 용량보다 큰 프로그램을 실행시기키 위해서 사용 된다.
- 용량의 한계와 페이지 교체등의 성능 이슈를 해결할 수 있다.

가상메모리가 하는 일

- 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것으로 정리할 수 있다.
- 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다.

가상 주소 공간

- 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상 메모리에 구현한 공간이다.
- 프로세스가 요구하는 메모리 공간을 가상 메모리에서 제공함으로서 현재 직접적으로 필요치 않는 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리를 절약할 수 있다.
- 100KB가 요구 되었다고 했을 때 메모리공간(heap, stack, code, data\_가 40KB라고 한다면, 실제 물리 메모리에는 40KB에 올라가 있고, 나머지 60KB 만큼은 필요시에 물리 메모리에 요구한다고 한다.

### 페이지

- 가상 메모리를 일정한 크기로 나눈 블록
- 페이2지의 크기는 시스템에 따라 다르며 크기가 작으면 메모리 단편화하기 쉬워지지만, 많이지면 입출력이 자주 발생한다

### 패이지 폴트

프로그램이 자신의 주소 공간(가상메모리 공간)에는 존재하지만 시스템의 RAM에는 현재 없는 데이터나 코드에 접근을 시도한 경우에 발생하는 현상, 페이지 볼트가 발생하면 운영체제는 그 데이터를 메모리로 가져와서 마치 페이지 폴트가 전혀 발생하지 않는 것처럼 프로그램이 계속적으로 동작하게 해준다.

### 프로세스간의 페이지 공유

- 시스템 라이브로리가 여러 프로세스들 사이에 공유 될 수 있다고 한다.
- 각 프로세스들은 공유 라이브로리를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가 있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다.
- 프소세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해서 통신할 수 있다.
- 각자 자신의 주송간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다.
- fork()를 통한 프로세스 생성과정에서 페이지들이 공유되는 것을 가능하게 한다.

### 요구페이징

- 프로그램 실행 시작시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략 → 가상 메모리 시스템에서 많이 사용된다.
- 요구 페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들을 적재된다.
- 한 번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않는다.

- 프로세스 내의 개별 페이지들을 페이저에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어 옮으로서, 사용되지 않을 페이지를 가져오는 시간 낭비와 메모리 낭비를 줄일 수 잇다.

### 패이지 교체

- 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 때문에, 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 Page Fault가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 된다.
- 만약, 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 이뤄줘야 한다.

기본적인 방법

1. 디스크에 필요한 페이지 위치를 찾는다.
2. 빈 페이지 프레임을 찾는다.
   1. 페이지 교체 알고리즘을 통해 희생될 페이지를 고른다.
   2. 희생될 페이지를 디스크에 기록하고 관련페이지 테이블을 수정한다.
3. 새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 테이블을 수정한다.
4. 사용자 프로세스 시작

FIFO 페이지 교체

- 먼저 물리 메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 된다는 것이다.
  - 장점
    - 이해하기도 쉽고, 프로그램 하기도 쉽다.
  - 단점
    - 오래된 페이지가 항상 불필요하지 않는 정보를 포함하지 않을 수 있다.
    - 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 부재율을 높이는 부작용을 초래할 수 있다.
    - Belady 모순 - 페이지를 저장할 수 있는 페이지 프레임 개수를 늘려도 되려 페이지 부재가 더 많이 발생하는 모순이 존재한다.

최적 페이지 교체(OPT, Optimal Page Replacement)

- 모든 알고리즘보다 낮은 페이지 부재율을 보이며 Belady의 모순이 발생하지 않는다.
- 아픙로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체하는 것
  - 장점
    - 알고리즘 중 가장 낮은 페이지 부재율을 보장한다.
  - 단점
    - 구현의 어려움이 있다.
    - 모든 프로세스의 메모리 참조의 계획을 미리 파악할 방법이 없기 때문

LRU(Least-Recently-Used)

- 최적 알고리즘의 근사 알고리즘으로, 가장 오랫동안 사용되지 않 페이지를 선택하여 교체한다.
- FIFO알고리즘보다 우수하고 OPT알고리즘보다 우수하지 않다.

LFU(Least-Freqently-Used)

- 참조 횟수가 가장 적은 페이지를 교체하는 방법. 활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정에서 만들어진 알고리즘
- 어떤 프로세스가 특정 페이즈를 집중적으로 사용하다, 다른 기능을 사용하게 되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다.
- 최적 페이지 교체를 제대로 근사하지 못하기 떄문에, 잘 쓰이지 않는다.

MFU(Most-Frequently-Used)

- 참조회수가 가장 작은 페이지가 최근 메모리에 올라왔고, 앞으로 계속 사용할 것이라는 가정에 기반한다.
- 최적 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다.

<hr>

## 캐시의 지역성 원리

- 캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도 차에 따른 병목 현상을 줄이기 위한 범용 메모리
- CPU가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다.
- 캐시의 성능은 작은 용량의 캐시 메모리에 CPU가 이후에 참조할, 쓸모 있는 정보가 어느 정도 들어있느냐에 따라 좌우되기 때문이다.

- 적중률을 극대화 시키기 위해 데이터 지역성 원리를 사용한다.
- 지역성의 전제조건으로 프로그램은 모든 코드나 데이터를 균등하게 Acess하지 않는다는 특성을 기본으로 한다.
- Locality란 기억 장치 내의 정보를 균일하게 Access하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성인 것이다.

- 이 데이터 지역성은 대표적으로 시간 지역성(Temporal Locality)과 공간 지역성(Spatial Locality)로 나뉜다.
- 시간 지역성 - 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성
- 공간 지역성 - 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용을 다시 참조되는 특성

### Caching line

- Cahce는 프로세스 가까이에 위치하면서 빈번하게 사용되는 데이터를 나두는 장소이다.
- 캐시가 아무리 가까이 있더라도 찾고자하는 데이터가 어느 것에 저장되어 있는지 몰라 데이터를 순화해야해서 시간이 오래걸리게 된다.
- 캐시에 목적데이터가 저장되어 있다면 바로 접근하여 출력할 수 있어야 캐시가 의미 있어진다는 것이다.

- 캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 묶음으로 저장하게되는데 이를 캐싱라인이라고 한다.
- 프로세스는 다양한 주소에 있는 데이터를 사용하므로 빈번하게 사용하는 데이터의 주소 또한 흩어져 있다.
- 따라서 캐시에 저장하는 데이터에는 데이터의 메모리 주소등을 기록해 둔 태기를 달아놓을 필요가 있다.
- 이러한 태그들의 묶음을 캐시라인이라고 하고 메모리로 부터 가져올 때도 캐싱 라인을 기준으로 가져온다.

1. Full Associative
2. Set Associative
3. Direct Map

<hr>

## System call

- 운영체제의 서비스에 접근하기 위한 인터페이스
- 권한이 낮은 응용 SW가 커널에 제공하는 서비스를 사용하는 방법

### 커널

- 운영체제의 핵심이 되는 컴퓨터 프로그램
- 부팅하는 동안 메모리를 로드하는 운영체제의 첫 부분
- 지속적으로 읽어들일 수 있도록 되어 있으며, 메모리 상에서 사용자가 접근할 수 없도록 커널 영역에서 보호됨

<hr>

## IPC

1. Pipe - 익명의 파이프를 통해 동일한 PPID를 가진 프로세스간 단방향 통신

   부모 자식간의 통신

2. Named PIPE - 이름을 가진 PIPE들과 단방향 통신

   서로 다른 프로세스들이 PIPE 이름만 알면 통신이 가능하다

3. Message Queue - 메모리를 사용한 PIPE

   커널에서 제공하는 메모리 큐 여서 EnQueue하는데 제안이 있다.

4. 공유 메모리 - 공유 메모리가 데이터 자체를 공유한다.

   일정한 크기의 메모리를 프로세스간 공유, 커널이 관리, 서로 Read, Write 할때 사용

5. 메모리맵 - 파일을 프로세스의 메모리에 일정 부분 맵핑 시켜 사용

   대용량 파일에 사용,

6. 소켓 - 네트워크 소켓 통신을 사용한다.

   네트워크 소켓, Client - Server 구조를 갖는다.

   네트워크 프로그래밍 가능해야함

7. 세마포어 - 프로세스간 데이터를 동기화하고 보호하는데 목적

## 32Bit vs 64Bit

bit: 컴퓨터 처리 정보의 최소 단위

- 차이: 저장 장치의 bit 폭 차이
- 즉, 레지스터의 처리값이 32bit 인지 64bit 인지 차이점이 있다

- 32bit는 2의 32승까지 한번에 표현이 가능하기 때문에 4GB까지 가능하다
- 64bit는 32bit의 32제곱으로 기하급수적으로 엄청 크게 된다
- 즉, 32bit에서 RAM은 4GB까지 인식이 가능했지만 64bit에서는 더 크게 가능하다

### 32bit에서 64bit로 한번에 크게 넘어가게 된 이유?

## 공유 메모리

IPC의 일종으로 프로세스간 통신 할때 사용한다.

### 데이터 공유 방식

- 커널에 생성된 공유 메모리를 통해서 데이터를 공유한다.
- 공유된 메모리 영역을 통해서 통신이 가능하다.
- 단순히 공유 메모리를 Point 함으로써 프로세스에서 사용되는 메모리가 증가하지 않는다.

- 장점: 비교적 간단하고, 커널 메모리 영역에서 관리하기 때문에 매우 빠르게 접근 가능하다는 장점이 있다.
- 단점: 커널설정에 종속적이기 때문에, 사용하기 전에 커널에서 허용하고 있는 공유 메모리 세그먼트 크기를 확인해야 한다.
  - 메시지 전달 방식이 아니기 때문에 데이터 읽어야 되는 시점을 알 수 없다
  - 동기화 문제가 발생할 수 있다 -> 뮤텍스로 해결

## Block, Synchronous

- Block: 특정 행위로 인해 막혀버린, 제한된 대기하는 상태, 단일 개체 스스로의 상태
  - 호출된 함수가 자신이 할 일을 모두 마칠 때 까지 제어권을 가지고서 호출한 함수에게 바로 돌려주지 않으면 Block
  - 호출된 함수가 자신이 할 일을 마치지 않았더라도 바로 제어권을 건네주어 호출한 함수가 다른일을 진행할 수 있도록 해주면 Non-Block
- Synchronous: 동시에 발생되는 것들

  - 호출된 함수의 수행결과가 호출한 함수가 신경 쓰면 Synchronous
  - 호출된 함수의 수행 결과 및 종료된 함수 혼자 신경 쓰고 처리하면 Asynchronouse

- Block VS Synchronous
  - Block: 호출되는 함수가 바로 리턴하느냐 마느냐
    - 바로 Return이 되는지 안되는지
  - Synchronous: 호출되는 함수의 작업 완료 여부를 누가 신경쓰는가
    - 나중에 join()이 되는지 안되는지
