# Spark(Apache Spark)

인 메모리 기반의 대용량 데이터 고속 처리 엔진으로 범용 분산 클러스터 컴퓨팅 프레임 워크

- DISK I/O 기반으로 동작하는 Hadoop과 다르게 인메모리를 사용하여 속도가 최소 1000배는 빠르다.
- 데이터 실시간 스트리밍 처리 니즈를 충족한다.
- 하둡 + 스파크: 하둡의 Yarn 위에 Spark를 얹고, 실시간성이 필요한 데이터는 스파크로 처리하는 방식

## 등장 배경

- 하둡의 HDFS가 DISK I/O를 기반으로 동작하고 있는데 실시간 성 데이터에 대한 니즈가 급격히 들어나면서 하둡으로 처리하기에는 속도 측면에서 부적합하다.
- Spark는 DISK가 아닌 인메모리에서 사용하기 떄문에 반복적인 처리가 필요한 작업에서 속도가 빨라진다.
- 그래서 이제 하둡 + 스파크 라는 둘의 연계가 하나의 큰 흐름으로 자리 잡았다.

## Spark Application

실제 일을 수행하는 역할을 담당한다

1. Driver: 한 개의 노드에서 실행되며, 스파크 전체의 main 함수를 실행한다.

- 어플리케이션 내 정보의 유지 관리, 익스 큐터의 실행 및 실행 분석, 배포 등의 역할을 수행한다.

2. Executor: 다수의 worker 노드에서 실행되는 프로세스

- Driver가 할당한 작업을 수행하여 결과를 반환한다.
- Worker: 클러스터 내에서 Application을 수행 가능한 노드

- 1개의 스카프 어플리케이션은 1개의 Driver와 N개의 Executor가 존재한다.
- Executor는 Cluster Manager에 의하여 해당 스파크 어플리케이션에 할당된다.

- 해당 스파크 어플리케이션이 완전히 종료된 후 할당에서 해방된다
- 다른 스파크 어플리케이션 간의 직접적인 데이터 공유는 불가능하다.

- 즉, Driver는 main을 가동시키는 프로세스, Executor는 데이터를 디스크에 유지하는 프로세스

- SparkContext: 애플리케이션 간 리소를 제공하는 여러 유형의 클러스터 관리자에 연결할 수 있다.

  - 사용자의 주 함수를 실행하고 작업자 노드에서 다양한 병렬 작업을 실행한다.
  - 그리고 SparkContext 는 작업 결과를 수행한다.

- 드라이버 프로그램들은 연산 클러스터에 대한 연결을 나타내는 SparkContext 객체를 통해 스파크에 접속한다.

## Cluster Manager

스파크 어플리케이션 사이에 자원을 중계해주는 역할을 담당한다.

- 스파크 어플리케이션의 리소스를 효율적으로 분배하는 역할을 담당한다.
- Executor에 Task를 할당하고 관리하기 위해서 클러스터 매니저에 의존한다.

- 사용 가능한 클러스터 매니저: Spark StandAlone, Hadoop Yarn, Mesos, Kubernetes등

## 실행 과정

1. 사용자가 Spark-submit을 통해 어플리케이션을 제출한다.
2. Spark Driver가 main을 실행하며, Spark Context를 생성한다.
3. Spark Context가 Cluster Manager와 연결된다.
4. Spark Driver가 Cluster Manager로 부터 Executor 실행을 위한 리소스를 요청한다.
5. Spark Context는 작업 내용을 task 단위로 분할하여 Excutor에 보낸다
6. 각 Executor는 작업을 수행하고, 결과를 저장한다.

- 즉, 사용자 프로그램을 수행하기 위해서, Spark Driver 내의 Spark Context가 Job을 task 단위로 쪼갠다.
  - Cluster Maanger로 부터 할당받은 Executor로 task를 넘긴다.

## 구성요소

1. Spark Core: 메인 컴포넌트로 작업 스케쥴링, 메모리 관리, 장애 복구와 같은 기본적인 기능을 제공하고, RDD, Dateset, DataFrame을 이용한 스파크 연산을 처리한다.
2. Spark Library: 빅데이터 처리를 위한 라이브러리
   - park SQL: 이를 이용하여 작업을 생성하고 처리한다.
   - park Streaming: 실시간 데이터 스트림을 처리하는 컴포넌트이다.
   - MLib: 스파크 기반의 머신러닝 기능을 제공하는 컴포넌트이다.
   - GraphX: 분산형 그래프 프로세싱이 가능하게 해주는 컴포넌트이다.
3. Cluster Manager: 스파크 작업을 운영하는 클러스터 관리자이다

## 장점

1. 인메모리 기반의 데이터 처리로 빠르다

- 인메모리: 데이터스토리지의 메인 메모리에 설치되어 운영되는 방식의 데이터베이스 방식 관리 시스템
  - 즉, 하드 디스크가 아닌 메인 메모리에 올려서 서비스를 수행 하는 것을 말한다.

2. 어플리케이션 형태의 빅데이터 통합환경을 제공
3. 실시간 데이터 프로세싱 지원
4. sparkml이라는 머신러닝 패키지 지원
5. Scala기반으로 작성되어 있음, 어플리케이션 코드로는 JAVA, Python 지원
6. Hadoop의 데이터 저장소와 아주 쉽게 연동된다.

## 단점

1. 자체 파일 시스템이 존재하지 않는다: 데이터를 가져오거나 저장할 때 Hadoop을 연동하여 사용해야 한다.
2. 비싸다: 데이터가 클 경우 병목현상이 일어난다.
3. 빈약학 ML 알고리즘
4. 데이터 처리가 유저에게 편리하지 않다.
5. 학습 비용이 크다.
